{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x74d3798ba8b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from models import SkipConnectionSupervenientFeatureNetwork\n",
    "from trainers import train_feature_network\n",
    "\n",
    "lt.monkey_patch()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "seed = 44\n",
    "torch.manual_seed(seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"torch_seed\": seed,\n",
    "    \"dataset_type\": \"ecog\",\n",
    "    \"num_atoms\": 64,\n",
    "    \"batch_size\": 1000,\n",
    "    \"train_mode\": True,\n",
    "    \"train_model_B\": False,\n",
    "    \"adjust_Psi\": False,\n",
    "    \"clip\": 5,\n",
    "    \"feature_size\": 3,\n",
    "    \"epochs\": 70,\n",
    "    \"start_updating_f_after\": 500,\n",
    "    \"update_f_every_N_steps\": 5,\n",
    "    \"minimize_neg_terms_until\": 9999999999,\n",
    "    \"downward_critics_config\": {\n",
    "        \"hidden_sizes_v_critic\": [512, 1024, 1024, 512],\n",
    "        \"hidden_sizes_xi_critic\": [512, 512, 512],\n",
    "        \"critic_output_size\": 32,\n",
    "        \"lr\": 1e-3,\n",
    "        \"bias\": True,\n",
    "        \"weight_decay\": 0,\n",
    "    },\n",
    "    \"decoupled_critic_config\": {\n",
    "        \"hidden_sizes_encoder_1\": [512, 512, 512],\n",
    "        \"hidden_sizes_encoder_2\": [512, 512, 512],\n",
    "        \"critic_output_size\": 32,\n",
    "        \"lr\": 1e-3,\n",
    "        \"bias\": True,\n",
    "        \"weight_decay\": 0,\n",
    "    },\n",
    "    \"feature_network_config\": {\n",
    "        \"hidden_sizes\": [256, 256, 256, 256, 256],\n",
    "        \"lr\": 1e-4,\n",
    "        \"bias\": True,\n",
    "        \"weight_decay\": 1e-3,\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ECoGDataset()\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=config[\"batch_size\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded\n"
     ]
    }
   ],
   "source": [
    "# bits_dataset_config = {\n",
    "#     \"num_data_points\": int(1e6),\n",
    "#     \"extra_bit_correlation\": 0.99,\n",
    "#     \"parity_bit_correlation\": 0.99,\n",
    "# }\n",
    "\n",
    "\n",
    "# dataset = BitStringDataset(\n",
    "#     gamma_parity=bits_dataset_config['parity_bit_correlation'],\n",
    "#     gamma_extra=bits_dataset_config['extra_bit_correlation'],\n",
    "#     length=bits_dataset_config['num_data_points'],\n",
    "# )\n",
    "\n",
    "# trainloader = torch.utils.data.DataLoader(\n",
    "#     dataset,\n",
    "#     batch_size=config['batch_size'],\n",
    "#     shuffle=True,\n",
    "# )\n",
    "\n",
    "# print(\"Dataset loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdmcsharry\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/dm2223/info-theory-experiments/wandb/run-20240510_122610-z5e2ymir</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dmcsharry/ecog-Train%3DTrue-model_B%3DFalse-dataset-neurips/runs/z5e2ymir' target=\"_blank\">vocal-firefly-7</a></strong> to <a href='https://wandb.ai/dmcsharry/ecog-Train%3DTrue-model_B%3DFalse-dataset-neurips' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dmcsharry/ecog-Train%3DTrue-model_B%3DFalse-dataset-neurips' target=\"_blank\">https://wandb.ai/dmcsharry/ecog-Train%3DTrue-model_B%3DFalse-dataset-neurips</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dmcsharry/ecog-Train%3DTrue-model_B%3DFalse-dataset-neurips/runs/z5e2ymir' target=\"_blank\">https://wandb.ai/dmcsharry/ecog-Train%3DTrue-model_B%3DFalse-dataset-neurips/runs/z5e2ymir</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 70/70 [1:16:01<00:00, 65.16s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import importlib\n",
    "import trainers\n",
    "importlib.reload(trainers)\n",
    "from trainers import train_feature_network\n",
    "\n",
    "feature_network = SkipConnectionSupervenientFeatureNetwork(\n",
    "    num_atoms=config['num_atoms'],\n",
    "    feature_size=config['feature_size'],\n",
    "    hidden_sizes=config['feature_network_config']['hidden_sizes'],\n",
    "    include_bias=config['feature_network_config']['bias'],\n",
    ").to(device)\n",
    "\n",
    "feature_network = train_feature_network(config, trainloader, feature_network)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<Training model B>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:aikxvpi4) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">charmed-moon-4</strong> at: <a href='https://wandb.ai/dmcsharry/ecog-Train%3DTrue-model_B%3DFalse-dataset-neurips/runs/aikxvpi4' target=\"_blank\">https://wandb.ai/dmcsharry/ecog-Train%3DTrue-model_B%3DFalse-dataset-neurips/runs/aikxvpi4</a><br/> View project at: <a href='https://wandb.ai/dmcsharry/ecog-Train%3DTrue-model_B%3DFalse-dataset-neurips' target=\"_blank\">https://wandb.ai/dmcsharry/ecog-Train%3DTrue-model_B%3DFalse-dataset-neurips</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240508_071940-aikxvpi4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:aikxvpi4). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/dm2223/info-theory-experiments/wandb/run-20240508_072101-aavrfkxq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dmcsharry/ecog-Train%3DTrue-model_B%3DTrue-dataset-neurips/runs/aavrfkxq' target=\"_blank\">lemon-wave-1</a></strong> to <a href='https://wandb.ai/dmcsharry/ecog-Train%3DTrue-model_B%3DTrue-dataset-neurips' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dmcsharry/ecog-Train%3DTrue-model_B%3DTrue-dataset-neurips' target=\"_blank\">https://wandb.ai/dmcsharry/ecog-Train%3DTrue-model_B%3DTrue-dataset-neurips</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dmcsharry/ecog-Train%3DTrue-model_B%3DTrue-dataset-neurips/runs/aavrfkxq' target=\"_blank\">https://wandb.ai/dmcsharry/ecog-Train%3DTrue-model_B%3DTrue-dataset-neurips/runs/aavrfkxq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 70/70 [1:11:27<00:00, 61.25s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = {\n",
    "    \"torch_seed\": seed,\n",
    "    \"dataset_type\": \"ecog\",\n",
    "    \"num_atoms\": 64,\n",
    "    \"batch_size\": 1000,\n",
    "    \"train_mode\": True,\n",
    "    \"train_model_B\": True,\n",
    "    \"adjust_Psi\": False,\n",
    "    \"clip\": 5,\n",
    "    \"feature_size\": 3,\n",
    "    \"epochs\": 70,\n",
    "    \"start_updating_f_after\": 500,\n",
    "    \"update_f_every_N_steps\": 5,\n",
    "    \"minimize_neg_terms_until\": 9999999999,\n",
    "    \"downward_critics_config\": {\n",
    "        \"hidden_sizes_v_critic\": [512, 1024, 1024, 512],\n",
    "        \"hidden_sizes_xi_critic\": [512, 512, 512],\n",
    "        \"critic_output_size\": 32,\n",
    "        \"lr\": 1e-3,\n",
    "        \"bias\": True,\n",
    "        \"weight_decay\": 0,\n",
    "    },\n",
    "    \"decoupled_critic_config\": {\n",
    "        \"hidden_sizes_encoder_1\": [512, 512, 512],\n",
    "        \"hidden_sizes_encoder_2\": [512, 512, 512],\n",
    "        \"critic_output_size\": 32,\n",
    "        \"lr\": 1e-3,\n",
    "        \"bias\": True,\n",
    "        \"weight_decay\": 0,\n",
    "    },\n",
    "    \"feature_network_config\": {\n",
    "        \"hidden_sizes\": [256, 256, 256, 256, 256],\n",
    "        \"lr\": 1e-4,\n",
    "        \"bias\": True,\n",
    "        \"weight_decay\": 1e-3,\n",
    "    }\n",
    "}\n",
    "\n",
    "import importlib\n",
    "import trainers\n",
    "importlib.reload(trainers)\n",
    "from trainers import train_feature_network\n",
    "\n",
    "feature_network_A = SkipConnectionSupervenientFeatureNetwork(\n",
    "    num_atoms=config['num_atoms'],\n",
    "    feature_size=config['feature_size'],\n",
    "    hidden_sizes=config['feature_network_config']['hidden_sizes'],\n",
    "    include_bias=config['feature_network_config']['bias'],\n",
    "    ).to(device)\n",
    "\n",
    "model_A_path = '/vol/bitbucket/dm2223/info-theory-experiments/models/ecog_feature_network_robust-star-3.pth'\n",
    "feature_network_A.load_state_dict(torch.load(model_A_path))\n",
    "\n",
    "feature_network_B = SkipConnectionSupervenientFeatureNetwork(\n",
    "    num_atoms=config['num_atoms'],\n",
    "    feature_size=config['feature_size'],\n",
    "    hidden_sizes=config['feature_network_config']['hidden_sizes'],\n",
    "    include_bias=config['feature_network_config']['bias'],\n",
    ").to(device)\n",
    "\n",
    "feature_network_B = train_feature_network(config, trainloader, feature_network_B, feature_network_A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SkipConnectionSupervenientFeatureNetwork:\n\tMissing key(s) in state_dict: \"hidden_layers.3.weight\", \"hidden_layers.3.bias\", \"hidden_layers.4.weight\", \"hidden_layers.4.bias\". \n\tsize mismatch for initial_projection.weight: copying a param with shape torch.Size([256, 6]) from checkpoint, the shape in current model is torch.Size([256, 64]).\n\tsize mismatch for final_projection.weight: copying a param with shape torch.Size([1, 256]) from checkpoint, the shape in current model is torch.Size([3, 256]).\n\tsize mismatch for final_projection.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 14\u001b[0m\n\u001b[1;32m      4\u001b[0m feature_network_A \u001b[38;5;241m=\u001b[39m SkipConnectionSupervenientFeatureNetwork(\n\u001b[1;32m      5\u001b[0m     num_atoms\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_atoms\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      6\u001b[0m     feature_size\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m     hidden_sizes\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_network_config\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_sizes\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      8\u001b[0m     include_bias\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_network_config\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      9\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m model_A_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/vol/bitbucket/dm2223/info-theory-experiments/models/feature_network_apricot-pond-70.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mfeature_network_A\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_A_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m feature_network \u001b[38;5;241m=\u001b[39m feature_network_A\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# plot the various values of V to visually inspect if they contain information about the different bits\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/dm2223/info-theory-experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SkipConnectionSupervenientFeatureNetwork:\n\tMissing key(s) in state_dict: \"hidden_layers.3.weight\", \"hidden_layers.3.bias\", \"hidden_layers.4.weight\", \"hidden_layers.4.bias\". \n\tsize mismatch for initial_projection.weight: copying a param with shape torch.Size([256, 6]) from checkpoint, the shape in current model is torch.Size([256, 64]).\n\tsize mismatch for final_projection.weight: copying a param with shape torch.Size([1, 256]) from checkpoint, the shape in current model is torch.Size([3, 256]).\n\tsize mismatch for final_projection.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([3])."
     ]
    }
   ],
   "source": [
    "from einops import reduce\n",
    "import numpy as np\n",
    "\n",
    "feature_network_A = SkipConnectionSupervenientFeatureNetwork(\n",
    "    num_atoms=config['num_atoms'],\n",
    "    feature_size=config['feature_size'],\n",
    "    hidden_sizes=config['feature_network_config']['hidden_sizes'],\n",
    "    include_bias=config['feature_network_config']['bias'],\n",
    ").to(device)\n",
    "\n",
    "model_A_path = '/vol/bitbucket/dm2223/info-theory-experiments/models/feature_network_apricot-pond-70.pth'\n",
    "\n",
    "\n",
    "feature_network_A.load_state_dict(torch.load(model_A_path))\n",
    "\n",
    "feature_network = feature_network_A\n",
    "\n",
    "# plot the various values of V to visually inspect if they contain information about the different bits\n",
    "\n",
    "\n",
    "binary_numbers = torch.tensor([[int(bit) for bit in f\"{i:06b}\"] for i in range(2**6)])\n",
    "\n",
    "v = feature_network(binary_numbers.float().to(device))\n",
    "\n",
    "xor_bits = (reduce(binary_numbers[:, :5], 'b n -> b', 'sum') % 2).unsqueeze(1)\n",
    "\n",
    "# plot the different values of v on a histogram, with different colors for the two different xor bits\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "v_np = v.detach().cpu().numpy()\n",
    "xor_bits_np = xor_bits.cpu().numpy()\n",
    "\n",
    "plt.hist(v_np[xor_bits_np == 0], bins=100, alpha=0.5, label='xor_bit=0')\n",
    "plt.hist(v_np[xor_bits_np == 1], bins=100, alpha=0.5, label='xor_bit=1')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "extra_bits = binary_numbers[:, -1].unsqueeze(1)\n",
    "\n",
    "# plot the different values of v on a histogram, with different colors for the two different extra bits\n",
    "\n",
    "\n",
    "plt.hist(v_np[extra_bits == 0], bins=100, alpha=0.5, label='extra_bit=0')\n",
    "plt.hist(v_np[extra_bits == 1], bins=100, alpha=0.5, label='extra_bit=1')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "bonus_bits = ( xor_bits + extra_bits ) % 2\n",
    "\n",
    "# plot the different values of v on a histogram, with different colors for the two different bonus bits\n",
    "\n",
    "\n",
    "plt.hist(v_np[bonus_bits == 0], bins=100, alpha=0.5, label='bonus_bit=0')\n",
    "plt.hist(v_np[bonus_bits == 1], bins=100, alpha=0.5, label='bonus_bit=1')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
