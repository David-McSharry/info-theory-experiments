{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/info-theory-experiments/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-14m into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "import transformer_lens\n",
    "\n",
    "\n",
    "model = transformer_lens.HookedTransformer.from_pretrained(\"pythia-14m\")\n",
    "\n",
    "MAX_TOKENS = model.cfg.n_ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: we generate two datasets, one of the resid stream of text produced my model and another of resid streams on fixed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2043/2043 [00:28<00:00, 72.90it/s]\n"
     ]
    }
   ],
   "source": [
    "input_str = \"Once upon a time\"\n",
    "\n",
    "input_tokens = model.to_tokens(input_str)[0]\n",
    "\n",
    "REMANING_TOKENS = MAX_TOKENS - len(input_tokens)\n",
    "\n",
    "output_str = model.generate(input_str, max_new_tokens=REMANING_TOKENS, stop_at_eos=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " man\n",
      "torch.Size([1, 2040])\n"
     ]
    }
   ],
   "source": [
    "print(model.to_string(model.to_tokens(output_str)[0, -1]))\n",
    "\n",
    "print(model.to_tokens(output_str).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 68.29it/s]\n"
     ]
    }
   ],
   "source": [
    "REMANING_TOKENS = MAX_TOKENS - model.to_tokens(output_str).size()[-1]\n",
    "\n",
    "print(REMANING_TOKENS)\n",
    "\n",
    "out2 = model.generate(output_str, max_new_tokens=REMANING_TOKENS, stop_at_eos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 128])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "out2_tokens = model.to_tokens(out2)\n",
    "\n",
    "_, act_cache = model.run_with_cache(out2_tokens)\n",
    "\n",
    "print(act_cache[\"blocks.0.hook_resid_pre\"][0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'act_cache' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m6\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     acts \u001b[38;5;241m=\u001b[39m \u001b[43mact_cache\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblocks.0.hook_resid_pre\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# save tensor to a file called f\"resid_actications_layer_{i}.pt\" in activations folder\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(acts, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivations/resid_actications_layer_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'act_cache' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "for i in range(6):\n",
    "    acts = act_cache[\"blocks.0.hook_resid_pre\"][0]\n",
    "    # save tensor to a file called f\"resid_actications_layer_{i}.pt\" in activations folder\n",
    "    torch.save(acts, f\"activations/resid_actications_layer_{i}.pt\")\n",
    "\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving non-gen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for j in range(1, 15):\n",
    "    with open(f\"econ_texts/econ{j}.txt\") as f:\n",
    "        econ_text1 = f.read()\n",
    "\n",
    "    econ_tokens1 = model.to_tokens(econ_text1)[0][:-1]\n",
    "\n",
    "    _, cache = model.run_with_cache(econ_tokens1)\n",
    "\n",
    "    acts = cache[\"blocks.0.hook_resid_pre\"][0]\n",
    "\n",
    "    torch.save(acts, f\"activations2/econ_resid_actications_layer_3_{j}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([739, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_174882/1508002673.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_acts = torch.load(\"activations2/econ_resid_actications_layer_3_8.pt\")\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load one of the saved tensors from the activations folder\n",
    "loaded_acts = torch.load(\"activations2/econ_resid_actications_layer_3_8.pt\")\n",
    "print(loaded_acts.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now for finding emergent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import (\n",
    "    SkipConnectionSupervenientFeatureNetwork\n",
    ")\n",
    "from custom_datasets import ResidualStreamDataset\n",
    "import lovely_tensors as lt\n",
    "\n",
    "import wandb\n",
    "import tqdm\n",
    "from trainers import train_feature_network\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/info-theory-experiments/custom_datasets.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(data_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:dx2yowns) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Psi</td><td>▁███████████████████████████████████████</td></tr><tr><td>decoupled_MI</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_0</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_1</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_10</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_100</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_101</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_102</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_103</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_104</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_105</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_106</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_107</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_108</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_109</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_11</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_110</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_111</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_112</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_113</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_114</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_115</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_116</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_117</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_118</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_119</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_12</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_120</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_121</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_122</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_123</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_124</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_125</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_126</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_127</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_13</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_14</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_15</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_16</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_17</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_18</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_19</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_2</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_20</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_21</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_22</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_23</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_24</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_25</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_26</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_27</td><td>▁▂▄▅▅▃▄▃▂▆▄▄▇▃▃▇▆▆▆▇▆▆▆▆▆▇▅▅▄▆▇▇▇▇▆▇▇▆█▄</td></tr><tr><td>downward_MI_28</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_29</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_3</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_30</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_31</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_32</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_33</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_34</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_35</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_36</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_37</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_38</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_39</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_4</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_40</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_41</td><td>▁▆▇▇▆▆▇█▇▆▇▆▇▆▅▆▇▆▇▆▇▆▇▆█▇▇▆▇▇▆▇█▇█▇▆▆▆▆</td></tr><tr><td>downward_MI_42</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_43</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_44</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_45</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_46</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_47</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_48</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_49</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_5</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_50</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_51</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_52</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_53</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_54</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_55</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_56</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_57</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_58</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_59</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_6</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_60</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_61</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_62</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_63</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_64</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_65</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_66</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_67</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_68</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_69</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_7</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_70</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_71</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_72</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_73</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_74</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_75</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_76</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_77</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_78</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>downward_MI_79</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_8</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_80</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_81</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_82</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_83</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_84</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_85</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_86</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_87</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_88</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_89</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_9</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_90</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_91</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_92</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_93</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_94</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_95</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_96</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_97</td><td>▁███████████████████████████████████████</td></tr><tr><td>downward_MI_98</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>downward_MI_99</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>sum_downward_MI</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Psi</td><td>8e-05</td></tr><tr><td>decoupled_MI</td><td>-0.0</td></tr><tr><td>downward_MI_0</td><td>-0.0</td></tr><tr><td>downward_MI_1</td><td>-0.0</td></tr><tr><td>downward_MI_10</td><td>-0.0</td></tr><tr><td>downward_MI_100</td><td>-0.0</td></tr><tr><td>downward_MI_101</td><td>-0.0</td></tr><tr><td>downward_MI_102</td><td>-0.0</td></tr><tr><td>downward_MI_103</td><td>-0.0</td></tr><tr><td>downward_MI_104</td><td>-0.0</td></tr><tr><td>downward_MI_105</td><td>-0.0</td></tr><tr><td>downward_MI_106</td><td>0.0</td></tr><tr><td>downward_MI_107</td><td>-0.0</td></tr><tr><td>downward_MI_108</td><td>-0.0</td></tr><tr><td>downward_MI_109</td><td>-0.0</td></tr><tr><td>downward_MI_11</td><td>0.0</td></tr><tr><td>downward_MI_110</td><td>-0.0</td></tr><tr><td>downward_MI_111</td><td>-0.0</td></tr><tr><td>downward_MI_112</td><td>-0.0</td></tr><tr><td>downward_MI_113</td><td>-0.0</td></tr><tr><td>downward_MI_114</td><td>-0.0</td></tr><tr><td>downward_MI_115</td><td>-0.0</td></tr><tr><td>downward_MI_116</td><td>-0.0</td></tr><tr><td>downward_MI_117</td><td>-0.0</td></tr><tr><td>downward_MI_118</td><td>-0.0</td></tr><tr><td>downward_MI_119</td><td>-0.0</td></tr><tr><td>downward_MI_12</td><td>-0.0</td></tr><tr><td>downward_MI_120</td><td>0.0</td></tr><tr><td>downward_MI_121</td><td>-0.0</td></tr><tr><td>downward_MI_122</td><td>-0.0</td></tr><tr><td>downward_MI_123</td><td>0.0</td></tr><tr><td>downward_MI_124</td><td>-0.0</td></tr><tr><td>downward_MI_125</td><td>-0.0</td></tr><tr><td>downward_MI_126</td><td>-0.0</td></tr><tr><td>downward_MI_127</td><td>-0.0</td></tr><tr><td>downward_MI_13</td><td>-0.0</td></tr><tr><td>downward_MI_14</td><td>-0.0</td></tr><tr><td>downward_MI_15</td><td>0.0</td></tr><tr><td>downward_MI_16</td><td>0.0</td></tr><tr><td>downward_MI_17</td><td>-0.0</td></tr><tr><td>downward_MI_18</td><td>-0.0</td></tr><tr><td>downward_MI_19</td><td>0.0</td></tr><tr><td>downward_MI_2</td><td>0.0</td></tr><tr><td>downward_MI_20</td><td>-0.0</td></tr><tr><td>downward_MI_21</td><td>-0.0</td></tr><tr><td>downward_MI_22</td><td>-0.0</td></tr><tr><td>downward_MI_23</td><td>0.0</td></tr><tr><td>downward_MI_24</td><td>-0.0</td></tr><tr><td>downward_MI_25</td><td>-0.0</td></tr><tr><td>downward_MI_26</td><td>-0.0</td></tr><tr><td>downward_MI_27</td><td>-0.0</td></tr><tr><td>downward_MI_28</td><td>-0.0</td></tr><tr><td>downward_MI_29</td><td>-0.0</td></tr><tr><td>downward_MI_3</td><td>-0.0</td></tr><tr><td>downward_MI_30</td><td>-0.0</td></tr><tr><td>downward_MI_31</td><td>-0.0</td></tr><tr><td>downward_MI_32</td><td>-0.0</td></tr><tr><td>downward_MI_33</td><td>-0.0</td></tr><tr><td>downward_MI_34</td><td>-0.0</td></tr><tr><td>downward_MI_35</td><td>0.0</td></tr><tr><td>downward_MI_36</td><td>0.0</td></tr><tr><td>downward_MI_37</td><td>-0.0</td></tr><tr><td>downward_MI_38</td><td>-0.0</td></tr><tr><td>downward_MI_39</td><td>0.0</td></tr><tr><td>downward_MI_4</td><td>-0.0</td></tr><tr><td>downward_MI_40</td><td>0.0</td></tr><tr><td>downward_MI_41</td><td>-0.0</td></tr><tr><td>downward_MI_42</td><td>-0.0</td></tr><tr><td>downward_MI_43</td><td>-0.0</td></tr><tr><td>downward_MI_44</td><td>-0.0</td></tr><tr><td>downward_MI_45</td><td>-0.0</td></tr><tr><td>downward_MI_46</td><td>-0.0</td></tr><tr><td>downward_MI_47</td><td>-0.0</td></tr><tr><td>downward_MI_48</td><td>-0.0</td></tr><tr><td>downward_MI_49</td><td>-0.0</td></tr><tr><td>downward_MI_5</td><td>-0.0</td></tr><tr><td>downward_MI_50</td><td>-0.0</td></tr><tr><td>downward_MI_51</td><td>-0.0</td></tr><tr><td>downward_MI_52</td><td>0.0</td></tr><tr><td>downward_MI_53</td><td>-0.0</td></tr><tr><td>downward_MI_54</td><td>-0.0</td></tr><tr><td>downward_MI_55</td><td>-0.0</td></tr><tr><td>downward_MI_56</td><td>-0.0</td></tr><tr><td>downward_MI_57</td><td>-0.0</td></tr><tr><td>downward_MI_58</td><td>-0.0</td></tr><tr><td>downward_MI_59</td><td>-0.0</td></tr><tr><td>downward_MI_6</td><td>-0.0</td></tr><tr><td>downward_MI_60</td><td>-0.0</td></tr><tr><td>downward_MI_61</td><td>-0.0</td></tr><tr><td>downward_MI_62</td><td>-0.0</td></tr><tr><td>downward_MI_63</td><td>-0.0</td></tr><tr><td>downward_MI_64</td><td>-0.0</td></tr><tr><td>downward_MI_65</td><td>-0.0</td></tr><tr><td>downward_MI_66</td><td>-0.0</td></tr><tr><td>downward_MI_67</td><td>0.0</td></tr><tr><td>downward_MI_68</td><td>-0.0</td></tr><tr><td>downward_MI_69</td><td>0.0</td></tr><tr><td>downward_MI_7</td><td>-0.0</td></tr><tr><td>downward_MI_70</td><td>-0.0</td></tr><tr><td>downward_MI_71</td><td>-0.0</td></tr><tr><td>downward_MI_72</td><td>-0.0</td></tr><tr><td>downward_MI_73</td><td>-0.0</td></tr><tr><td>downward_MI_74</td><td>-0.0</td></tr><tr><td>downward_MI_75</td><td>-0.0</td></tr><tr><td>downward_MI_76</td><td>-0.0</td></tr><tr><td>downward_MI_77</td><td>-0.0</td></tr><tr><td>downward_MI_78</td><td>-0.0</td></tr><tr><td>downward_MI_79</td><td>-0.0</td></tr><tr><td>downward_MI_8</td><td>-0.0</td></tr><tr><td>downward_MI_80</td><td>-0.0</td></tr><tr><td>downward_MI_81</td><td>-0.0</td></tr><tr><td>downward_MI_82</td><td>-0.0</td></tr><tr><td>downward_MI_83</td><td>0.0</td></tr><tr><td>downward_MI_84</td><td>-0.0</td></tr><tr><td>downward_MI_85</td><td>0.0</td></tr><tr><td>downward_MI_86</td><td>-0.0</td></tr><tr><td>downward_MI_87</td><td>-0.0</td></tr><tr><td>downward_MI_88</td><td>-0.0</td></tr><tr><td>downward_MI_89</td><td>-0.0</td></tr><tr><td>downward_MI_9</td><td>-0.0</td></tr><tr><td>downward_MI_90</td><td>-0.0</td></tr><tr><td>downward_MI_91</td><td>0.0</td></tr><tr><td>downward_MI_92</td><td>-0.0</td></tr><tr><td>downward_MI_93</td><td>0.0</td></tr><tr><td>downward_MI_94</td><td>0.0</td></tr><tr><td>downward_MI_95</td><td>-0.0</td></tr><tr><td>downward_MI_96</td><td>-0.0</td></tr><tr><td>downward_MI_97</td><td>0.0</td></tr><tr><td>downward_MI_98</td><td>-0.0</td></tr><tr><td>downward_MI_99</td><td>0.0</td></tr><tr><td>sum_downward_MI</td><td>-8e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">devoted-leaf-7</strong> at: <a href='https://wandb.ai/dmcsharry/resid_layer_3_AI_gen_True_emergent/runs/dx2yowns' target=\"_blank\">https://wandb.ai/dmcsharry/resid_layer_3_AI_gen_True_emergent/runs/dx2yowns</a><br/> View project at: <a href='https://wandb.ai/dmcsharry/resid_layer_3_AI_gen_True_emergent' target=\"_blank\">https://wandb.ai/dmcsharry/resid_layer_3_AI_gen_True_emergent</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240802_002902-dx2yowns/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:dx2yowns). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/info-theory-experiments/wandb/run-20240802_003234-zw5cef0z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dmcsharry/resid_layer_3_AI_gen_True_emergent/runs/zw5cef0z' target=\"_blank\">apricot-flower-8</a></strong> to <a href='https://wandb.ai/dmcsharry/resid_layer_3_AI_gen_True_emergent' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dmcsharry/resid_layer_3_AI_gen_True_emergent' target=\"_blank\">https://wandb.ai/dmcsharry/resid_layer_3_AI_gen_True_emergent</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dmcsharry/resid_layer_3_AI_gen_True_emergent/runs/zw5cef0z' target=\"_blank\">https://wandb.ai/dmcsharry/resid_layer_3_AI_gen_True_emergent/runs/zw5cef0z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "resid_config = {\n",
    "    \"torch_seed\": seed,\n",
    "    \"dataset_type\": \"resid\",\n",
    "    \"num_atoms\": 128,\n",
    "    \"batch_size\": 100,\n",
    "    \"train_mode\": False,\n",
    "    \"resid_layer_index\": 3,\n",
    "    \"use_AI_generated_tokens\": True, # if false, use resid streams for 2048 tokens of econ text, otherwise AI generated text\n",
    "    \"train_model_B\": False,\n",
    "    \"adjust_Psi\": False,\n",
    "    \"clip\": 5,\n",
    "    \"feature_size\": 1,\n",
    "    \"epochs\": 300,\n",
    "    \"start_updating_f_after\": 0,\n",
    "    \"update_f_every_N_steps\": 1,\n",
    "    \"minimize_neg_terms_until\": 0, # if zero I think full psi used, if 9999... then only neg terms\n",
    "    \"downward_critics_config\": {\n",
    "        \"hidden_sizes_v_critic\": [512, 1024, 1024, 512],\n",
    "        \"hidden_sizes_xi_critic\": [512, 1024, 1024, 512],\n",
    "        \"critic_output_size\": 32,\n",
    "        \"lr\": 1e-2,\n",
    "        \"bias\": True,\n",
    "        \"weight_decay\": 0,\n",
    "    },\n",
    "    \n",
    "    \"decoupled_critic_config\": {\n",
    "        \"hidden_sizes_encoder_1\": [1024, 1024, 1024],\n",
    "        \"hidden_sizes_encoder_2\": [1024, 1024, 1024],\n",
    "        \"critic_output_size\": 32,\n",
    "        \"lr\": 1e-2,\n",
    "        \"bias\": True,\n",
    "        \"weight_decay\": 0,\n",
    "    },\n",
    "    \"feature_network_config\": {\n",
    "        \"hidden_sizes\": [512, 512, 512, 512, 512],\n",
    "        \"lr\": 1e-4,\n",
    "        \"bias\": True,\n",
    "        \"weight_decay\": 1e-3,\n",
    "    }\n",
    "}\n",
    "\n",
    "dataset = ResidualStreamDataset(\n",
    "    AI_gen = resid_config[\"use_AI_generated_tokens\"],\n",
    "    index = resid_config[\"resid_layer_index\"],\n",
    ")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=resid_config[\"batch_size\"],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "feature_network = SkipConnectionSupervenientFeatureNetwork(\n",
    "    num_atoms=resid_config[\"num_atoms\"],\n",
    "    feature_size=resid_config[\"feature_size\"],\n",
    "    hidden_sizes=resid_config[\"feature_network_config\"][\"hidden_sizes\"],\n",
    "    include_bias=resid_config[\"feature_network_config\"][\"bias\"]\n",
    ").to(device)\n",
    "\n",
    "project_name = f\"resid_layer_{resid_config['resid_layer_index']}_AI_gen_{resid_config['use_AI_generated_tokens']}_emergent\"\n",
    "model_dir_prefix = f\"resid_layer_{resid_config['resid_layer_index']}_AI_gen_{resid_config['use_AI_generated_tokens']}_emergent\"\n",
    "\n",
    "skip_model = train_feature_network(\n",
    "    config=resid_config,\n",
    "    trainloader=dataloader,\n",
    "    feature_network_training=feature_network,\n",
    "    project_name=project_name,\n",
    "    model_dir_prefix=model_dir_prefix,\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
