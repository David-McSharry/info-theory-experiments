{"cells":[{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["import torch\n","from datasets import BitStringDataset\n","import lovely_tensors as lt\n","import wandb\n","import tqdm\n","from einops import rearrange, reduce, repeat\n","from models import (SupervenientFeatureNetwork,\n","                    CLUB,\n","                    DecoupledSmileMIEstimator,\n","                    DownwardSmileMIEstimator,\n","                    GeneralSmileMIEstimator,\n","                    SkipConnectionSupervenientFeatureNetwork\n","                    )\n","lt.monkey_patch()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","torch.cuda.empty_cache()\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def train_feature_network(config, trainloader, feature_network):\n","\n","    wandb.init(project=\"bits-dataset-neurips\", config=config)\n","    # init weights to zero of the feature network\n","\n","    decoupled_MI_estimator = DecoupledSmileMIEstimator(\n","        feature_size=config['feature_size'],\n","        critic_output_size=config['critic_output_size'],\n","        hidden_sizes_1=config['decoupled_critic_hidden_sizes_1'],\n","        hidden_sizes_2=config['decoupled_critic_hidden_sizes_2'],\n","        clip=config['clip'],\n","        include_bias=config['bias']\n","        ).to(device)\n","    downward_MI_estimators = [\n","        DownwardSmileMIEstimator(\n","            feature_size=config['feature_size'],\n","            critic_output_size=config['critic_output_size'],\n","            hidden_sizes_v_critic=config['downward_hidden_sizes_v_critic'],\n","            hidden_sizes_xi_critic=config['downward_hidden_sizes_xi_critic'],\n","            clip=config['clip'],\n","            include_bias=config['bias']\n","            ).to(device) \n","        for _ in range(config['num_atoms'])\n","    ]\n","    xor_estimator = GeneralSmileMIEstimator(\n","        x_dim=config['feature_size'],\n","        y_dim=1,\n","        critic_output_size=config['critic_output_size'],\n","        x_critics_hidden_sizes=[512, 512, 128],\n","        y_critics_hidden_sizes=[512, 512, 128],\n","        clip=config['clip'],\n","        include_bias=config['bias']\n","    ).to(device)\n","\n","    extra_bit_estimator = GeneralSmileMIEstimator(\n","        x_dim=config['feature_size'],\n","        y_dim=1,\n","        critic_output_size=config['critic_output_size'],\n","        x_critics_hidden_sizes=[512, 512, 128],\n","        y_critics_hidden_sizes=[512, 512, 128],\n","        clip=config['clip'],\n","        include_bias=config['bias']\n","    ).to(device)\n","\n","    bonus_bit_estimator = GeneralSmileMIEstimator(\n","        x_dim=config['feature_size'],\n","        y_dim=1,\n","        critic_output_size=config['critic_output_size'],\n","        x_critics_hidden_sizes=[512, 512, 128],\n","        y_critics_hidden_sizes=[512, 512, 128],\n","        clip=config['clip'],\n","        include_bias=config['bias']\n","    ).to(device)\n","\n","    \n","\n","    feature_optimizer = torch.optim.Adam(\n","        feature_network.parameters(),\n","        lr=config[\"feature_lr\"],\n","        weight_decay=config[\"weight_decay\"]\n","    )\n","    decoupled_optimizer = torch.optim.Adam(\n","        decoupled_MI_estimator.parameters(),\n","        lr=config[\"decoupled_critic_lr\"],\n","        weight_decay=config[\"weight_decay\"]\n","    )\n","    downward_optims = [\n","        torch.optim.Adam(\n","            dc.parameters(),\n","            lr=config[\"downward_lr\"],\n","            weight_decay=config[\"weight_decay\"]\n","        ) \n","        for dc in downward_MI_estimators\n","    ]\n","    xor_optimizer = torch.optim.Adam(\n","        xor_estimator.parameters(),\n","        lr=1e-4,\n","        weight_decay=config[\"weight_decay\"]\n","    )\n","\n","    extra_bit_optimizer = torch.optim.Adam(\n","        extra_bit_estimator.parameters(),\n","        lr=1e-4,\n","        weight_decay=config[\"weight_decay\"]\n","    )\n","\n","    bonus_bit_optimizer = torch.optim.Adam(\n","        bonus_bit_estimator.parameters(),\n","        lr=1e-4,\n","        weight_decay=config[\"weight_decay\"]\n","    )\n","\n","\n","\n","    # TODO: figure out why only f network is being watched, I would like to keep a closer eye on the grad n params.\n","    # TODO: Look at how GANs are trained with pytorch and make sure I'm not doing anything unreasonable.\n","    # Eg, https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/gan/gan.py \n","    # ^ this does not require retain_graph=True, so maybe this can be optomized somehow\n","    wandb.watch(feature_network, log='all')\n","    wandb.watch(decoupled_MI_estimator, log=\"all\")\n","    for dc in downward_MI_estimators:\n","        wandb.watch(dc, log='all')\n","\n","    ##\n","    ## TRAIN FEATURE NETWORK\n","    ##\n","\n","    epochs = config['epochs']\n","\n","    step = 0\n","\n","    for _ in tqdm.tqdm(range(epochs), desc='Training'):\n","        for batch_num, batch in enumerate(trainloader):\n","            x0 = batch[:, 0].to(device).float()\n","            x1 = batch[:, 1].to(device).float()\n","            v0 = feature_network(x0).detach()\n","            v1 = feature_network(x1).detach()\n","\n","            # update decoupled critic\n","            decoupled_optimizer.zero_grad()\n","            decoupled_MI = decoupled_MI_estimator(v0, v1)\n","            decoupled_loss = -decoupled_MI\n","            decoupled_loss.backward(retain_graph=True)\n","            decoupled_optimizer.step()\n","\n","            # update each downward critic \n","            for i in range(config['num_atoms']):\n","                downward_optims[i].zero_grad()\n","                channel_i = x0[:, i].unsqueeze(1).detach()\n","                downward_MI_i = downward_MI_estimators[i](v1, channel_i)\n","                downward_loss = - downward_MI_i\n","                downward_loss.backward(retain_graph=True)\n","                downward_optims[i].step()\n","                wandb.log({\n","                    f\"downward_MI_{i}\": downward_MI_i   \n","                })\n","\n","            # update feature network\n","            feature_optimizer.zero_grad()\n","            channel_MIs = []\n","\n","            # MIs = []\n","            v0 = feature_network(x0)\n","            v1 = feature_network(x1)\n","\n","            for i in range(config['num_atoms']):\n","                channel_i = x0[:, i].unsqueeze(1)\n","                channel_i_MI = downward_MI_estimators[i](v1, channel_i)\n","                channel_MIs.append(channel_i_MI)\n","                # MIs.append(channel_i_MI)\n","\n","            sum_downward_MI = sum(channel_MIs)\n","\n","            decoupled_MI1 = decoupled_MI_estimator(v0, v1)\n","\n","            #clipped_min_MIs = max(0, min(MIs))\n","\n","            Psi = decoupled_MI1 - sum_downward_MI #+ (config['num_atoms'] - 1) * clipped_min_MIs\n","            #NOTE LOSS CHANGEDDDDD\n","            feature_loss = sum_downward_MI\n","            if config['start_updating_f_after'] < step:\n","                if batch_num % config['update_f_every_N_steps'] == 0:\n","                    feature_loss.backward(retain_graph=True)\n","                    feature_optimizer.step()\n","\n","            wandb.log({\n","                \"decoupled_MI\": decoupled_MI1,\n","                \"sum_downward_MI\": sum_downward_MI,\n","                \"Psi\": Psi,\n","            }, step=step)\n","\n","\n","\n","\n","            v0 = feature_network(x0).detach()\n","            v1 = feature_network(x1).detach()\n","            xor_bits = (reduce(x0[: , :5], 'b n -> b', 'sum') % 2).unsqueeze(1)\n","            extra_bit = x0[:, -1].unsqueeze(1)\n","            bonus_bit = ( xor_bits + extra_bit ) % 2\n","\n","\n","            xor_optimizer.zero_grad()\n","            xor_MI = xor_estimator(v0, xor_bits)\n","            xor_loss = -xor_MI\n","            xor_loss.backward(retain_graph=True)\n","            xor_optimizer.step()\n","\n","            extra_bit_optimizer.zero_grad()\n","            extra_bit_MI = extra_bit_estimator(v0, extra_bit)\n","            extra_bit_loss = -extra_bit_MI\n","            extra_bit_loss.backward(retain_graph=True)\n","            extra_bit_optimizer.step()\n","\n","            bonus_bit_optimizer.zero_grad()\n","            bonus_bit_MI = bonus_bit_estimator(v0, bonus_bit)\n","            bonus_bit_loss = -bonus_bit_MI\n","            bonus_bit_loss.backward(retain_graph=True)\n","            bonus_bit_optimizer.step()\n","\n","            wandb.log({\n","                \"xor_MI\": xor_MI,\n","                \"extra_bit_MI\": extra_bit_MI,\n","                \"bonus_bit_MI\": bonus_bit_MI\n","            }, step=step)\n","\n","            step += 1\n","        \n","    torch.save(feature_network.state_dict(), f\"models/feature_network_{wandb.run.name}.pth\")\n","    \n","    return feature_network\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def train_feature_network_B(config, trainloader, feature_network_A, feature_network_B):\n","\n","    wandb.init(project=\"bits-dataset-neurips\", config=config)\n","    # init weights to zero of the feature network\n","\n","    decoupled_MI_estimator = DecoupledSmileMIEstimator(\n","        feature_size=config['feature_size'],\n","        critic_output_size=config['critic_output_size'],\n","        hidden_sizes_1=config['decoupled_critic_hidden_sizes_1'],\n","        hidden_sizes_2=config['decoupled_critic_hidden_sizes_2'],\n","        clip=config['clip'],\n","        include_bias=config['bias']\n","        ).to(device)\n","    downward_MI_estimators = [\n","        DownwardSmileMIEstimator(\n","            feature_size=config['feature_size'],\n","            critic_output_size=config['critic_output_size'],\n","            hidden_sizes_v_critic=config['downward_hidden_sizes_v_critic'],\n","            hidden_sizes_xi_critic=config['downward_hidden_sizes_xi_critic'],\n","            clip=config['clip'],\n","            include_bias=config['bias']\n","            ).to(device) \n","        for _ in range(config['num_atoms'])\n","    ]\n","    MI_AB_estimator = GeneralSmileMIEstimator(\n","        x_dim=config['feature_size'],\n","        y_dim=config['feature_size'],\n","        critic_output_size=config['critic_output_size'],\n","        x_critics_hidden_sizes=[512, 512, 128],\n","        y_critics_hidden_sizes=[512, 512, 128],\n","        clip=config['clip'],\n","        include_bias=config['bias']\n","    ).to(device)\n","    xor_estimator = GeneralSmileMIEstimator(\n","        x_dim=config['feature_size'],\n","        y_dim=1,\n","        critic_output_size=config['critic_output_size'],\n","        x_critics_hidden_sizes=[512, 512, 128],\n","        y_critics_hidden_sizes=[512, 512, 128],\n","        clip=config['clip'],\n","        include_bias=config['bias']\n","    ).to(device)\n","    extra_bit_estimator = GeneralSmileMIEstimator(\n","        x_dim=config['feature_size'],\n","        y_dim=1,\n","        critic_output_size=config['critic_output_size'],\n","        x_critics_hidden_sizes=[512, 512, 128],\n","        y_critics_hidden_sizes=[512, 512, 128],\n","        clip=config['clip'],\n","        include_bias=config['bias']\n","    ).to(device)\n","    bonus_bit_estimator = GeneralSmileMIEstimator(\n","        x_dim=config['feature_size'],\n","        y_dim=1,\n","        critic_output_size=config['critic_output_size'],\n","        x_critics_hidden_sizes=[512, 512, 128],\n","        y_critics_hidden_sizes=[512, 512, 128],\n","        clip=config['clip'],\n","        include_bias=config['bias']\n","    ).to(device)\n","\n","    \n","\n","    feature_optimizer = torch.optim.Adam(\n","        feature_network_B.parameters(),\n","        lr=config[\"feature_lr\"],\n","        weight_decay=config[\"weight_decay\"]\n","    )\n","    decoupled_optimizer = torch.optim.Adam(\n","        decoupled_MI_estimator.parameters(),\n","        lr=config[\"decoupled_critic_lr\"],\n","        weight_decay=config[\"weight_decay\"]\n","    )\n","    downward_optims = [\n","        torch.optim.Adam(\n","            dc.parameters(),\n","            lr=config[\"downward_lr\"],\n","            weight_decay=config[\"weight_decay\"]\n","        ) \n","        for dc in downward_MI_estimators\n","    ]\n","    MI_AB_optimizer = torch.optim.Adam(\n","        MI_AB_estimator.parameters(),\n","        lr=1e-3,\n","        weight_decay=config[\"weight_decay\"]\n","    )\n","    xor_optimizer = torch.optim.Adam(\n","        xor_estimator.parameters(),\n","        lr=1e-3,\n","        weight_decay=config[\"weight_decay\"]\n","    )\n","    extra_bit_optimizer = torch.optim.Adam(\n","        extra_bit_estimator.parameters(),\n","        lr=1e-3,\n","        weight_decay=config[\"weight_decay\"]\n","    )\n","    bonus_bit_optimizer = torch.optim.Adam(\n","        bonus_bit_estimator.parameters(),\n","        lr=1e-3,\n","        weight_decay=config[\"weight_decay\"]\n","    )\n","\n","\n","\n","    # TODO: figure out why only f network is being watched, I would like to keep a closer eye on the grad n params.\n","    # TODO: Look at how GANs are trained with pytorch and make sure I'm not doing anything unreasonable.\n","    # Eg, https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/gan/gan.py \n","    # ^ this does not require retain_graph=True, so maybe this can be optomized somehow\n","    wandb.watch(feature_network_B, log='all')\n","    wandb.watch(decoupled_MI_estimator, log=\"all\")\n","    for dc in downward_MI_estimators:\n","        wandb.watch(dc, log='all')\n","\n","    ##\n","    ## TRAIN FEATURE NETWORK\n","    ##\n","\n","    epochs = config['epochs']\n","\n","    step = 0\n","\n","    for _ in tqdm.tqdm(range(epochs), desc='Training'):\n","        for batch_num, batch in enumerate(trainloader):\n","\n","            x0 = batch[:, 0].to(device).float()\n","            x1 = batch[:, 1].to(device).float()\n","            v0_B = feature_network_B(x0).detach()\n","            v1_B = feature_network_B(x1).detach()\n","            v0_A = feature_network_A(x0).detach()\n","\n","\n","            # update decoupled critic\n","            decoupled_optimizer.zero_grad()\n","            decoupled_MI = decoupled_MI_estimator(v0_B, v1_B)\n","            decoupled_loss = -decoupled_MI\n","            decoupled_loss.backward(retain_graph=True)\n","            decoupled_optimizer.step()\n","\n","\n","            # update each downward critic \n","            for i in range(config['num_atoms']):\n","                downward_optims[i].zero_grad()\n","                channel_i = x0[:, i].unsqueeze(1).detach()\n","                downward_MI_i = downward_MI_estimators[i](v1_B, channel_i)\n","                downward_loss = - downward_MI_i\n","                downward_loss.backward(retain_graph=True)\n","                downward_optims[i].step()\n","                # wandb.log({\n","                #     f\"downward_MI_{i}\": downward_MI_i   \n","                # })\n","\n","\n","            # update MI_AB critic\n","            MI_AB_optimizer.zero_grad()\n","            MI_AB = MI_AB_estimator(v0_B, v0_A)\n","            MI_AB_loss = -MI_AB\n","            MI_AB_loss.backward(retain_graph=True)\n","            MI_AB_optimizer.step()\n","            wandb.log({\"MI_AB\": MI_AB},step=step)\n","\n","\n","            # update feature network\n","            feature_optimizer.zero_grad()\n","            channel_MIs = []\n","\n","            # MIs = []\n","            v0_B = feature_network_B(x0)\n","            v1_B = feature_network_B(x1)\n","\n","            for i in range(config['num_atoms']):\n","                channel_i = x0[:, i].unsqueeze(1)\n","                channel_i_MI = downward_MI_estimators[i](v1_B, channel_i)\n","                channel_MIs.append(channel_i_MI)\n","                # MIs.append(channel_i_MI)\n","\n","            sum_downward_MI = sum(channel_MIs)\n","            decoupled_MI1 = decoupled_MI_estimator(v0_B, v1_B)\n","            MI_AB = MI_AB_estimator(v0_B, v0_A)\n","\n","            #clipped_min_MIs = max(0, min(MIs))\n","\n","            Psi = decoupled_MI1 - sum_downward_MI - MI_AB #+ (config['num_atoms'] - 1) * clipped_min_MIs\n","            feature_loss = -Psi\n","            if config['start_updating_f_after'] < step:\n","                if batch_num % config['update_f_every_N_steps'] == 0:\n","                    feature_loss.backward(retain_graph=True)\n","                    feature_optimizer.step()\n","\n","            if config['start_updating_f_after'] == step:\n","                print(\"Starting to update feature network B\")\n","\n","            wandb.log({\n","                \"decoupled_MI\": decoupled_MI1,\n","                \"sum_downward_MI\": sum_downward_MI,\n","                \"Psi\": Psi,\n","            },step=step)\n","\n","\n","\n","            v0_B = feature_network_B(x0).detach()\n","            v1_B = feature_network_B(x1).detach()\n","            xor_bits = (reduce(x0[: , :5], 'b n -> b', 'sum') % 2).unsqueeze(1)\n","            extra_bit = x0[:, -1].unsqueeze(1)\n","            bonus_bit = ( xor_bits + extra_bit ) % 2\n","\n","\n","            xor_optimizer.zero_grad()\n","            xor_MI = xor_estimator(v0_B, xor_bits)\n","            xor_loss = -xor_MI\n","            xor_loss.backward(retain_graph=True)\n","            xor_optimizer.step()\n","\n","            extra_bit_optimizer.zero_grad()\n","            extra_bit_MI = extra_bit_estimator(v0_B, extra_bit)\n","            extra_bit_loss = -extra_bit_MI\n","            extra_bit_loss.backward(retain_graph=True)\n","            extra_bit_optimizer.step()\n","\n","            bonus_bit_optimizer.zero_grad()\n","            bonus_bit_MI = bonus_bit_estimator(v0_B, bonus_bit)\n","            bonus_bit_loss = -bonus_bit_MI\n","            bonus_bit_loss.backward(retain_graph=True)\n","            bonus_bit_optimizer.step()\n","\n","            wandb.log({\n","                \"xor_MI\": xor_MI,\n","                \"extra_bit_MI\": extra_bit_MI,\n","                \"bonus_bit_MI\": bonus_bit_MI\n","            },step=step)\n","\n","            step += 1\n","\n","\n","\n","        \n","    torch.save(feature_network_B.state_dict(), f\"models/feature_network_{wandb.run.name}.pth\")\n","    \n","    return feature_network_B\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["config = {\n","    \"num_data_points\": int(1e6),\n","    \"extra_bit_correlation\": 0.99,\n","    \"parity_bit_correlation\": 0.99,\n","    \"epochs\": 20,\n","    \"batch_size\": 1000,\n","    \"num_atoms\": 6,\n","    \"feature_size\": 1,\n","    \"clip\": 5,\n","    \"critic_output_size\": 32,\n","    \"downward_hidden_sizes_v_critic\": [512, 512, 512, 256],\n","    \"downward_hidden_sizes_xi_critic\": [512, 512, 512, 256],\n","    \"feature_hidden_sizes\": [256, 256, 256],\n","    \"decoupled_critic_hidden_sizes_1\": [512, 512, 512],\n","    \"decoupled_critic_hidden_sizes_2\": [512, 512, 512],\n","    \"feature_lr\": 0.00001,\n","    \"decoupled_critic_lr\": 1e-3,\n","    \"downward_lr\": 1e-3,    \n","    \"bias\": True,\n","    \"update_f_every_N_steps\": 10,\n","    \"weight_decay\": 0,\n","    \"start_updating_f_after\": 1000,\n","}\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["\n","\n","dataset = BitStringDataset(\n","    gamma_parity=config['parity_bit_correlation'],\n","    gamma_extra=config['extra_bit_correlation'],\n","    length=config['num_data_points'],\n",")\n","\n","trainloader = torch.utils.data.DataLoader(\n","    dataset,\n","    batch_size=config['batch_size'],\n","    shuffle=True,\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdmcsharry\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.17.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/vol/bitbucket/dm2223/info-theory-experiments/wandb/run-20240508_015636-g9tp4j08</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/dmcsharry/bits-dataset-neurips/runs/g9tp4j08' target=\"_blank\">celestial-leaf-98</a></strong> to <a href='https://wandb.ai/dmcsharry/bits-dataset-neurips' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/dmcsharry/bits-dataset-neurips' target=\"_blank\">https://wandb.ai/dmcsharry/bits-dataset-neurips</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/dmcsharry/bits-dataset-neurips/runs/g9tp4j08' target=\"_blank\">https://wandb.ai/dmcsharry/bits-dataset-neurips/runs/g9tp4j08</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Training:   5%|▌         | 1/20 [00:37<11:49, 37.35s/it]"]},{"name":"stdout","output_type":"stream","text":["Starting to update feature network B\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 20/20 [11:45<00:00, 35.27s/it]\n"]}],"source":["# trainin a model B using a model A that learned the XOR bit.\n","feature_network_A = SkipConnectionSupervenientFeatureNetwork(\n","    num_atoms=config['num_atoms'],\n","    feature_size=config['feature_size'],\n","    hidden_sizes=config['feature_hidden_sizes'],\n","    include_bias=config['bias']\n","    ).to(device)\n","\n","model_A_path = '/vol/bitbucket/dm2223/info-theory-experiments/models/feature_network_apricot-pond-70.pth'\n","feature_network_A.load_state_dict(torch.load(model_A_path))\n","\n","feature_network_B = SkipConnectionSupervenientFeatureNetwork(\n","    num_atoms=config['num_atoms'],\n","    feature_size=config['feature_size'],\n","    hidden_sizes=config['feature_hidden_sizes'],\n","    include_bias=config['bias']\n","    ).to(device)\n","\n","feature_network_B = train_feature_network_B(config, trainloader, feature_network_A, feature_network_B)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["\n","# NOTE: the Psi here isnt really Psi, what we should do instead here is add I(va,vb) in loss but keep track of true loss, \n","# maybe add a smaller coeeficient for I(va,vb) term in the loss\n","def find_true_Psi(feature_network, run_id, trainloader):\n","\n","    config = {\n","        \"epochs\": 1,\n","        \"batch_size\": 1000,\n","        \"num_atoms\": 6,\n","        \"feature_size\": feature_network.feature_size,\n","        \"clip\": 5,\n","        \"critic_output_size\": 16,\n","        \"downward_hidden_sizes_v_critic\": [512, 512, 128],\n","        \"downward_hidden_sizes_xi_critic\": [512, 512, 128],\n","        \"decoupled_critic_hidden_sizes_1\": [512, 512, 128],\n","        \"decoupled_critic_hidden_sizes_2\": [512, 512, 128],\n","        \"decoupled_critic_lr\": 1e-3,\n","        \"downward_lr\": 1e-3,\n","        \"bias\": True,\n","        \"weight_decay\": 0,\n","        \"original_run_id\": run_id\n","    }\n","\n","    wandb.init(project=\"BITS_Finding-true-Psi-for-f\", config=config, id=run_id)\n","\n","    decoupled_critic = DecoupledSmileMIEstimator(\n","        feature_size=config['feature_size'],\n","        critic_output_size=config['critic_output_size'],\n","        hidden_sizes_1=config['decoupled_critic_hidden_sizes_1'],\n","        hidden_sizes_2=config['decoupled_critic_hidden_sizes_2'],\n","        clip=config['clip'],\n","        include_bias=config['bias']\n","        ).to(device)\n","\n","    downward_critics = [\n","        DownwardSmileMIEstimator(\n","            feature_size=config['feature_size'],\n","            critic_output_size=config['critic_output_size'],\n","            hidden_sizes_v_critic=config['downward_hidden_sizes_v_critic'],\n","            hidden_sizes_xi_critic=config['downward_hidden_sizes_xi_critic'],\n","            clip=config['clip'],\n","            include_bias=config['bias']\n","            ).to(device) \n","        for _ in range(config['num_atoms'])\n","    ]\n","\n","    xor_estimator = GeneralSmileMIEstimator(\n","        x_dim=config['feature_size'],\n","        y_dim=1,\n","        critic_output_size=config['critic_output_size'],\n","        x_critics_hidden_sizes=[512, 512, 128],\n","        y_critics_hidden_sizes=[512, 512, 128],\n","        clip=config['clip'],\n","        include_bias=config['bias']\n","    ).to(device)\n","\n","    extra_bit_estimator = GeneralSmileMIEstimator(\n","        x_dim=config['feature_size'],\n","        y_dim=1,\n","        critic_output_size=config['critic_output_size'],\n","        x_critics_hidden_sizes=[512, 512, 128],\n","        y_critics_hidden_sizes=[512, 512, 128],\n","        clip=config['clip'],\n","        include_bias=config['bias']\n","    ).to(device)\n","\n","    bonus_bit_estimator = GeneralSmileMIEstimator(\n","        x_dim=config['feature_size'],\n","        y_dim=1,\n","        critic_output_size=config['critic_output_size'],\n","        x_critics_hidden_sizes=[512, 512, 128],\n","        y_critics_hidden_sizes=[512, 512, 128],\n","        clip=config['clip'],\n","        include_bias=config['bias']\n","    ).to(device)\n","\n","\n","    downward_optims = [\n","        torch.optim.Adam(\n","            dc.parameters(),\n","            lr=config[\"downward_lr\"],\n","            weight_decay=config[\"weight_decay\"]\n","        ) \n","        for dc in downward_critics\n","    ]\n","\n","    decoupled_optimizer = torch.optim.Adam(\n","        decoupled_critic.parameters(),\n","        lr=config[\"decoupled_critic_lr\"],\n","        weight_decay=config[\"weight_decay\"]\n","    )\n","\n","    xor_optimizer = torch.optim.Adam(\n","        xor_estimator.parameters(),\n","        lr=config[\"decoupled_critic_lr\"],\n","        weight_decay=config[\"weight_decay\"]\n","    )\n","\n","    extra_bit_optimizer = torch.optim.Adam(\n","        extra_bit_estimator.parameters(),\n","        lr=config[\"decoupled_critic_lr\"],\n","        weight_decay=config[\"weight_decay\"]\n","    )\n","\n","    bonus_bit_optimizer = torch.optim.Adam(\n","        bonus_bit_estimator.parameters(),\n","        lr=config[\"decoupled_critic_lr\"],\n","        weight_decay=config[\"weight_decay\"]\n","    )\n","\n","\n","    # TODO: figure out why only f network is being watched, I would like to keep a closer eye on the grad n params.\n","    # TODO: Look at how GANs are trained with pytorch and make sure I'm not doing anything unreasonable.\n","    # Eg, https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/gan/gan.py \n","    # ^ this does not require retain_graph=True, so maybe this can be optomized somehow\n","    wandb.watch(decoupled_critic, log=\"all\")\n","    for dc in downward_critics:\n","        wandb.watch(dc, log='all')\n","\n","    epochs = config['epochs']\n","\n","    for _ in tqdm.tqdm(range(epochs), desc='Training'):\n","        for _, batch in enumerate(trainloader):\n","            x0 = batch[:, 0].to(device).float()\n","            x1 = batch[:, 1].to(device).float()\n","\n","            # update decoupled critic\n","\n","            v0 = feature_network(x0)\n","            v1 = feature_network(x1) \n","\n","            xor_bits = (reduce(x0[: , :5], 'b n -> b', 'sum') % 2).unsqueeze(1)\n","            extra_bit = x0[:, -1].unsqueeze(1)\n","            bonus_bit = ( xor_bits + extra_bit ) % 2\n","\n","\n","            decoupled_optimizer.zero_grad()\n","            decoupled_MI = decoupled_critic(v0, v1)\n","            decoupled_loss = -decoupled_MI\n","            decoupled_loss.backward(retain_graph=True)\n","            decoupled_optimizer.step()\n","\n","\n","            # update each downward critic \n","\n","            MIs = []\n","\n","            for i in range(config['num_atoms']):\n","                downward_optims[i].zero_grad()\n","                channel_i = x0[:, i].unsqueeze(1)\n","                downward_MI_i = downward_critics[i](v1, channel_i)\n","                # add spectral norm to the loss\n","                downward_loss = - downward_MI_i\n","                downward_loss.backward(retain_graph=True)\n","                downward_optims[i].step()\n","                # wandb.log({\n","                #     f\"downward_MI_{i}\": downward_MI_i   \n","                # })\n","                MIs.append(downward_MI_i)\n","\n","            # update feature network   \n","\n","            min_MI = min(MIs)\n","            clipped_min_MIs = max(0, min_MI)\n","\n","            sum_downward_MI = 0\n","\n","            for i in range(config['num_atoms']):\n","                channel_i = x0[:, i].unsqueeze(1)\n","                sum_downward_MI += downward_critics[i](v1, channel_i)\n","\n","            decoupled_MI1 = decoupled_critic(v0, v1)\n","\n","            Psi = decoupled_MI1 - sum_downward_MI + (config['num_atoms'] - 1) * clipped_min_MIs\n","\n","            wandb.log({\n","                \"decoupled_MI\": decoupled_MI1,\n","                \"sum_downward_MI\": sum_downward_MI,\n","                \"Psi\": Psi,\n","            })\n","\n","            xor_optimizer.zero_grad()\n","            xor_MI = xor_estimator(v0, xor_bits)\n","            xor_loss = -xor_MI\n","            xor_loss.backward(retain_graph=True)\n","            xor_optimizer.step()\n","\n","            extra_bit_optimizer.zero_grad()\n","            extra_bit_MI = extra_bit_estimator(v0, extra_bit)\n","            extra_bit_loss = -extra_bit_MI\n","            extra_bit_loss.backward(retain_graph=True)\n","            extra_bit_optimizer.step()\n","\n","            bonus_bit_optimizer.zero_grad()\n","            bonus_bit_MI = bonus_bit_estimator(v0, bonus_bit)\n","            bonus_bit_loss = -bonus_bit_MI\n","            bonus_bit_loss.backward(retain_graph=True)\n","            bonus_bit_optimizer.step()\n","\n","            wandb.log({\n","                \"xor_MI\": xor_MI,\n","                \"extra_bit_MI\": extra_bit_MI,\n","                \"bonus_bit_MI\": bonus_bit_MI\n","            })\n","            \n","        \n","    return Psi\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdmcsharry\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/vol/bitbucket/dm2223/info-theory-experiments/wandb/run-20240507_150338-qrhxaxfx</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/dmcsharry/BITS_Finding-true-Psi-for-f/runs/qrhxaxfx' target=\"_blank\">elated-disco-37</a></strong> to <a href='https://wandb.ai/dmcsharry/BITS_Finding-true-Psi-for-f' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/dmcsharry/BITS_Finding-true-Psi-for-f' target=\"_blank\">https://wandb.ai/dmcsharry/BITS_Finding-true-Psi-for-f</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/dmcsharry/BITS_Finding-true-Psi-for-f/runs/qrhxaxfx' target=\"_blank\">https://wandb.ai/dmcsharry/BITS_Finding-true-Psi-for-f/runs/qrhxaxfx</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 1/1 [00:30<00:00, 30.12s/it]\n"]}],"source":["feature_network = SkipConnectionSupervenientFeatureNetwork(\n","    num_atoms=config['num_atoms'],\n","    feature_size=config['feature_size'],\n","    hidden_sizes=config['feature_hidden_sizes'],\n","    include_bias=config['bias']\n","    ).to(device)\n","\n","Psi = find_true_Psi(feature_network, None, trainloader)\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/html":["Finishing last run (ID:nnc7pfb4) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Psi</td><td>▄▂▃▃▂▁▁▂▂▁▄▃▄▃▄▅▅▅▃▄▄▅▅█▅▄▅▆▆▆▅▆▆▅▅▆▆▇▇▇</td></tr><tr><td>bonus_bit_MI</td><td>▁▅▆█▇████▆▅▆▆▇▆▅▄▅▃▄▅▃▅▄▃▄▅▃▅▅▂▃▃▃▂▂▂▂▁▂</td></tr><tr><td>decoupled_MI</td><td>▅▃▅█▆▃▅▆▅▇▄▂▁▁▃▂▁▁▂▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▂▂▂▄</td></tr><tr><td>extra_bit_MI</td><td>▇▇▆▇▇▆▆█▇▇▆▅▄▅▄▄▃▃▄▄▄▃▃▂▂▄▂▂▂▂▃▂▁▁▂▁▁▂▂▂</td></tr><tr><td>sum_downward_MI</td><td>▅▆▆▇▇▇█▇▇█▅▆▄▅▅▄▄▄▅▅▄▄▄▁▃▄▄▃▃▃▃▃▂▃▃▂▃▂▂▂</td></tr><tr><td>xor_MI</td><td>▁▁▂▂▂▁▂▃▃▂▁▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▂▂▃▃▄▅▆▄▅▅▇▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Psi</td><td>6e-05</td></tr><tr><td>bonus_bit_MI</td><td>0.02731</td></tr><tr><td>decoupled_MI</td><td>0.01176</td></tr><tr><td>extra_bit_MI</td><td>0.00567</td></tr><tr><td>sum_downward_MI</td><td>0.01169</td></tr><tr><td>xor_MI</td><td>0.26836</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">glowing-gorge-83</strong> at: <a href='https://wandb.ai/dmcsharry/bits-dataset-neurips/runs/nnc7pfb4' target=\"_blank\">https://wandb.ai/dmcsharry/bits-dataset-neurips/runs/nnc7pfb4</a><br/> View project at: <a href='https://wandb.ai/dmcsharry/bits-dataset-neurips' target=\"_blank\">https://wandb.ai/dmcsharry/bits-dataset-neurips</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240507_153257-nnc7pfb4/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:nnc7pfb4). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/vol/bitbucket/dm2223/info-theory-experiments/wandb/run-20240507_153805-6giz6p8e</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/dmcsharry/bits-dataset-neurips/runs/6giz6p8e' target=\"_blank\">serene-darkness-84</a></strong> to <a href='https://wandb.ai/dmcsharry/bits-dataset-neurips' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/dmcsharry/bits-dataset-neurips' target=\"_blank\">https://wandb.ai/dmcsharry/bits-dataset-neurips</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/dmcsharry/bits-dataset-neurips/runs/6giz6p8e' target=\"_blank\">https://wandb.ai/dmcsharry/bits-dataset-neurips/runs/6giz6p8e</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 20/20 [09:07<00:00, 27.38s/it]\n"]}],"source":["feature_network = SkipConnectionSupervenientFeatureNetwork(\n","    num_atoms=config['num_atoms'],\n","    feature_size=config['feature_size'],\n","    hidden_sizes=config['feature_hidden_sizes'],\n","    include_bias=config['bias']\n","    ).to(device)\n","\n","\n","feature_network = train_feature_network(config, trainloader, feature_network)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlj0lEQVR4nO3de3DU9b3/8deSZZcEkkDCJUQSk1JEbgY1wAAODUNaTkAKOseCgxjBUj0nFJKc4UiOcldWrLU5KAW1g3g6gLZzIE05lh4mBaLlmqRx1EO52ACpXEJ7NEtC2dDs9/dHf+7pSrgk+e5ns+H5mPnOsN/97n7ebpA8Z797cViWZQkAAMCQLuEeAAAA3F6IDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABjlDPcAX+X3+3X27FnFxsbK4XCEexwAAHALLMvSpUuXlJycrC5dbvzcRoeLj7NnzyolJSXcYwAAgDaora3VgAEDbnhMh4uP2NhYSX8bPi4uLszTAACAW+H1epWSkhL4PX4jHS4+vjzVEhcXR3wAABBhbuUlE7zgFAAAGEV8AAAAo4gPAABgVId7zQcAoHNpbm7W1atXwz0GbBAVFSWn09nuj8IgPgAAIdPQ0KA//vGPsiwr3KPAJjExMerfv79cLleb74P4AACERHNzs/74xz8qJiZGffr04YMjI5xlWWpqatLFixdVU1OjQYMG3fTDxK6H+AAAhMTVq1dlWZb69Omj6OjocI8DG0RHR6tr1646ffq0mpqa1K1btzbdDy84BQCEFM94dC5tfbYj6D5smAMAAOCWER8AAMAoXvMBADDqR7uPG12v4Jt3GV2vLZ544gl98cUXKikpue4xWVlZGjlypIqLi43NFSo88wEAQATYvn27Vq9eHbiclpZmS4isX79eaWlp6tatm8aMGaPDhw+3+z5vhvgAACCEmpub5ff7230/CQkJt/SNsa3x7rvvqrCwUMuXL1dVVZUyMjI0efJk1dXV2brOVxEfAAD8nYsXLyopKUlr1qwJ7Nu/f79cLpfKysr0+eef6/HHH1evXr0UExOjnJwcnThxInDs5s2b1bNnT5WWlmro0KFyu906c+bMLa29cuVK9enTR3FxcXr66afV1NQUuC4rK0v5+fmBP58+fVoFBQVyOBxtfkfRK6+8ovnz52vu3LkaOnSoNm7cqJiYGG3atKlN93eriA+gnX60+3jQBiCy9enTR5s2bdKKFStUUVGhS5cuac6cOVqwYIEmTZqkJ554QhUVFSotLdWBAwdkWZamTJkS9BHyly9f1tq1a/WTn/xEn3zyifr27XvTdcvKynT06FHt3btX27Zt0/bt27Vy5coWj92+fbsGDBigVatW6dy5czp37pwk6cyZM+rRo8cNty+jqqmpSZWVlcrOzg7cb5cuXZSdna0DBw605yG8KV5wCgDAV0yZMkXz58/X7NmzlZmZqe7du8vj8ejEiRMqLS3Vb3/7W40bN06StGXLFqWkpKikpESPPPKIpL99wNqPf/xjZWRk3PKaLpdLmzZtUkxMjIYNG6ZVq1Zp8eLFWr169TWfrZGQkKCoqCjFxsYqKSkpsD85OVnV1dU3XCchIUGS9Kc//UnNzc3q169f0PX9+vXT73//+1ueuy2IDwAAWvDyyy9r+PDh+vnPf67Kykq53W4dPXpUTqdTY8aMCRyXmJiowYMH6+jRo4F9LpdL99xzT6vWy8jIUExMTODy2LFj1dDQoNraWt155523dB9Op1Nf//rXW7VuOHDaBQCAFnz66ac6e/as/H6/Tp061arbRkdHh+WTXVtz2qV3796KiorShQsXgu7jwoULQc+mhALPfAAA8BVNTU167LHHNHPmTA0ePFjf/e539dFHH2nIkCH661//qkOHDgVOu/z5z3/WsWPHNHTo0Hat+eGHH+ovf/lL4HtwDh48qB49eiglJaXF410ul5qbm4P2tea0i8vl0v3336+ysjLNmDFDkuT3+1VWVqYFCxa067/lZogPAAC+4tlnn1V9fb3WrVunHj166L333tO8efO0c+dOTZ8+XfPnz9frr7+u2NhYLVmyRHfccYemT5/erjWbmpr05JNP6rnnntOpU6e0fPlyLViw4LrfpZKWlqby8nLNmjVLbrdbvXv3bvVpl8LCQuXm5iozM1OjR49WcXGxGhsbNXfu3Hb9t9wM8QEAMKqjf+Lo3r17VVxcrD179iguLk6S9NOf/lQZGRnasGGD3nrrLS1atEgPPvigmpqaNGHCBL333nvq2rVru9adNGmSBg0apAkTJsjn8+nRRx/VihUrrnv8qlWr9NRTT2ngwIHy+XyyLKvVa86cOVMXL17UsmXLdP78eY0cOVK7du265kWodnNYbZk2hLxer+Lj41VfXx/4oQMd2VffXtvR/2EFTLly5YpqamqUnp7e5q9eR8dzvZ9ra35/84JTAABgFPEBAECI3ejdJ++//364xzOO13wAABBiN3oHyh133GFukA6C+AAAIMQi4YO/TOK0CwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjWh0f5eXlmjZtmpKTk+VwOFRSUnLNMUePHtW3v/1txcfHq3v37ho1apTOnDljx7wAAHQ6TzzxRODL3a4nKytL+fn5RuYJtVa/1baxsVEZGRmaN2+eHn744Wuu//TTT/XAAw/oySef1MqVKxUXF6dPPvmEj9YFAPzNHo/Z9SYWmV0vRLZv3x70/TFpaWnKz89vV5CUl5frBz/4gSorK3Xu3Dnt2LHjphFkh1bHR05OjnJycq57/bPPPqspU6bopZdeCuwbOHBg26YDACDCNTc3y+FwXPfbaW9VQkKCTRP9n5s9oRAqtr7mw+/367/+67901113afLkyerbt6/GjBnT4qmZL/l8Pnm93qANAIBwuXjxopKSkrRmzZrAvv3798vlcqmsrEyff/65Hn/8cfXq1UsxMTHKycnRiRMnAsdu3rxZPXv2VGlpqYYOHSq3233LLz1YuXKl+vTpo7i4OD399NNqamoKXPf3p12ysrJ0+vRpFRQUyOFwyOFwtOm/NScnR88//7weeuihNt2+rWyNj7q6OjU0NOjFF1/UP/zDP+i///u/9dBDD+nhhx/Wvn37WryNx+NRfHx8YEtJSbFzJAAAWqVPnz7atGmTVqxYoYqKCl26dElz5szRggULNGnSJD3xxBOqqKhQaWmpDhw4IMuyNGXKFF29ejVwH5cvX9batWv1k5/8RJ988on69u1703XLysp09OhR7d27V9u2bdP27du1cuXKFo/dvn27BgwYoFWrVuncuXM6d+6cJOnMmTM3/B6ZHj16BEVVuNj68ep+v1+SNH36dBUUFEiSRo4cqf3792vjxo36xje+cc1tioqKVFhYGLjs9XoJEABAWE2ZMkXz58/X7NmzlZmZqe7du8vj8ejEiRMqLS3Vb3/7W40bN06StGXLFqWkpKikpESPPPKIJOnq1av68Y9/rIyMjFte0+VyadOmTYqJidGwYcO0atUqLV68WKtXr77mlE1CQoKioqIUGxurpKSkwP7k5OQbfo/Ml7cNN1vjo3fv3nI6nRo6dGjQ/iFDhuiDDz5o8TZut1tut9vOMQAAaLeXX35Zw4cP189//nNVVlbK7Xbr6NGjcjqdGjNmTOC4xMREDR48WEePHg3sc7lcuueee1q1XkZGhmJiYgKXx44dq4aGBtXW1urOO++8pftwOp0R8T0ytp52cblcGjVqlI4dOxa0//jx47f8wAEA0BF8+umnOnv2rPx+v06dOtWq20ZHR7f5dRjt0WlPuzQ0NOjkyZOByzU1NaqurlZCQoJSU1O1ePFizZw5UxMmTNDEiRO1a9cu/fKXv9TevXvtnBsAgJBpamrSY489ppkzZ2rw4MH67ne/q48++khDhgzRX//6Vx06dChw2uXPf/6zjh07ds2z/q314Ycf6i9/+Yuio6MlSQcPHlSPHj2u+1IEl8ul5ubmoH2d9rRLRUWFJk6cGLj85es1cnNztXnzZj300EPauHGjPB6PFi5cqMGDB+s///M/9cADD9g3NQAAIfTss8+qvr5e69atU48ePfTee+9p3rx52rlzp6ZPn6758+fr9ddfV2xsrJYsWaI77rhD06dPb9eaTU1NevLJJ/Xcc8/p1KlTWr58uRYsWHDdt+impaWpvLxcs2bNktvtDrz0oTWnXW72hEKotDo+srKyZFnWDY+ZN2+e5s2b1+ahAACdWAf/0K+9e/equLhYe/bsUVxcnCTppz/9qTIyMrRhwwa99dZbWrRokR588EE1NTVpwoQJeu+994I+AKwtJk2apEGDBmnChAny+Xx69NFHtWLFiusev2rVKj311FMaOHCgfD7fTX83t+RmTyiEisNqy7Qh5PV6FR8fr/r6+sAPHejIfrT7eNDlgm/eFaZJgI7lypUrqqmpUXp6Op9y3Ylc7+famt/ffLEcAAAwivgAACDEbvTuk/fffz/c4xln6+d8AACAa93oHSh33HGHuUE6COIDAIAQi4QP/jKJ0y4AgJDqYO9rQDvZ8fMkPgAAIREVFSVJQd/Mish3+fJlSWrXW4s57QIACAmn06mYmBhdvHhRXbt2ve6HZSEyWJaly5cvq66uTj179gzEZVsQHwCAkHA4HOrfv79qamp0+vTpcI8Dm/Ts2TPom3TbgvgAAISMy+XSoEGDOPXSSXTt2rVdz3h8ifgAAIRUly5d+IRTBOEEHAAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAqFbHR3l5uaZNm6bk5GQ5HA6VlJRc99inn35aDodDxcXF7RgRAAB0Jq2Oj8bGRmVkZGj9+vU3PG7Hjh06ePCgkpOT2zwcAADofJytvUFOTo5ycnJueMxnn32m73//+/r1r3+tqVOntnk4AADQ+bQ6Pm7G7/drzpw5Wrx4sYYNG3bT430+n3w+X+Cy1+u1eyQAANCB2P6C07Vr18rpdGrhwoW3dLzH41F8fHxgS0lJsXskAADQgdgaH5WVlfr3f/93bd68WQ6H45ZuU1RUpPr6+sBWW1tr50gAAKCDsTU+3n//fdXV1Sk1NVVOp1NOp1OnT5/Wv/zLvygtLa3F27jdbsXFxQVtAACg87L1NR9z5sxRdnZ20L7Jkydrzpw5mjt3rp1LAQCACNXq+GhoaNDJkycDl2tqalRdXa2EhASlpqYqMTEx6PiuXbsqKSlJgwcPbv+0AAAg4rU6PioqKjRx4sTA5cLCQklSbm6uNm/ebNtgAACgc2p1fGRlZcmyrFs+/tSpU61dAgAAdGJ8twsAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACManV8lJeXa9q0aUpOTpbD4VBJSUnguqtXr+qZZ57RiBEj1L17dyUnJ+vxxx/X2bNn7ZwZAABEsFbHR2NjozIyMrR+/fprrrt8+bKqqqq0dOlSVVVVafv27Tp27Ji+/e1v2zIsAACIfM7W3iAnJ0c5OTktXhcfH6/du3cH7Xvttdc0evRonTlzRqmpqW2bEgAAdBqtjo/Wqq+vl8PhUM+ePVu83ufzyefzBS57vd5QjwQAAMIopC84vXLlip555hk9+uijiouLa/EYj8ej+Pj4wJaSkhLKkQAAQJiFLD6uXr2q73znO7IsSxs2bLjucUVFRaqvrw9stbW1oRoJAAB0ACE57fJleJw+fVq/+c1vrvushyS53W653e5QjAEAADog2+Pjy/A4ceKE9uzZo8TERLuXAAAAEazV8dHQ0KCTJ08GLtfU1Ki6uloJCQnq37+//vEf/1FVVVXauXOnmpubdf78eUlSQkKCXC6XfZMDAICI1Or4qKio0MSJEwOXCwsLJUm5ublasWKFSktLJUkjR44Mut2ePXuUlZXV9kkBAECn0Or4yMrKkmVZ173+RtcBAADw3S4AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAUc5wDwAALdrjCb48sSg8cwCwHc98AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwKhWx0d5ebmmTZum5ORkORwOlZSUBF1vWZaWLVum/v37Kzo6WtnZ2Tpx4oRd8wIAgAjX6vhobGxURkaG1q9f3+L1L730ktatW6eNGzfq0KFD6t69uyZPnqwrV660e1gAABD5nK29QU5OjnJyclq8zrIsFRcX67nnntP06dMlSf/xH/+hfv36qaSkRLNmzWrftAAAIOLZ+pqPmpoanT9/XtnZ2YF98fHxGjNmjA4cONDibXw+n7xeb9AGAAA6r1Y/83Ej58+flyT169cvaH+/fv0C132Vx+PRypUr7RwDN7PHE3x5YlF45gAQUX60+3jgzwXfvCuMkyDShf3dLkVFRaqvrw9stbW14R4JAACEkK3xkZSUJEm6cOFC0P4LFy4Ervsqt9utuLi4oA0AAHRetsZHenq6kpKSVFZWFtjn9Xp16NAhjR071s6lAABAhGr1az4aGhp08uTJwOWamhpVV1crISFBqampys/P1/PPP69BgwYpPT1dS5cuVXJysmbMmGHn3AAAIEK1Oj4qKio0ceLEwOXCwkJJUm5urjZv3qx//dd/VWNjo773ve/piy++0AMPPKBdu3apW7du9k0NAAAiVqvjIysrS5ZlXfd6h8OhVatWadWqVe0aDAAAdE5hf7cLAAC4vRAfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIxyhnsAALglezz/9+eJReGbA0C78cwHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjLI9Ppqbm7V06VKlp6crOjpaAwcO1OrVq2VZlt1LAQCACOS0+w7Xrl2rDRs26O2339awYcNUUVGhuXPnKj4+XgsXLrR7OQAAEGFsj4/9+/dr+vTpmjp1qiQpLS1N27Zt0+HDh+1eCgAARCDbT7uMGzdOZWVlOn78uCTpww8/1AcffKCcnBy7lwIAABHI9mc+lixZIq/Xq7vvvltRUVFqbm7WCy+8oNmzZ7d4vM/nk8/nC1z2er12jwQAADoQ25/5+NnPfqYtW7Zo69atqqqq0ttvv62XX35Zb7/9dovHezwexcfHB7aUlBS7RwIAAB2I7fGxePFiLVmyRLNmzdKIESM0Z84cFRQUyOPxtHh8UVGR6uvrA1ttba3dIwEAgA7E9tMuly9fVpcuwU0TFRUlv9/f4vFut1tut9vuMQAAQAdle3xMmzZNL7zwglJTUzVs2DD97ne/0yuvvKJ58+bZvRQAAIhAtsfHq6++qqVLl+qf//mfVVdXp+TkZD311FNatmyZ3UsBAIAIZHt8xMbGqri4WMXFxXbfNQAA6AT4bhcAAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYFZL4+Oyzz/TYY48pMTFR0dHRGjFihCoqKkKxFAAAiDBOu+/w888/1/jx4zVx4kT96le/Up8+fXTixAn16tXL7qUAAEAEsj0+1q5dq5SUFL311luBfenp6XYvAwAAIpTtp11KS0uVmZmpRx55RH379tW9996rN99887rH+3w+eb3eoA0AAHRetsfHH/7wB23YsEGDBg3Sr3/9a/3TP/2TFi5cqLfffrvF4z0ej+Lj4wNbSkqK3SMBAIAOxPb48Pv9uu+++7RmzRrde++9+t73vqf58+dr48aNLR5fVFSk+vr6wFZbW2v3SAAAoAOxPT769++voUOHBu0bMmSIzpw50+LxbrdbcXFxQRsAAOi8bI+P8ePH69ixY0H7jh8/rjvvvNPupQAAQASyPT4KCgp08OBBrVmzRidPntTWrVv1xhtvKC8vz+6lAABABLI9PkaNGqUdO3Zo27ZtGj58uFavXq3i4mLNnj3b7qUAAEAEsv1zPiTpwQcf1IMPPhiKuwYAABGO73YBAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjAp5fLz44otyOBzKz88P9VIAACAChDQ+jhw5otdff1333HNPKJcBAAARJGTx0dDQoNmzZ+vNN99Ur169QrUMAACIMCGLj7y8PE2dOlXZ2dk3PM7n88nr9QZtAACg83KG4k7feecdVVVV6ciRIzc91uPxaOXKlaEYAwAAdEC2P/NRW1urRYsWacuWLerWrdtNjy8qKlJ9fX1gq62ttXskAADQgdj+zEdlZaXq6up03333BfY1NzervLxcr732mnw+n6KiogLXud1uud1uu8cAAAAdlO3xMWnSJH300UdB++bOnau7775bzzzzTFB4AACA24/t8REbG6vhw4cH7evevbsSExOv2Q8AAG4/fMIpAAAwKiTvdvmqvXv3mlgGAABEAJ75AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIxyhnsAIBL9aPfxcI8AABGLZz4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMsj0+PB6PRo0apdjYWPXt21czZszQsWPH7F4GAABEKNvjY9++fcrLy9PBgwe1e/duXb16Vd/61rfU2Nho91IAACACOe2+w127dgVd3rx5s/r27avKykpNmDDB7uUAAECEsT0+vqq+vl6SlJCQ0OL1Pp9PPp8vcNnr9YZ6JAAAEEYhjQ+/36/8/HyNHz9ew4cPb/EYj8ejlStXhnKMID/afTzw54Jv3mVsXQAAwmaPJ/jyxKLwzPH/hfTdLnl5efr444/1zjvvXPeYoqIi1dfXB7ba2tpQjgQAAMIsZM98LFiwQDt37lR5ebkGDBhw3ePcbrfcbneoxgAAAB2M7fFhWZa+//3va8eOHdq7d6/S09PtXgIAAEQw2+MjLy9PW7du1S9+8QvFxsbq/PnzkqT4+HhFR0fbvRwAAIgwtr/mY8OGDaqvr1dWVpb69+8f2N599127lwIAABEoJKddAAAArofvdgEAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMCll8rF+/XmlpaerWrZvGjBmjw4cPh2opAAAQQUISH++++64KCwu1fPlyVVVVKSMjQ5MnT1ZdXV0olgMAABEkJPHxyiuvaP78+Zo7d66GDh2qjRs3KiYmRps2bQrFcgAAIII47b7DpqYmVVZWqqioKLCvS5cuys7O1oEDB6453ufzyefzBS7X19dLkrxer92jSZKuNDYE/hyqNTq8xivBl2/Xx6Ed/v7v0Vfdtn+v7PbVv6d/j8c4LPj3M4IZ+Hf/y78TlmXd/GDLZp999pklydq/f3/Q/sWLF1ujR4++5vjly5dbktjY2NjY2Ng6wVZbW3vTVrD9mY/WKioqUmFhYeCy3+/X//7v/yoxMVEOhyMka3q9XqWkpKi2tlZxcXEhWeN2wuNpPx5Te/F42o/H1H6R/phalqVLly4pOTn5psfaHh+9e/dWVFSULly4ELT/woULSkpKuuZ4t9stt9sdtK9nz552j9WiuLi4iPwBd1Q8nvbjMbUXj6f9eEztF8mPaXx8/C0dZ/sLTl0ul+6//36VlZUF9vn9fpWVlWns2LF2LwcAACJMSE67FBYWKjc3V5mZmRo9erSKi4vV2NiouXPnhmI5AAAQQUISHzNnztTFixe1bNkynT9/XiNHjtSuXbvUr1+/UCzXam63W8uXL7/mdA/ahsfTfjym9uLxtB+Pqf1up8fUYVm38p4YAAAAe/DdLgAAwCjiAwAAGEV8AAAAo4gPAABg1G0XH+vXr1daWpq6deumMWPG6PDhw+EeKWJ5PB6NGjVKsbGx6tu3r2bMmKFjx46Fe6xO48UXX5TD4VB+fn64R4lon332mR577DElJiYqOjpaI0aMUEVFRbjHiljNzc1aunSp0tPTFR0drYEDB2r16tW39n0eUHl5uaZNm6bk5GQ5HA6VlJQEXW9ZlpYtW6b+/fsrOjpa2dnZOnHiRHiGDaHbKj7effddFRYWavny5aqqqlJGRoYmT56surq6cI8Wkfbt26e8vDwdPHhQu3fv1tWrV/Wtb31LjY2N4R4t4h05ckSvv/667rnnnnCPEtE+//xzjR8/Xl27dtWvfvUr/c///I9++MMfqlevXuEeLWKtXbtWGzZs0GuvvaajR49q7dq1eumll/Tqq6+Ge7SI0NjYqIyMDK1fv77F61966SWtW7dOGzdu1KFDh9S9e3dNnjxZV67c4IsWI5EdXyYXKUaPHm3l5eUFLjc3N1vJycmWx+MJ41SdR11dnSXJ2rdvX7hHiWiXLl2yBg0aZO3evdv6xje+YS1atCjcI0WsZ555xnrggQfCPUanMnXqVGvevHlB+x5++GFr9uzZYZoockmyduzYEbjs9/utpKQk6wc/+EFg3xdffGG53W5r27ZtYZgwdG6bZz6amppUWVmp7OzswL4uXbooOztbBw4cCONknUd9fb0kKSEhIcyTRLa8vDxNnTo16O8q2qa0tFSZmZl65JFH1LdvX91777168803wz1WRBs3bpzKysp0/PhxSdKHH36oDz74QDk5OWGeLPLV1NTo/PnzQf/vx8fHa8yYMZ3u91TYv9XWlD/96U9qbm6+5lNW+/Xrp9///vdhmqrz8Pv9ys/P1/jx4zV8+PBwjxOx3nnnHVVVVenIkSPhHqVT+MMf/qANGzaosLBQ//Zv/6YjR45o4cKFcrlcys3NDfd4EWnJkiXyer26++67FRUVpebmZr3wwguaPXt2uEeLeOfPn5ekFn9PfXldZ3HbxAdCKy8vTx9//LE++OCDcI8SsWpra7Vo0SLt3r1b3bp1C/c4nYLf71dmZqbWrFkjSbr33nv18ccfa+PGjcRHG/3sZz/Tli1btHXrVg0bNkzV1dXKz89XcnIyjylu2W1z2qV3796KiorShQsXgvZfuHBBSUlJYZqqc1iwYIF27typPXv2aMCAAeEeJ2JVVlaqrq5O9913n5xOp5xOp/bt26d169bJ6XSqubk53CNGnP79+2vo0KFB+4YMGaIzZ86EaaLIt3jxYi1ZskSzZs3SiBEjNGfOHBUUFMjj8YR7tIj35e+i2+H31G0THy6XS/fff7/KysoC+/x+v8rKyjR27NgwTha5LMvSggULtGPHDv3mN79Renp6uEeKaJMmTdJHH32k6urqwJaZmanZs2erurpaUVFR4R4x4owfP/6at38fP35cd955Z5gminyXL19Wly7BvzqioqLk9/vDNFHnkZ6erqSkpKDfU16vV4cOHep0v6duq9MuhYWFys3NVWZmpkaPHq3i4mI1NjZq7ty54R4tIuXl5Wnr1q36xS9+odjY2MA5yfj4eEVHR4d5usgTGxt7zetlunfvrsTERF5H00YFBQUaN26c1qxZo+985zs6fPiw3njjDb3xxhvhHi1iTZs2TS+88IJSU1M1bNgw/e53v9Mrr7yiefPmhXu0iNDQ0KCTJ08GLtfU1Ki6uloJCQlKTU1Vfn6+nn/+eQ0aNEjp6elaunSpkpOTNWPGjPANHQrhfruNaa+++qqVmppquVwua/To0dbBgwfDPVLEktTi9tZbb4V7tE6Dt9q23y9/+Utr+PDhltvttu6++27rjTfeCPdIEc3r9VqLFi2yUlNTrW7dullf+9rXrGeffdby+XzhHi0i7Nmzp8V/N3Nzcy3L+tvbbZcuXWr169fPcrvd1qRJk6xjx46Fd+gQcFgWH0sHAADMuW1e8wEAADoG4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYNT/AwSepLhf4sd+AAAAAElFTkSuQmCC","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["\n","# plot the various values of V to visually inspect if they contain information about the different bits\n","feature_network = SkipConnectionSupervenientFeatureNetwork(\n","    num_atoms=config['num_atoms'],\n","    feature_size=config['feature_size'],\n","    hidden_sizes=config['feature_hidden_sizes'],\n","    include_bias=config['bias']\n","    ).to(device)\n","\n","# load /vol/bitbucket/dm2223/info-theory-experiments/models/feature_network_apricot-pond-70.pth\n","\n","feature_network.load_state_dict(torch.load('/vol/bitbucket/dm2223/info-theory-experiments/models/feature_network_apricot-pond-70.pth'))\n","\n","binary_numbers = torch.tensor([[int(bit) for bit in f\"{i:06b}\"] for i in range(2**6)])\n","\n","v = feature_network(binary_numbers.float().to(device))\n","\n","xor_bits = (reduce(binary_numbers[:, :5], 'b n -> b', 'sum') % 2).unsqueeze(1)\n","\n","# plot the different values of v on a histogram, with different colors for the two different xor bits\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","v_np = v.detach().cpu().numpy()\n","xor_bits_np = xor_bits.cpu().numpy()\n","\n","plt.hist(v_np[xor_bits_np == 0], bins=100, alpha=0.5, label='xor_bit=0')\n","plt.hist(v_np[xor_bits_np == 1], bins=100, alpha=0.5, label='xor_bit=1')\n","plt.legend()\n","plt.show()\n","\n","\n","extra_bits = binary_numbers[:, -1].unsqueeze(1)\n","\n","# plot the different values of v on a histogram, with different colors for the two different extra bits\n","\n","\n","plt.hist(v_np[extra_bits == 0], bins=100, alpha=0.5, label='extra_bit=0')\n","plt.hist(v_np[extra_bits == 1], bins=100, alpha=0.5, label='extra_bit=1')\n","plt.legend()\n","plt.show()\n","\n","\n","bonus_bits = ( xor_bits + extra_bits ) % 2\n","\n","# plot the different values of v on a histogram, with different colors for the two different bonus bits\n","\n","\n","plt.hist(v_np[bonus_bits == 0], bins=100, alpha=0.5, label='bonus_bit=0')\n","plt.hist(v_np[bonus_bits == 1], bins=100, alpha=0.5, label='bonus_bit=1')\n","plt.legend()\n","plt.show()\n","\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1.4933602809906006\n"]}],"source":["bits = torch.tensor([1,0,0,0,0,1]).unsqueeze(0).to(device).float()\n","\n","v = feature_network(bits)\n","\n","print(v.item())"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'v_np' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplots_adjust(hspace\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(\u001b[43mv_np\u001b[49m, np\u001b[38;5;241m.\u001b[39mzeros_like(v_np), c\u001b[38;5;241m=\u001b[39mxor_bits_np, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrRd\u001b[39m\u001b[38;5;124m'\u001b[39m, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)\n\u001b[1;32m     15\u001b[0m plt\u001b[38;5;241m.\u001b[39maxhline(y\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mxticks(rotation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m45\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'v_np' is not defined"]},{"data":{"image/png":"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","text/plain":["<Figure size 1000x400 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Assuming you have the following variables defined:\n","# v_np: numpy array of values\n","# xor_bits_np: numpy array of XOR bits\n","# extra_bits: numpy array of extra bits\n","# bonus_bits: numpy array of bonus bits\n","\n","plt.figure(figsize=(10, 4))\n","plt.subplots_adjust(hspace=0.5)\n","\n","plt.subplot(3, 1, 1)\n","plt.scatter(v_np, np.zeros_like(v_np), c=xor_bits_np, cmap='OrRd', s=100, alpha=0.3)\n","plt.axhline(y=0, color='black', linewidth=0.5)\n","plt.xticks(rotation=45)\n","plt.gca().yaxis.set_visible(False)\n","plt.title('XOR Bits')\n","\n","plt.subplot(3, 1, 2)\n","plt.scatter(v_np, np.zeros_like(v_np), c=extra_bits, cmap='coolwarm', s=100, alpha=0.3)\n","plt.axhline(y=0, color='black', linewidth=0.5)\n","plt.xticks(rotation=45)\n","plt.gca().yaxis.set_visible(False)\n","plt.title('Extra Bits')\n","\n","plt.subplot(3, 1, 3)\n","plt.scatter(v_np, np.zeros_like(v_np), c=bonus_bits, cmap='coolwarm', s=100, alpha=0.3)\n","plt.axhline(y=0, color='black', linewidth=0.5)\n","plt.xticks(rotation=45)\n","plt.gca().yaxis.set_visible(False)\n","plt.title('Bonus Bits')\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","for batch in trainloader:\n","    x0 = batch[:, 0].to(device).float()\n","    x1 = batch[:, 1].to(device).float()\n","\n","    v0_B = feature_network(x0).squeeze()\n","    xor_bits = reduce(x0[: , :5], 'b n -> b', 'sum') % 2\n","    extra_bits = x0[:, -1]\n","    \n","    break\n","\n","\n","from tabulate import tabulate\n","\n","# Assuming v0, xor_bits, and extra_bits are already defined as PyTorch tensors\n","\n","# Convert the tensors to Python lists\n","v0_list = v0_B.tolist()\n","xor_bits_list = xor_bits.tolist()\n","extra_bits_list = extra_bits.tolist()\n","# Create a list of lists containing the values at each index\n","table_data = [[i, round(v0_list[i],3), xor_bits_list[i], extra_bits_list[i]] for i in range(len(v0_list))]\n","# Define the table headers\n","headers = [\"Index\", \"v0\", \"xor_bits\", \"extra_bits\"]\n","# Print the table using tabulate\n","print(tabulate(table_data, headers, tablefmt=\"grid\"))\n","\n","\n","# plot v0_list histogram\n","import matplotlib.pyplot as plt\n","plt.hist(v0_list, bins=100)\n","plt.xlabel('v0')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# find the mutual informatoin between v0 abd v1\n","\n","critic = GeneralSmileMIEstimator(\n","    x_dim=config['feature_size'],\n","    y_dim=config['feature_size'],\n","    critic_output_size=config['critic_output_size'],\n","    x_critics_hidden_sizes=[512, 512, 128],\n","    y_critics_hidden_sizes=[512, 512, 128],\n","    clip=config['clip'],\n","    include_bias=config['bias']\n",").to(device)\n","\n","critic_optimizer = torch.optim.Adam(\n","    critic.parameters(),\n","    lr=config[\"decoupled_critic_lr\"],\n","    weight_decay=config[\"weight_decay\"]\n",")\n","\n","for _ in range(10):\n","    for batch in trainloader:\n","        x0 = batch[:, 0].to(device).float()\n","        x1 = batch[:, 1].to(device).float()\n","\n","        v0_B = feature_network(x0)\n","        v1_B = feature_network(x1)\n","\n","        critic_optimizer.zero_grad()\n","        MI = critic(v0_B, v1_B)\n","        loss = -MI\n","        loss.backward()\n","        critic_optimizer.step()\n","\n","        print(MI.item())\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# predict the extra_bit_0 from v0\n","\n","class MLP(torch.nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        self.fc1 = torch.nn.Linear(config['feature_size'], 128)\n","        self.fc2 = torch.nn.Linear(128, 128)\n","        self.fc3 = torch.nn.Linear(128, 1)\n","        self.relu = torch.nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.relu(self.fc1(x))\n","        x = self.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","mlp = MLP().to(device)\n","\n","mlp_optimizer = torch.optim.Adam(\n","    mlp.parameters(),\n","    lr=config[\"decoupled_critic_lr\"],\n","    weight_decay=config[\"weight_decay\"]\n",")\n","\n","accuracies = []\n","\n","import matplotlib.pyplot as plt\n","\n","for _ in range(6):\n","    for batch in trainloader:\n","        x0 = batch[:, 0].to(device).float()\n","        # x1 = batch[:, 1].to(device).float()\n","\n","        v0_B = feature_network(x0)\n","        extra_bit_0 = x0[:, -1].unsqueeze(1)\n","\n","        mlp_optimizer.zero_grad()\n","        extra_bit_pred = mlp(v0_B)\n","        loss = torch.nn.functional.mse_loss(extra_bit_pred, extra_bit_0)\n","        loss.backward()\n","        mlp_optimizer.step()\n","\n","        print(loss.item())\n","\n","        # accuracy\n","        correct = (torch.round(extra_bit_pred) == extra_bit_0).sum().item()\n","\n","        print(correct / len(extra_bit_0))\n","\n","        accuracies.append(correct / len(extra_bit_0))\n","\n","plt.plot(accuracies)\n","plt.xlabel('batch')\n","plt.ylabel('accuracy')\n","plt.title('Extra Bit Prediction Accuracy')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# predict the xor_bit_0 from v0\n","\n","mlp = MLP().to(device)\n","\n","mlp_optimizer = torch.optim.Adam(\n","    mlp.parameters(),\n","    lr=config[\"decoupled_critic_lr\"],\n","    weight_decay=config[\"weight_decay\"]\n",")\n","for _ in range(5):\n","    for batch in trainloader:\n","        x0 = batch[:, 0].to(device).float()\n","        x1 = batch[:, 1].to(device).float()\n","\n","        v0_B = feature_network(x0)\n","        xor_bits = (reduce(x0[: , :5], 'b n -> b', 'sum') % 2).unsqueeze(1)\n","\n","        mlp_optimizer.zero_grad()\n","        xor_bits_pred = mlp(v0_B)\n","        loss = torch.nn.functional.mse_loss(xor_bits_pred, xor_bits)\n","        loss.backward()\n","        mlp_optimizer.step()\n","\n","        print(loss.item())\n","\n","        # accuracy\n","        correct = (torch.round(xor_bits_pred) == xor_bits).sum().item()\n","\n","        print(correct / len(xor_bits))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# find the mutual informatoin between v1 and xor_bits_1\n","\n","critic = GeneralSmileMIEstimator(\n","    x_dim=config['feature_size'],\n","    y_dim=1,\n","    critic_output_size=config['critic_output_size'],\n","    x_critics_hidden_sizes=[1024, 1024, 1024, 512],\n","    y_critics_hidden_sizes=[1024, 1024, 1024, 512],\n","    clip=config['clip'],\n","    include_bias=config['bias']\n",").to(device)\n","\n","critic_optimizer = torch.optim.Adam(\n","    critic.parameters(),\n","    lr=config[\"decoupled_critic_lr\"],\n","    weight_decay=config[\"weight_decay\"]\n",")\n","\n","\n","for batch in trainloader:\n","    # x0 = batch[:, 0].to(device).float()\n","    x1 = batch[:, 1].to(device).float()\n","\n","    v1_B = feature_network(x1)\n","    xor_bits_1 = (reduce(x1[: , :5], 'b n -> b', 'sum') % 2).unsqueeze(1)\n","\n","    critic_optimizer.zero_grad()\n","    MI = critic(v1_B, xor_bits_1)\n","    loss = -MI\n","    loss.backward()\n","    critic_optimizer.step()\n","\n","    print(MI.item())\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# predict extra_bit_1 from v1\n","\n","mlp = MLP().to(device)\n","\n","mlp_optimizer = torch.optim.Adam(\n","    mlp.parameters(),\n","    lr=config[\"decoupled_critic_lr\"],\n","    weight_decay=config[\"weight_decay\"]\n",")\n","\n","for _ in range(5):\n","    for batch in trainloader:\n","        x0 = batch[:, 0].to(device).float()\n","        x1 = batch[:, 1].to(device).float()\n","\n","        v1_B = feature_network(x1)\n","        extra_bit_1 = x1[:, -1].unsqueeze(1)\n","\n","        mlp_optimizer.zero_grad()\n","        extra_bit_pred = mlp(v1_B)\n","        loss = torch.nn.functional.mse_loss(extra_bit_pred, extra_bit_1)\n","        loss.backward()\n","        mlp_optimizer.step()\n","\n","        print(loss.item())\n","\n","        # accuracy\n","        correct = (torch.round(extra_bit_pred) == extra_bit_1).sum().item()\n","\n","        print(correct / len(extra_bit_1))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# predict the bonus bit from v0\n","\n","mlp = MLP().to(device)\n","\n","mlp_optimizer = torch.optim.Adam(\n","    mlp.parameters(),\n","    lr=config[\"decoupled_critic_lr\"],\n","    weight_decay=config[\"weight_decay\"]\n",")\n","for _ in range(3):\n","    for batch in trainloader:\n","        x0 = batch[:, 0].to(device).float()\n","        x1 = batch[:, 1].to(device).float()\n","\n","        v0_B = feature_network(x0)\n","        xor_bits = (reduce(x0[: , :5], 'b n -> b', 'sum') % 2).unsqueeze(1)\n","        extra_bit = x0[:, -1].unsqueeze(1)\n","        bonus_bit = ( xor_bits + extra_bit ) % 2\n","\n","        mlp_optimizer.zero_grad()\n","        bonus_bit_pred = mlp(v0_B)\n","        loss = torch.nn.functional.mse_loss(bonus_bit_pred, bonus_bit)\n","        loss.backward()\n","        mlp_optimizer.step()\n","\n","        print(loss.item())\n","\n","        # accuracy\n","        correct = (torch.round(bonus_bit_pred) == bonus_bit).sum().item()\n","\n","        print(correct / len(bonus_bit))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# find the mutual information between extra bit and xor bit\n","\n","critic = GeneralSmileMIEstimator(\n","    x_dim=1,\n","    y_dim=1,\n","    critic_output_size=config['critic_output_size'],\n","    x_critics_hidden_sizes=[1024, 1024, 1024, 512],\n","    y_critics_hidden_sizes=[1024, 1024, 1024, 512],\n","    clip=config['clip'],\n","    include_bias=config['bias']\n",").to(device)\n","\n","critic_optimizer = torch.optim.Adam(\n","    critic.parameters(),\n","    lr=config[\"decoupled_critic_lr\"],\n","    weight_decay=config[\"weight_decay\"]\n",")\n","\n","for _ in range(3):\n","    for batch in trainloader:\n","        x0 = batch[:, 0].to(device).float()\n","        x1 = batch[:, 1].to(device).float()\n","\n","        xor_bits = (reduce(x0[: , :5], 'b n -> b', 'sum') % 2).unsqueeze(1)\n","        extra_bit = x0[:, -1].unsqueeze(1)\n","\n","        critic_optimizer.zero_grad()\n","        MI = critic(xor_bits, extra_bit)\n","        loss = -MI\n","        loss.backward()\n","        critic_optimizer.step()\n","\n","        print(MI.item())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# find MI between adjacent XOR bits\n","\n","critic = GeneralSmileMIEstimator(\n","    x_dim=1,\n","    y_dim=1,\n","    critic_output_size=config['critic_output_size'],\n","    x_critics_hidden_sizes=[1024, 1024, 1024, 512],\n","    y_critics_hidden_sizes=[1024, 1024, 1024, 512],\n","    clip=config['clip'],\n","    include_bias=config['bias']\n",").to(device)\n","\n","critic_optimizer = torch.optim.Adam(\n","    critic.parameters(),\n","    lr=config[\"decoupled_critic_lr\"],\n","    weight_decay=config[\"weight_decay\"]\n",")\n","\n","for _ in range(3):\n","    for batch in trainloader:\n","        x0 = batch[:, 0].to(device).float()\n","        x1 = batch[:, 1].to(device).float()\n","\n","        xor_bit0 = (reduce(x0[: , :5], 'b n -> b', 'sum') % 2).unsqueeze(1)\n","        xor_bit1 = (reduce(x1[: , :5], 'b n -> b', 'sum') % 2).unsqueeze(1)\n","\n","        critic_optimizer.zero_grad()\n","        MI = critic(xor_bit0, xor_bit1)\n","        loss = -MI\n","        loss.backward()\n","        critic_optimizer.step()\n","\n","        print(MI.item())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# find MI between v0 and extra_bit_0\n"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":2}
