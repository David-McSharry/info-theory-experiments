{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory set to: /home/ubuntu/info-theory-experiments\n",
      "Added /home/ubuntu/info-theory-experiments to sys.path\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "def setup_project_root(start_path='.'):\n",
    "    \"\"\"Find the project root, set it as the current working directory, and add it to sys.path.\"\"\"\n",
    "    current_path = os.path.abspath(start_path)\n",
    "    while True:\n",
    "        if '.git' in os.listdir(current_path):\n",
    "            project_root = current_path\n",
    "            break\n",
    "        parent_path = os.path.dirname(current_path)\n",
    "        if parent_path == current_path:  # We've reached the root directory\n",
    "            raise Exception(\"Could not find project root (.git directory not found)\")\n",
    "        current_path = parent_path\n",
    "    \n",
    "    # Change the current working directory to the project root\n",
    "    os.chdir(project_root)\n",
    "    print(f\"Current working directory set to: {os.getcwd()}\")\n",
    "\n",
    "    # Add project root to sys.path if it's not already there\n",
    "    if project_root not in sys.path:\n",
    "        sys.path.insert(0, project_root)\n",
    "        print(f\"Added {project_root} to sys.path\")\n",
    "\n",
    "# sets the current working directory to the project root\n",
    "setup_project_root()\n",
    "\n",
    "# Don't cache imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Decoder Loss: 0.8615, Encoder Loss: 0.8605, MI: 1.7582\n",
      "Epoch [2/3], Decoder Loss: 0.8340, Encoder Loss: 0.8330, MI: 1.6298\n",
      "Epoch [3/3], Decoder Loss: 0.8259, Encoder Loss: 0.8251, MI: 1.8415\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from info_theory_experiments.custom_datasets import MegDataset\n",
    "from info_theory_experiments.models import GeneralSmileMIEstimator\n",
    "\n",
    "class MLPEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=116, latent_dim=1):\n",
    "        super(MLPEncoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, latent_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "class MLPDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim=1, output_dim=116):\n",
    "        super(MLPDecoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = MegDataset()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# Initialize the models, loss function, and optimizers\n",
    "encoder = MLPEncoder().to(device)\n",
    "decoder = MLPDecoder().to(device)\n",
    "mse_loss = nn.MSELoss()\n",
    "optimizer_encoder = optim.Adam(encoder.parameters(), lr=1e-4)\n",
    "optimizer_decoder = optim.Adam(decoder.parameters(), lr=1e-3)\n",
    "\n",
    "decoupled_estimator = GeneralSmileMIEstimator(\n",
    "    x_dim=1,\n",
    "    y_dim=1,\n",
    "    critic_output_size=32,\n",
    "    x_critics_hidden_sizes=[256, 256],\n",
    "    y_critics_hidden_sizes=[256, 256],\n",
    "    clip=5,\n",
    "    include_bias=True,\n",
    ").to(device)\n",
    "\n",
    "decoupled_optimizer = optim.Adam(decoupled_estimator.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    total_decoder_loss = 0\n",
    "    total_encoder_loss = 0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data0 = data[:, 0].to(device)\n",
    "        data1 = data[:, 1].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        data1_pred = decoder(encoder(data0))\n",
    "\n",
    "        # Decoder loss (minimize MSE)\n",
    "        decoder_loss = mse_loss(data1_pred, data1)\n",
    "\n",
    "        # Update decoder\n",
    "        if batch_idx % 1 == 0:\n",
    "            optimizer_decoder.zero_grad()\n",
    "            decoder_loss.backward()\n",
    "            optimizer_decoder.step()\n",
    "\n",
    "        # update decoupled estimator\n",
    "        decoupled_optimizer.zero_grad()\n",
    "        v0 = encoder(data0)\n",
    "        v1 = encoder(data1)\n",
    "        mi = decoupled_estimator(v0, v1)\n",
    "        decoupled_loss = -mi # maximize MI\n",
    "        decoupled_loss.backward()\n",
    "        decoupled_optimizer.step()\n",
    "\n",
    "        # Recompute the forward pass for encoder loss\n",
    "        if batch_idx % 1 == 0:\n",
    "            optimizer_encoder.zero_grad()\n",
    "            data1_pred = decoder(encoder(data0))\n",
    "            v0 = encoder(data0)\n",
    "            v1 = encoder(data1)\n",
    "            mi = decoupled_estimator(v0, v1)\n",
    "            encoder_loss = - mse_loss(data1_pred, data1) - 0.1 * mi\n",
    "            # Update encoder\n",
    "            optimizer_encoder.zero_grad()\n",
    "            encoder_loss.backward()\n",
    "            optimizer_encoder.step()\n",
    "        \n",
    "        total_decoder_loss += decoder_loss.item()\n",
    "        total_encoder_loss += encoder_loss.item()\n",
    "    \n",
    "    # Print epoch statistics\n",
    "    avg_decoder_loss = total_decoder_loss / len(train_loader)\n",
    "    avg_encoder_loss = total_encoder_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Decoder Loss: {avg_decoder_loss:.4f}, Encoder Loss: {avg_encoder_loss:.4f}, MI: {mi.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Average Loss: 0.8234\n",
      "Epoch [2/2], Average Loss: 0.8155\n",
      "Decoder training completed.\n",
      "Test Loss: 0.8014\n"
     ]
    }
   ],
   "source": [
    "# Train decoder with MSE loss using the trained encoder\n",
    "\n",
    "# Freeze encoder parameters\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Initialize decoder (using the MLPDecoder class from the notebook)\n",
    "decoder = MLPDecoder(latent_dim=encoder.latent_dim, output_dim=116).to(device)\n",
    "\n",
    "# Define optimizer for decoder\n",
    "optimizer_decoder = optim.Adam(decoder.parameters(), lr=1e-3)\n",
    "\n",
    "# Define loss function\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "num_epochs = 2  # Adjust as needed\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data0 = data[:, 0].to(device)\n",
    "        data1 = data[:, 1].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            encoded = encoder(data0)\n",
    "        decoded = decoder(encoded)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = mse_loss(decoded, data1)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer_decoder.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_decoder.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Print epoch statistics\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "# Unfreeze encoder parameters (if needed for future use)\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "print(\"Decoder training completed.\")\n",
    "\n",
    "# Optionally, you can evaluate the model here\n",
    "# For example:\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "with torch.no_grad():\n",
    "    test_data = next(iter(train_loader))\n",
    "    test_input = test_data[:, 0].to(device)\n",
    "    test_target = test_data[:, 1].to(device)\n",
    "    encoded = encoder(test_input)\n",
    "    reconstructed = decoder(encoded)\n",
    "    test_loss = mse_loss(reconstructed, test_target)\n",
    "    print(f\"Test Loss: {test_loss.item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:0vbouhyi) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Psi</td><td>█▅▅▄▃▄▂▃▅▄▃▂▄▅▄▅▄▄▃▄▁▄▃▂▃▄▅▃▃▄▂▄▃▅▅▂▃▆▄▃</td></tr><tr><td>decoupled_MI</td><td>▁▁▂▃▄▄▄▅▆▆▆▆▇▆▇▆▇▆▆▇▇█▆▇█▇▆▇▇▆▆▇█▇▆▇▇▅▇▇</td></tr><tr><td>downward_MI_0</td><td>▄▄▅▆▆▅▅▅▅▇▅▄▇▄▄▅▆██▅▇▆▅█▇▅▆▆▆▆▆▅▇▅▆▇▁▄▆▅</td></tr><tr><td>downward_MI_1</td><td>▁▃▆▆▅▅▅▅▇▆▅▇▆▆▃▅▆▆▅▆▅▆▆▅▅▅▅▆▇▇▅▅▅▅▁█▄▅▆▅</td></tr><tr><td>downward_MI_10</td><td>▄▄▄▄▆▆▅▅▅▇▅▄▇▅▄▃▅▇▆▄▆▁▆▅▄▅▄▃█▅▆▅▄▄▆▃█▅▅▃</td></tr><tr><td>downward_MI_100</td><td>▂▂▃▅▆▇▅▃▂▆▆▅▆▃▁▆▆▇█▄▅▄▆▆▁▁▅▅▄▅▆▇█▅▅▅▄▃▇▆</td></tr><tr><td>downward_MI_101</td><td>▂▃▆▃▅▆▃▁▁▆▆▅▆▃▃▇▅▄▇▅▄▅▅▇▅▆▆▅▅▄▇▆▆▅▅▇▄▄█▆</td></tr><tr><td>downward_MI_102</td><td>▁▂▂▂▅▆▄▄▄▇▇▇▄▄▄▃▅▃▅▄▅▄▆▅▅▂▂▄▄▆▅█▇▂▃█▇▃▄▄</td></tr><tr><td>downward_MI_103</td><td>▁▁▃▅▇▅▅█▄█▃▆▄▄▄▅▆▅▇▆▆▇▇█▅▁▂▆▅▃▇▇█▃▅█▅▄▇▇</td></tr><tr><td>downward_MI_104</td><td>▃▄▄▁▄▅▅▂▄▅▇▄▇▄▄▄▅▄▅▄▄▄▅▅▆▇▇▅█▄█▃▇▆▃▆▄▄▆▇</td></tr><tr><td>downward_MI_105</td><td>▁▂▃▂▅▆▆▃▁▅▇▆▂▂▃▅▅▃▆▅▆▆▆▇▃▄▅▂▆▅▇█▆▅▅▆▄▃█▄</td></tr><tr><td>downward_MI_106</td><td>▁▂▂▄▅▆▅▄▁▆▇▅▃▅▅▄▅▃▆▅▆▆▆▆▄▄▆▅▅▅▅▇▅▄▅▆▄▃█▃</td></tr><tr><td>downward_MI_107</td><td>▁▃▃▃▄▆▆▄▂▁▄▆▅▅▄▄▃▃▄▃▅▅█▅▃▂▇▄▂▃▇▇▄▂▃█▄▂▄▄</td></tr><tr><td>downward_MI_108</td><td>▁▃▄▅▆▄▄▄▄▆▄▄▅▃▃▄▆█▇▅▇▅▄█▆▅▄▄▆▇▆▄▇▄▄▅▁▄▄▅</td></tr><tr><td>downward_MI_109</td><td>▁▃▃▅▅▂▆▄▄▅▆▇▅▂▅▅▅▅▇▆▆▅▄█▇▃▆▆▄▅▅▆█▆▅▆▅▄▅▆</td></tr><tr><td>downward_MI_11</td><td>▂▂▂▂▆▅▅▄▄▄▃▂▅▅▂▂▃█▅▃▃▂▂▅▂▄▁▅▆▄▃▃▂▃▂▂▅▃▃▁</td></tr><tr><td>downward_MI_110</td><td>▂▂▃▃▄▅▃▄▂▄▂▃▅▂▃▁▃▄▃▂▆▃▅█▅▂▃▅▅▄▆▄▂▂▄▄▄▂▂▂</td></tr><tr><td>downward_MI_111</td><td>▄▅▅▅▅▅▅█▄▆▅▇▆▅▄▁▆▇▅▃▆▆▄█▅▅▄▆▇▆▅▅▅▄▅▇▇▆▅▅</td></tr><tr><td>downward_MI_112</td><td>▁▄▃▅▅▃▄▅▆▄▅█▅▁▆▅▅▅▅▅▄▅▅▆▃▄▂▅▄▅▅▅▂▄▅▅▅▅▆▆</td></tr><tr><td>downward_MI_113</td><td>▁▃▃▄▅▁▆▄▄▄▅█▅▁▃▃▅▄█▄▇▅▃█▇▄▃▅▆▆▅▄▇▁▄▅▇▃▃▅</td></tr><tr><td>downward_MI_114</td><td>▃▅▄▅▅▂▅▅▅▅▆█▅▁▅▄▅▆▇▅█▆▅█▇▅▅▅▆▇▆▅▇▄▅▇▇▅▄▆</td></tr><tr><td>downward_MI_115</td><td>▁▆▇▆▃▄▆█▅▅▆█▆▄▇▅▆█▆▅▅▆▆█▆▆▄▇▆▅▆▅▇▅▆█▆▅▅▇</td></tr><tr><td>downward_MI_12</td><td>▃▅▆▄▅▆▇▆▅▇▇▄▅▄▅▅▆▄▅▆█▁▆▆▅▆▆▆▅▇▅▆▅▂▆▆▇▅▆▅</td></tr><tr><td>downward_MI_13</td><td>▂▂▂▂▃▃▂▂▂▁▂▂▃▂▃▂█▂▂▂▂▃▂▃▂▁▂▂▂▃▂▂▃▂▂▃▂▂▅▃</td></tr><tr><td>downward_MI_14</td><td>▂▃▃▂▃▁▅▅▄▁▃▄▁▆▅▃▃▄▃▃▄▄▃▄▄▅▄▅▄▄▄▃▂▄▂▄▄▃▅█</td></tr><tr><td>downward_MI_15</td><td>▄▄▄▅▅▇▄▅▅▄▅▅▇▅▃▃▄▅▅▃▅▅▅▇▆▅▄█▇▄▆▁▁▄▆▅▅▄▆▄</td></tr><tr><td>downward_MI_16</td><td>▄▅▆▅▆▅▇▆▆█▅▄▅▂▅▅▆▅▅▆▇▄▅▅▆▅▅▇▆▆▄▅▁▅█▆▇▆▆▅</td></tr><tr><td>downward_MI_17</td><td>▄▄▄▄▄▄▄▄▅▄▃▄▄▃▅▄█▄▄▄▇▄▅▆▆▁▄▄▅▄▆▄▄▅▄▂▄▄▄▄</td></tr><tr><td>downward_MI_18</td><td>▃▃▃▄▅▄▃▃▃▄▃▃▃▂▃▃▆▅▄▄▃▄▃▃▁▄▄▄▄▆▃▃▅▃▃▄▄▃▆█</td></tr><tr><td>downward_MI_19</td><td>▅▅▆▁▅▃▆▅▅▅▆▆▆▆▆▅▅▆▄▇▆▆▅▆▆▅▅▅█▄▆▅▆▅▅▅▅▇▅▆</td></tr><tr><td>downward_MI_2</td><td>▁▂▄▂▂▂▂█▅▃▅▄█▂▃▁▄▅▇▂▅▃▄▃▄▆▃█▄▃▄▃▅▃▂▆▆▃▄▂</td></tr><tr><td>downward_MI_20</td><td>▄▅▄▅▅▅▆▆▅▁▅▅▄▅▆▄▇▅▅▅█▆▅▇▆▅▅▅▇▅▄▅▅▅▅▄▅▅▅▆</td></tr><tr><td>downward_MI_21</td><td>▂▄▁▃▅▆▅▄▃▂▆▄▆▄▃▂▅▇▆▃▇▄▁█▄▅▂▅▅█▃▄▆▃▃▅▅▃▃▅</td></tr><tr><td>downward_MI_22</td><td>▃▃▂▄▆▁▃▆▃▃█▆▄▃▆▃█▄▄▄▆▃▄▃▃▂▄▁▅▅▂▄▂▄▅▄▁▂▄▆</td></tr><tr><td>downward_MI_23</td><td>▆▆▇▄▇▆▇▆▆▇▆▆▅▆▆▆▇▅▄▆▆▆▆▇▆▆▅▆█▇▅▆▁▅█▅▆▆▇▇</td></tr><tr><td>downward_MI_24</td><td>▂▃▃▃█▂▄▅▃▂▄▄▆▄▃▃▅▇▇▅▄▆▃▇▆▅▄▁▄▇▇▁▇▄▃▆▆▄▃▅</td></tr><tr><td>downward_MI_25</td><td>▃▅▃▃▅▁▄▄▃▃▅▇▆▂▅▃▄▄▅▄█▅▄█▅▅▄▅▅▆▇▃▇▄▄█▆▄▃▆</td></tr><tr><td>downward_MI_26</td><td>▂▅▅▅▄▄▄▆▅▅▅█▅▁▅▅▆▅▆▅▅▅▆▅▅▅▅▅▅▆▆▄▆▅▆▅▅▆▆▆</td></tr><tr><td>downward_MI_27</td><td>▂▃▄▃▂▁▄▅▃▅▅█▄▃▇▃▅▃▅▃▅▂▅▅▃▄▄▄▁▅█▄▄▂▅▅▅▃▃▃</td></tr><tr><td>downward_MI_28</td><td>▂▃▅▁▄▂▆▆▅▁▄▅▂▅▅▄▃▄▅▄▂▅▄▄▆▆▆▆▅▅▄▃▄▅▃▆▅▄▆█</td></tr><tr><td>downward_MI_29</td><td>▃▄▄▁▄▄▅▄▅▅▄▇▄▆▇▄▄▅▅▄█▅▄▄▅▄▅▅▄▄▃▄▄▇▅▆▃▄▆█</td></tr><tr><td>downward_MI_3</td><td>▁▇▇▇▇▇▇▇▇▇█▇▅█▇▇▇█▇▇▇▇▇█▇█▇▇▇▇▇▇▇▆▇▆▇▇▇▇</td></tr><tr><td>downward_MI_30</td><td>▄▅▄▅▇▆▄▅▆▁█▇▇▄▆▅▃▆▅▆▅▃▅▆▄▂▂▅▅▅█▄▇▅▅▄▇▆▆█</td></tr><tr><td>downward_MI_31</td><td>▂▁▂▄▃▁▅▅▅▃█▄▅▂▇▄▄▂▄▃▂▃▄▄▅▂▄▆▃▃▅▅▅▄▄█▅▃▄▆</td></tr><tr><td>downward_MI_32</td><td>▁▃▄▄▄█▃▃▄▆▁▁▅▄▃▃▄▇▆▄▄▃▅▄▄▆▄▄▅▅▄▄▃▄▅▅▂▃▄▃</td></tr><tr><td>downward_MI_33</td><td>▄▅▄▅▆▄▅▅▆▆▆▅▅▆▅▄▅▅▅▆▅▆▅▅▆▆▅▅█▅▅▅▄▅▅▁▅▅▅▄</td></tr><tr><td>downward_MI_34</td><td>▄▅▄▆▅▃▄▇▅▄▆█▅▁▅▅▅▄▆▅▆▄▅█▇▆▅▇▆▇▇▄█▅▅▇▆▅▄▆</td></tr><tr><td>downward_MI_35</td><td>▄▅▅▄▄▄▇▄█▆▇▅▆▆▅▄▆▇▄▇▇█▄▇▇█▅▁█▆▇▄▇▄▆▄█▆▆▅</td></tr><tr><td>downward_MI_36</td><td>▁▃▂▆▄▂▅▆▇▄▅▆▅▃█▅▃▅▅▄▇▄▅▅▇▅▆▆▇▃▆▆▅▅▄▆▄▄▆█</td></tr><tr><td>downward_MI_37</td><td>▁▃▄▃▆▂▄▄▂▄▄▂▅▃▃▃▄█▆▅▄█▃▃▆▄▄▆▃▆▅▁▇▄▄▆▄▃▃▅</td></tr><tr><td>downward_MI_38</td><td>▂▂▃▃▄▃▂▃▃▃▃▂▁▂▂▂▂▃▃▁▂▂▃▃▂▃▃▃▄▃█▂▁▃▃▂▂▃▂▂</td></tr><tr><td>downward_MI_39</td><td>▄▃▃▃▄▄█▅▂▂▃▄▂▆▄▄▃▄▄▄▃▄▄▄▄▄▄▄▅▄▁▇▅▄▄▅▃▄▅▄</td></tr><tr><td>downward_MI_4</td><td>▁▄▄▄▃▄▄▄▆▄▅▄▄▅▃▄▁▆▄▄▅▄▄▃▄▄▄▆▄▅▅▃█▄▄▃▄▃▃▃</td></tr><tr><td>downward_MI_40</td><td>▁▄▄▅▄▃▃▃▅▅▄▄▄▃▄▄▄▆▅▅▃▄▄▄▄▄▄▄█▄▄▅▁▄▅▃▅▄▅▄</td></tr><tr><td>downward_MI_41</td><td>▁▅▅▆▆▃▅▇▆▅▆▆▇▄▆▅▅▅▇▆▆▆▆▇▆▆▆▆▅▇▅▆█▆▆█▇▅▆▆</td></tr><tr><td>downward_MI_42</td><td>▂▃▃▅▄▂▃▇▃▂█▅▄▂▄▃▃▃▅▃▃▃▂▄▅▄▁▄▄▃▄▄▄▃▂▄▃▄▄▄</td></tr><tr><td>downward_MI_43</td><td>▂▄▄▄▂▃▅▇▄▁▆▅▅▄▄▁▅▇▄▂▅▅▄▄▄▃▅▂▃▅▄▂▆█▅▇▆▄▅▅</td></tr><tr><td>downward_MI_44</td><td>▅▅▅▇▄▄▆█▅▅▇▇▃▅▆▅█▃▆▁▅▇▅▅▅▆▅▅▅▇▅▅▆▆▄▃▆▅▇▅</td></tr><tr><td>downward_MI_45</td><td>▂▃▅▃▃▂▁▄▃▄▅█▃▁▅▄▆▃▆▅▃▂▆▄▄▃▁▄▁▃▅▃▄▃▃▄▃▄▄▁</td></tr><tr><td>downward_MI_46</td><td>▃▃▂▅▅▃▇▄▂▃▆▃▄▃▃▂▄▅▄▃▇▃▃█▅▅▂▄▃█▃▂▅▂▃▄▆▁▂▄</td></tr><tr><td>downward_MI_47</td><td>▃▃▂▆▁▃▆▃▃▄▇▅▇▁▄▄▃▂▄▁▇▃▂█▄▆▃▅▂▆▅▃▅▃▅▆█▃▃▃</td></tr><tr><td>downward_MI_48</td><td>▂▃▄▃▄▃▄▄▅▆▃▄▄▆▅▅▁▄▄▄▅▄▄▃▆▄▅▃█▄▅▅▂▃▄▆▆▃▄▅</td></tr><tr><td>downward_MI_49</td><td>▃▄▆▄▃▂█▄▅▆▅▅▁▅▆▄▅█▆▅▇▇▄▅▆▅▆▂▇▃▅▃▆▄▆▄▇▆▆▅</td></tr><tr><td>downward_MI_5</td><td>▁▅▆▄▃▇▄▆▅▃▆▄▇▄▅▃▅▇▄▅▇▇▄▅▅▆▄█▄▃▅▄▇▅▄█▆▆▄▁</td></tr><tr><td>downward_MI_50</td><td>▃▄▄▃▅▄▅▄▅▁▇▇▄▄▅▄▄▆▄█▄▅▁▅▄▇▃▅▄▂▄▅▄▅▅▆▄▅▅▆</td></tr><tr><td>downward_MI_51</td><td>▃▃▄▂▇▁▃▃▅▁▅▃▄▆▃▅▄▇▃▅▄▅▃▄▇▅▅▄█▄▆▅▆▄█▄▅▅▆▅</td></tr><tr><td>downward_MI_52</td><td>▁▅▅▆▄▂▄▅▅▅▆▅▆▄▅▆▅▅▅▇▄▅▅▂█▇▄▇▇▄▅▄▄▅▅▄▄▅▅▅</td></tr><tr><td>downward_MI_53</td><td>▁▆▆▂▇▆▆▅▆▆▆▄█▆▅▅▆▆▆▆▅▆▆▆▆▇▅▇█▆▆▆█▅▇▆▆▄▆▆</td></tr><tr><td>downward_MI_54</td><td>▁▃▄▄▃▇▃▆▄▁▃▃▄▇▂▂▃▆▅▆▄▄▃▅█▆▆▇▃▄▄▅▇▆▄▆▅▄▁▃</td></tr><tr><td>downward_MI_55</td><td>▂▃▆▄▅▁▅▃▄▇▆▄▂▅▃▆▂▂▅▅▆▅▅▆▆▄▅▄▅▅▅▆▂▅▂██▄▅▅</td></tr><tr><td>downward_MI_56</td><td>▁▅▄▄▅▅▅▅▄▄▅▄▅▄▄▅▅▅▅▄▇▄▅▅▅▄▁▅▆▅▅█▅▄▄▄▆▄▅▅</td></tr><tr><td>downward_MI_57</td><td>▁▆▆▅▅▅▆▆▆▆▃▆▆▆▆▆▄▅▆▆▆▆▆▆▆▆▆▅█▆▇▆▇▆▆▄▆▆▆▆</td></tr><tr><td>downward_MI_58</td><td>▄▄▄▆▆▇▇▇▇▆▆▄▅▅▅▅▇▅▆▅▇▆█▇▆▃▆▅▁▄▆▅▆▅▅▅▆▄▆▅</td></tr><tr><td>downward_MI_59</td><td>▂▂▁▄▅▇▆▆▅▅▆▆▃▄▅▅▆▂▃▆▅▆▇▆▆▂▂▅▃▄▇▇█▅▄▆▇▃▄▄</td></tr><tr><td>downward_MI_6</td><td>▃▃▃▃▃▂▃▃▄▅▁▄▄▃▄▄▄▄▆▃▃▅▃▄▃▄▄▃▇▄▄▅▃▄▆▁█▄▃▄</td></tr><tr><td>downward_MI_60</td><td>▁▃▃▅▆▆▄█▆▄▅▄▄▄▆▆▆▂▄▆▇▆▇▇▇▃▃▅▂▁▇▆▅▇▃▅▅▅▄▂</td></tr><tr><td>downward_MI_61</td><td>▆▆▆▇▇▇▇▇▆▇▇▇▇▁▇▇▇▆▆██▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▆▆▆</td></tr><tr><td>downward_MI_62</td><td>▂▃▃▃▆▇▅▄▃▂▄▃▁▆▃█▇▅▄▅▄▇▅▄▄▅▃▆▄▄▆▇█▂▅▆▄▂▃▅</td></tr><tr><td>downward_MI_63</td><td>▂▃▃▃▃▃▆▄▃▅▃▆▆▆▂▃▅▃▃▃▇▆▄▃▅█▆▃▆▆▅▅▅▄▄▅▃▂█▁</td></tr><tr><td>downward_MI_64</td><td>▃▃▃▂▃▂▄▃▃▂▄▂▄▅▄▂▄█▂▁▆▄▅▂▆▄▄▄▃▁▃▅▃▅█▇▃▄▃▇</td></tr><tr><td>downward_MI_65</td><td>▂▄▄▄▄▂▄▂▃▁▄▅▅▃▅▂▄▅▆▅▅▄▅▆▄▄▄▂█▅▅▄▅▅▄▄▆▄▄▄</td></tr><tr><td>downward_MI_66</td><td>▄▅▆▁▃▇▆▇▅▄█▅▆▅▅▆▅█▄▄▅▆▆▄▇▇▅▇▇▃▇█▇▄▃▆▅▆▅▅</td></tr><tr><td>downward_MI_67</td><td>▁▃▃▃▅▅▅▃▃▄▄▆▁▇▄▇▇▄▃▄▆▇▆▃▄▆▃▆▆▅▆▇█▂▄▅▅▃█▄</td></tr><tr><td>downward_MI_68</td><td>▂▂▄▂▃▄▄▅▃▅▄▁▃▇█▂▆▄▂▃▇▄▆▁▅▆▃▄▃▁▄▅▃▂▇█▄▂▃█</td></tr><tr><td>downward_MI_69</td><td>▂▃▄▄▅▅▆▄▅▄▄▅▄▅▃▂▆▃▄▆▆▄▂▅▅▆▅▄▇▅▂▄▆█▆▂▅▄▁▅</td></tr><tr><td>downward_MI_7</td><td>▁▆▅▆▆▂▅▅▅▄▅▃▆▄▄▅▅▆▄▅▅▇▅▃▄█▃▄▅▄▄▄▄▄▄▅▅▆▄▅</td></tr><tr><td>downward_MI_70</td><td>▁▄▄▅▄▅▃▃▃▄▄▆▄▄▄▃▄▄▅▅▅▄▃▆▅▆▃▅█▄▂▄▄▆▄▃▅▄▄▄</td></tr><tr><td>downward_MI_71</td><td>▃▄▃▅▆▇▅▆▄▁▆▅▄▄▇▇▆▅▅▇▇▇▇██▄▃▆▅▄▆▅▆▇▆▄▅▅▅▄</td></tr><tr><td>downward_MI_72</td><td>▄▅▄▅▆▅█▅▅▆▅▇▇▆▁▅▆▃▆▆█▇▆▅▆▇▆▆▃▆▆▆▅▄▆▆▆▂█▆</td></tr><tr><td>downward_MI_73</td><td>▃▃▂▅▄▄▆▅▄▄▅▆▆▃▃▃▄▂▆▃▄▃▆▄▅▅▃█▅▇▄▅▄▁█▇▄▆▂▅</td></tr><tr><td>downward_MI_74</td><td>▂▃▁▅▄▅▂▅▁▅▄▄▄▁▆▅▅▃▃▅█▄▅▅▄▆▅▆▃▄▅▅▄▅▃▅▃▃▄▃</td></tr><tr><td>downward_MI_75</td><td>▂▃▃▃▆▆▅▄▂▆▇▅▆▆▄▅▄▁█▅▅▄▆▇▄▃▅▆▃▄▆▇▃▅▅▆▄▄█▂</td></tr><tr><td>downward_MI_76</td><td>▁▃▃▄▃▃▄▁▄▃▃▄▅▄▆▃▄▄▃▅▆▅▃▅▂▅▃▃█▃▄▄▆▄▃▃▆▃▄▃</td></tr><tr><td>downward_MI_77</td><td>▅▆▅▆▆▇▆▇▆▇▆█▆▆▁▅▇▆▅▇█▆▅▆▆▆▆▇▆▆▅▆▆▇▇▇▆▅▇▇</td></tr><tr><td>downward_MI_78</td><td>▅▅▅▅▆▆▅▄▅▃▅▇▆▅▅▅▂▇▄▇▅▁▅▅▅▅▄▇▆▅▇▅█▅▅▆▅▅▅▆</td></tr><tr><td>downward_MI_79</td><td>▂▂▃▃▅▇▆▁▄▃▄▄▄▃▄▅▃▅▃█▅▇▂▃▃▃▃▄▆▁▂▂▄▆▂▅▃▄▄▆</td></tr><tr><td>downward_MI_8</td><td>▅▆▅▅▅▅▆▅▆▆▇▅▇▆▅▁▇▇▄▇▇█▅▇▆▇▅▅█▆▆▅▅▃▅▄▇▄▇▃</td></tr><tr><td>downward_MI_80</td><td>▂▃▃▁▃▅▇▂▂▃▄▇▃▅▄▅█▆▄▃▇▂▆▄▂▇▃▆▄▇▇▆▂▄▅▅▂▃▆▅</td></tr><tr><td>downward_MI_81</td><td>▁▃▃▂▂▅▂▅▄▃▆▄▅▅▆▄▅▁▃▅▄▄▅▃█▄▂▃▂▃▄▆▅▂▃▄▃▂▄▅</td></tr><tr><td>downward_MI_82</td><td>▄▆▅▅▅▄▅▅▅▅▅▅▅▅█▅▅▅▅▄▅▅▅▇▅▅▅▄▅▅▅▁▄▆▅▅▅▅▆▅</td></tr><tr><td>downward_MI_83</td><td>▅▅▆▅▆▅▅▅▃▂▅▅▆▆▅▅▆▆█▆▆▇▅█▅▅▆▇▇▆▄▆▅▅▆▁▆▆▆▇</td></tr><tr><td>downward_MI_84</td><td>▄▄▅▄▃▄▅▂▄▆▅▄▆▄▆▄▅▄▃▅▆▄▄▄▂▄▅▄▆▃▅▁▅▄▅▇▂▄▃█</td></tr><tr><td>downward_MI_85</td><td>▃▄▂▄▁▆▄▅▂▃▅▄▅▅▃▄▅▅▄▆▅▇▅▆▅▅▄▅▄▄█▄▅▅▆▄▅▄▃▄</td></tr><tr><td>downward_MI_86</td><td>▁▃▅▅▄▄▄▃▆▆▄▄▆▅█▃▄▃▄▅▇▆▄▄▃▆▄▅█▃▅▅▇▄▄▄▇▄▅▃</td></tr><tr><td>downward_MI_87</td><td>▄▆▆▆▄▁▅▅▆▆▆█▅▅▇▇▅▁▇▅▅▄▆▆▇▆▃█▅▆▅▆▆▆▆▅▆▅▅▄</td></tr><tr><td>downward_MI_88</td><td>▃▄▅▄▄▄▆▃█▅▂▄▅▅▅▅▅▅▅▆▆▆▅▆▆▆▅▁▇▄▆▄▆▄▅▆▇▅▅▅</td></tr><tr><td>downward_MI_89</td><td>▂▃▃▂▃▄▆▄▃▄▆▄▂▄▃▃▅▆▂▃▆▆▅▁▆█▃▇▂▄▅▅▄▃▄▆▃▅▃▄</td></tr><tr><td>downward_MI_9</td><td>▃▃▃▄▆▅▃▅▃▅▄▃▅▅▃▂▃█▄▄▃▃▄▅▃▄▁▄▅▄▅▃▁▄▂▁▅▄▃▃</td></tr><tr><td>downward_MI_90</td><td>▃▅▅▅█▆▆▅█▇▅▁▆▅▆▆▇█▆▅▆▇▅▅▆▃▅▅▅▅▅▇▄▃▅▆▅▄▆▆</td></tr><tr><td>downward_MI_91</td><td>▄▄▆▄▅▇▆▄▃▇█▅▆▇▄▁▄▃▇▆▅▅▅▆▃▇▅▅▆▅▇█▅▆▅▅▅▅▇▅</td></tr><tr><td>downward_MI_92</td><td>▃▃▂▆▇█▇▅▇▅▄▁▅▅▇▃▇▅▅▆▆▄▆▆▅▃▅▅▅▄▄▄▅▄▅▅▆▂▅█</td></tr><tr><td>downward_MI_93</td><td>▄▅▅▅▅▆▄▅▅▆▇▅▇▄▃▅▅▆▆▆▅▄▅▇▁▆▅▆█▆▇▄▅▆▆▅▆▅█▇</td></tr><tr><td>downward_MI_94</td><td>▄▄▅▄▇▄▄▃▃▄▆▃▃▄▄▂▄▆▇▄▅▃▆▆▂▄▅▇▅▄▅▅▄▅▄▁▃▅█▆</td></tr><tr><td>downward_MI_95</td><td>▄▅▅▅▅▅▅▆▅▄▅▆▅▅▆▅▅█▅▅▅▅▅▅▆▅▅▄▆▅▅▁▅▆▆▆▅▅▅▅</td></tr><tr><td>downward_MI_96</td><td>▃▄▆▅▅▃▃▄▄▄▅▅▄▄▅▆▆▄▅█▄▄█▄▅▄▁▄▅▅▅▄▄▄▄▆▃▄▂▄</td></tr><tr><td>downward_MI_97</td><td>▁▃▂▃▅▂▄▅▁▃▃▅▄▅▃▃▃▃▆▅▄▁▅▅▅▃▄▅▂▁█▅▃▄▄▄▅▂▃▃</td></tr><tr><td>downward_MI_98</td><td>▁▂▂▃▃▁▄▃▅▇▄▃▁▅▃▅▂▃▄▅▅▅▆▅▅▄▄▁▅▂▄▅▂▆▃█▅▂▄▆</td></tr><tr><td>downward_MI_99</td><td>▂▅▅▅▄▄▄▂▇▆▄▄▃▁▄▄▅▇▅▆█▅▆▇▆█▅▆▇▄▆▄█▆▅▆▆▄▅▆</td></tr><tr><td>sum_downward_MI</td><td>▁▃▃▄▅▅▆▅▅▆▆▇▆▅▆▅▆▆▆▆█▆▆█▇▆▅▆▇▅▇▆▇▅▅▇▆▄▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Psi</td><td>-2.48999</td></tr><tr><td>decoupled_MI</td><td>1.53329</td></tr><tr><td>downward_MI_0</td><td>0.01593</td></tr><tr><td>downward_MI_1</td><td>-0.00601</td></tr><tr><td>downward_MI_10</td><td>0.00441</td></tr><tr><td>downward_MI_100</td><td>0.11409</td></tr><tr><td>downward_MI_101</td><td>0.08233</td></tr><tr><td>downward_MI_102</td><td>0.1627</td></tr><tr><td>downward_MI_103</td><td>0.11473</td></tr><tr><td>downward_MI_104</td><td>0.06455</td></tr><tr><td>downward_MI_105</td><td>0.19657</td></tr><tr><td>downward_MI_106</td><td>0.16207</td></tr><tr><td>downward_MI_107</td><td>-0.00174</td></tr><tr><td>downward_MI_108</td><td>0.04563</td></tr><tr><td>downward_MI_109</td><td>0.03972</td></tr><tr><td>downward_MI_11</td><td>-0.00086</td></tr><tr><td>downward_MI_110</td><td>0.0275</td></tr><tr><td>downward_MI_111</td><td>0.06294</td></tr><tr><td>downward_MI_112</td><td>0.09746</td></tr><tr><td>downward_MI_113</td><td>0.10285</td></tr><tr><td>downward_MI_114</td><td>0.11474</td></tr><tr><td>downward_MI_115</td><td>0.20495</td></tr><tr><td>downward_MI_12</td><td>0.0045</td></tr><tr><td>downward_MI_13</td><td>0.00727</td></tr><tr><td>downward_MI_14</td><td>-0.01756</td></tr><tr><td>downward_MI_15</td><td>0.00277</td></tr><tr><td>downward_MI_16</td><td>0.00828</td></tr><tr><td>downward_MI_17</td><td>0.01086</td></tr><tr><td>downward_MI_18</td><td>0.01198</td></tr><tr><td>downward_MI_19</td><td>0.00823</td></tr><tr><td>downward_MI_2</td><td>0.00339</td></tr><tr><td>downward_MI_20</td><td>0.00577</td></tr><tr><td>downward_MI_21</td><td>0.04851</td></tr><tr><td>downward_MI_22</td><td>0.02747</td></tr><tr><td>downward_MI_23</td><td>0.01078</td></tr><tr><td>downward_MI_24</td><td>0.07193</td></tr><tr><td>downward_MI_25</td><td>0.07652</td></tr><tr><td>downward_MI_26</td><td>0.02314</td></tr><tr><td>downward_MI_27</td><td>0.01383</td></tr><tr><td>downward_MI_28</td><td>0.00382</td></tr><tr><td>downward_MI_29</td><td>0.0257</td></tr><tr><td>downward_MI_3</td><td>0.00107</td></tr><tr><td>downward_MI_30</td><td>0.03767</td></tr><tr><td>downward_MI_31</td><td>0.00991</td></tr><tr><td>downward_MI_32</td><td>-0.00281</td></tr><tr><td>downward_MI_33</td><td>0.00115</td></tr><tr><td>downward_MI_34</td><td>0.06874</td></tr><tr><td>downward_MI_35</td><td>0.02104</td></tr><tr><td>downward_MI_36</td><td>0.16174</td></tr><tr><td>downward_MI_37</td><td>0.02389</td></tr><tr><td>downward_MI_38</td><td>-0.0035</td></tr><tr><td>downward_MI_39</td><td>0.00036</td></tr><tr><td>downward_MI_4</td><td>-0.00558</td></tr><tr><td>downward_MI_40</td><td>-0.00504</td></tr><tr><td>downward_MI_41</td><td>0.04916</td></tr><tr><td>downward_MI_42</td><td>0.03119</td></tr><tr><td>downward_MI_43</td><td>0.02796</td></tr><tr><td>downward_MI_44</td><td>0.0506</td></tr><tr><td>downward_MI_45</td><td>-0.03246</td></tr><tr><td>downward_MI_46</td><td>0.04905</td></tr><tr><td>downward_MI_47</td><td>0.0653</td></tr><tr><td>downward_MI_48</td><td>0.06299</td></tr><tr><td>downward_MI_49</td><td>0.01752</td></tr><tr><td>downward_MI_5</td><td>0.02592</td></tr><tr><td>downward_MI_50</td><td>0.01707</td></tr><tr><td>downward_MI_51</td><td>0.03372</td></tr><tr><td>downward_MI_52</td><td>0.00928</td></tr><tr><td>downward_MI_53</td><td>0.00128</td></tr><tr><td>downward_MI_54</td><td>0.00295</td></tr><tr><td>downward_MI_55</td><td>0.11066</td></tr><tr><td>downward_MI_56</td><td>0.00518</td></tr><tr><td>downward_MI_57</td><td>-0.00201</td></tr><tr><td>downward_MI_58</td><td>0.06034</td></tr><tr><td>downward_MI_59</td><td>0.19306</td></tr><tr><td>downward_MI_6</td><td>0.00242</td></tr><tr><td>downward_MI_60</td><td>0.0456</td></tr><tr><td>downward_MI_61</td><td>0.03105</td></tr><tr><td>downward_MI_62</td><td>0.06134</td></tr><tr><td>downward_MI_63</td><td>0.00101</td></tr><tr><td>downward_MI_64</td><td>0.00192</td></tr><tr><td>downward_MI_65</td><td>0.0431</td></tr><tr><td>downward_MI_66</td><td>0.00304</td></tr><tr><td>downward_MI_67</td><td>0.07228</td></tr><tr><td>downward_MI_68</td><td>0.02028</td></tr><tr><td>downward_MI_69</td><td>0.00466</td></tr><tr><td>downward_MI_7</td><td>-0.00013</td></tr><tr><td>downward_MI_70</td><td>0.00216</td></tr><tr><td>downward_MI_71</td><td>0.04641</td></tr><tr><td>downward_MI_72</td><td>0.00607</td></tr><tr><td>downward_MI_73</td><td>0.02439</td></tr><tr><td>downward_MI_74</td><td>0.01786</td></tr><tr><td>downward_MI_75</td><td>0.02658</td></tr><tr><td>downward_MI_76</td><td>0.10381</td></tr><tr><td>downward_MI_77</td><td>0.04308</td></tr><tr><td>downward_MI_78</td><td>0.02951</td></tr><tr><td>downward_MI_79</td><td>0.02033</td></tr><tr><td>downward_MI_8</td><td>0.00456</td></tr><tr><td>downward_MI_80</td><td>0.04806</td></tr><tr><td>downward_MI_81</td><td>0.02682</td></tr><tr><td>downward_MI_82</td><td>-0.00042</td></tr><tr><td>downward_MI_83</td><td>-0.0091</td></tr><tr><td>downward_MI_84</td><td>0.00519</td></tr><tr><td>downward_MI_85</td><td>0.03776</td></tr><tr><td>downward_MI_86</td><td>0.16972</td></tr><tr><td>downward_MI_87</td><td>0.00671</td></tr><tr><td>downward_MI_88</td><td>0.0286</td></tr><tr><td>downward_MI_89</td><td>0.00472</td></tr><tr><td>downward_MI_9</td><td>-0.01077</td></tr><tr><td>downward_MI_90</td><td>0.01467</td></tr><tr><td>downward_MI_91</td><td>0.02983</td></tr><tr><td>downward_MI_92</td><td>0.03495</td></tr><tr><td>downward_MI_93</td><td>0.00632</td></tr><tr><td>downward_MI_94</td><td>0.00051</td></tr><tr><td>downward_MI_95</td><td>0.00866</td></tr><tr><td>downward_MI_96</td><td>0.00026</td></tr><tr><td>downward_MI_97</td><td>-0.00938</td></tr><tr><td>downward_MI_98</td><td>0.11368</td></tr><tr><td>downward_MI_99</td><td>0.0613</td></tr><tr><td>sum_downward_MI</td><td>4.02328</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">generous-puddle-3</strong> at: <a href='https://wandb.ai/dmcsharry/meg-min-mse-max-mi-verification/runs/0vbouhyi' target=\"_blank\">https://wandb.ai/dmcsharry/meg-min-mse-max-mi-verification/runs/0vbouhyi</a><br/> View project at: <a href='https://wandb.ai/dmcsharry/meg-min-mse-max-mi-verification' target=\"_blank\">https://wandb.ai/dmcsharry/meg-min-mse-max-mi-verification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240814_083310-0vbouhyi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:0vbouhyi). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/info-theory-experiments/wandb/run-20240814_085313-hu3cdv1s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dmcsharry/meg-min-mse-max-mi-verification/runs/hu3cdv1s' target=\"_blank\">vague-surf-4</a></strong> to <a href='https://wandb.ai/dmcsharry/meg-min-mse-max-mi-verification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dmcsharry/meg-min-mse-max-mi-verification' target=\"_blank\">https://wandb.ai/dmcsharry/meg-min-mse-max-mi-verification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dmcsharry/meg-min-mse-max-mi-verification/runs/hu3cdv1s' target=\"_blank\">https://wandb.ai/dmcsharry/meg-min-mse-max-mi-verification/runs/hu3cdv1s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/2 [05:43<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 36\u001b[0m\n\u001b[1;32m      4\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_seed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeg\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     },\n\u001b[1;32m     32\u001b[0m }\n\u001b[1;32m     34\u001b[0m project_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeg-min-mse-max-mi-verification\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 36\u001b[0m _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_feature_network\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_network_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/info-theory-experiments/info_theory_experiments/trainers.py:196\u001b[0m, in \u001b[0;36mtrain_feature_network\u001b[0;34m(config, trainloader, feature_network_training, project_name, feature_network_A, model_dir_prefix)\u001b[0m\n\u001b[1;32m    194\u001b[0m     downward_loss\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    195\u001b[0m     downward_optims[i]\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 196\u001b[0m     \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdownward_MI_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownward_MI_i\u001b[49m\u001b[43m   \u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m# update MI_AB_estimator\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_model_B\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m~/info-theory-experiments/venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:450\u001b[0m, in \u001b[0;36m_run_decorator._noop.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m         wandb\u001b[38;5;241m.\u001b[39mtermwarn(message, repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mDummy()\n\u001b[0;32m--> 450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/info-theory-experiments/venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:401\u001b[0m, in \u001b[0;36m_run_decorator._noop_on_finish.<locals>.decorator_fn.<locals>.wrapper_fn\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m: Type[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_finished\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m     default_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is finished. The call to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be ignored. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease make sure that you are using an active run.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    406\u001b[0m     )\n\u001b[1;32m    407\u001b[0m     resolved_message \u001b[38;5;241m=\u001b[39m message \u001b[38;5;129;01mor\u001b[39;00m default_message\n",
      "File \u001b[0;32m~/info-theory-experiments/venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:391\u001b[0m, in \u001b[0;36m_run_decorator._attach.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_is_attaching \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/info-theory-experiments/venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:1880\u001b[0m, in \u001b[0;36mRun.log\u001b[0;34m(self, data, step, commit, sync)\u001b[0m\n\u001b[1;32m   1873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_settings\u001b[38;5;241m.\u001b[39m_shared \u001b[38;5;129;01mand\u001b[39;00m step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1874\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mtermwarn(\n\u001b[1;32m   1875\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn shared mode, the use of `wandb.log` with the step argument is not supported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1876\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand will be ignored. Please refer to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwburls\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwandb_define_metric\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1877\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon how to customize your x-axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1878\u001b[0m         repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1879\u001b[0m     )\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/info-theory-experiments/venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:1644\u001b[0m, in \u001b[0;36mRun._log\u001b[0;34m(self, data, step, commit)\u001b[0m\n\u001b[1;32m   1641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m   1642\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey values passed to `wandb.log` must be strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1644\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial_history_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetpid() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_pid \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_attached:\n",
      "File \u001b[0;32m~/info-theory-experiments/venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:1516\u001b[0m, in \u001b[0;36mRun._partial_history_callback\u001b[0;34m(self, row, step, commit)\u001b[0m\n\u001b[1;32m   1513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39minterface:\n\u001b[1;32m   1514\u001b[0m     not_using_tensorboard \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(wandb\u001b[38;5;241m.\u001b[39mpatched[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1516\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_partial_history\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1518\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflush\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpublish_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnot_using_tensorboard\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/info-theory-experiments/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:643\u001b[0m, in \u001b[0;36mInterfaceBase.publish_partial_history\u001b[0;34m(self, data, user_step, step, flush, publish_step, run)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flush \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    642\u001b[0m     partial_history\u001b[38;5;241m.\u001b[39maction\u001b[38;5;241m.\u001b[39mflush \u001b[38;5;241m=\u001b[39m flush\n\u001b[0;32m--> 643\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_partial_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial_history\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/info-theory-experiments/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:89\u001b[0m, in \u001b[0;36mInterfaceShared._publish_partial_history\u001b[0;34m(self, partial_history)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_partial_history\u001b[39m(\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m, partial_history: pb\u001b[38;5;241m.\u001b[39mPartialHistoryRequest\n\u001b[1;32m     87\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(partial_history\u001b[38;5;241m=\u001b[39mpartial_history)\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/info-theory-experiments/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/info-theory-experiments/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[1;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/info-theory-experiments/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/info-theory-experiments/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/info-theory-experiments/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from info_theory_experiments.trainers import train_feature_network\n",
    "seed = 3\n",
    "torch.manual_seed(seed)\n",
    "config = {\n",
    "    \"torch_seed\": seed,\n",
    "    \"dataset_type\": \"meg\",\n",
    "    \"num_atoms\": 116,\n",
    "    \"batch_size\": 1000,\n",
    "    \"train_mode\": False,\n",
    "    \"train_model_B\": False,\n",
    "    \"adjust_Psi\": True,\n",
    "    \"clip\": 5,\n",
    "    \"feature_size\": 1,\n",
    "    \"epochs\": 2,\n",
    "    \"downward_critics_config\": {\n",
    "        \"hidden_sizes_v_critic\": [512, 1024, 1024, 512],\n",
    "        \"hidden_sizes_xi_critic\": [512, 512, 512],\n",
    "        \"critic_output_size\": 32,\n",
    "        \"lr\": 1e-3,\n",
    "        \"bias\": True,\n",
    "        \"weight_decay\": 0,\n",
    "    },\n",
    "    \n",
    "    \"decoupled_critic_config\": {\n",
    "        \"hidden_sizes_encoder_1\": [512, 512, 512],\n",
    "        \"hidden_sizes_encoder_2\": [512, 512, 512],\n",
    "        \"critic_output_size\": 32,\n",
    "        \"lr\": 1e-3,\n",
    "        \"bias\": True,\n",
    "        \"weight_decay\": 0,\n",
    "    },\n",
    "}\n",
    "\n",
    "project_name = \"meg-min-mse-max-mi-verification\"\n",
    "\n",
    "_, _ = train_feature_network(\n",
    "    config=config,\n",
    "    trainloader=train_loader,\n",
    "    feature_network_training=encoder,\n",
    "    project_name=project_name,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
