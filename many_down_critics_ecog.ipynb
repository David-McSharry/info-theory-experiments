{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import lovely_tensors as lt\n",
    "from einops import reduce, rearrange, repeat\n",
    "# from npeet.entropy_estimators import entropy, mi\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import utils\n",
    "import importlib\n",
    "import os\n",
    "from utils import prepare_ecog_dataset, prepare_batch, estimate_MI_smile\n",
    "from smile_estimator import estimate_mutual_information\n",
    "import tqdm\n",
    "from torch.nn.utils import spectral_norm\n",
    "# importlib.reload(utils)\n",
    "\n",
    "\n",
    "\n",
    "lt.monkey_patch()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SupervenientFeatureNetwork(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_atoms: int,\n",
    "            feature_size: int,\n",
    "            hidden_sizes: list,\n",
    "            include_bias: bool = True\n",
    "        ):\n",
    "        super(SupervenientFeatureNetwork, self).__init__()\n",
    "        layers = []\n",
    "        input_size = num_atoms\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(input_size, hidden_size, bias=include_bias))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_size = hidden_size\n",
    "        layers.append(nn.Linear(input_size, feature_size, bias=include_bias))\n",
    "        self.f = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.f(x)\n",
    "\n",
    "\n",
    "class DecoupledCritic(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            feature_size: int,\n",
    "            critic_output_size: int,\n",
    "            hidden_sizes: list,\n",
    "            include_bias: bool = True\n",
    "        ):\n",
    "        super(DecoupledCritic, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        input_size = feature_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(input_size, hidden_size, bias=include_bias))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_size = hidden_size\n",
    "        layers.append(nn.Linear(input_size, critic_output_size, bias=include_bias))\n",
    "\n",
    "        self.v_encoder = nn.Sequential(*layers)\n",
    "        self.W = nn.Linear(critic_output_size, critic_output_size, bias=False)\n",
    "\n",
    "    def forward(self, v0, v1):\n",
    "        v0_encoded = self.v_encoder(v0)\n",
    "        v1_encoded = self.v_encoder(v1)\n",
    "        v1_encoded_transformed = self.W(v1_encoded)\n",
    "        scores = torch.matmul(v0_encoded, v1_encoded_transformed.t())\n",
    "        return scores\n",
    "    \n",
    "\n",
    "class DownwardCritic(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            feature_size: int,\n",
    "            critic_output_size: int,\n",
    "            hidden_sizes_v_critic: list,\n",
    "            hidden_sizes_xi_critic: list,\n",
    "            include_bias: bool = True\n",
    "        ):\n",
    "        super(DownwardCritic, self).__init__()\n",
    "\n",
    "        v_encoder_layers = []\n",
    "        input_size = feature_size\n",
    "        for hidden_size in hidden_sizes_v_critic:\n",
    "            # TODO: Understand what the fuck spectral norm actually is\n",
    "            v_encoder_layers.append((nn.Linear(input_size, hidden_size, bias=include_bias)))\n",
    "            v_encoder_layers.append(nn.ReLU())\n",
    "            input_size = hidden_size\n",
    "        v_encoder_layers.append((nn.Linear(input_size, critic_output_size, bias=include_bias)))\n",
    "        self.v_encoder = nn.Sequential(*v_encoder_layers)\n",
    "\n",
    "        atom_encoder_layers = []\n",
    "        input_size = 1\n",
    "        for hidden_size in hidden_sizes_xi_critic:\n",
    "            atom_encoder_layers.append((nn.Linear(input_size, hidden_size, bias=include_bias)))\n",
    "            atom_encoder_layers.append(nn.ReLU())\n",
    "            input_size = hidden_size\n",
    "        atom_encoder_layers.append((nn.Linear(input_size, critic_output_size, bias=include_bias)))\n",
    "        self.atom_encoder = nn.Sequential(*atom_encoder_layers)\n",
    "    \n",
    "    def forward(self, v1, x0i):\n",
    "        v1_encoded = self.v_encoder(v1)\n",
    "        x0i_encoded = self.atom_encoder(x0i)\n",
    "\n",
    "        scores = torch.matmul(v1_encoded, x0i_encoded.t())\n",
    "        return scores\n",
    "    \n",
    "\n",
    "\n",
    "class NoSpectralDownwardCritic(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            feature_size: int,\n",
    "            critic_output_size: int,\n",
    "            hidden_sizes_v_critic: list,\n",
    "            hidden_sizes_xi_critic: list,\n",
    "            include_bias: bool = True\n",
    "        ):\n",
    "        super(NoSpectralDownwardCritic, self).__init__()\n",
    "\n",
    "        v_encoder_layers = []\n",
    "        input_size = feature_size\n",
    "        for hidden_size in hidden_sizes_v_critic:\n",
    "            v_encoder_layers.append(nn.Linear(input_size, hidden_size, bias=include_bias))\n",
    "            v_encoder_layers.append(nn.ReLU())\n",
    "            input_size = hidden_size\n",
    "        v_encoder_layers.append(nn.Linear(input_size, critic_output_size, bias=include_bias))\n",
    "        self.v_encoder = nn.Sequential(*v_encoder_layers)\n",
    "\n",
    "        atom_encoder_layers = []\n",
    "        input_size = 1\n",
    "        for hidden_size in hidden_sizes_xi_critic:\n",
    "            atom_encoder_layers.append(nn.Linear(input_size, hidden_size, bias=include_bias))\n",
    "            atom_encoder_layers.append(nn.ReLU())\n",
    "            input_size = hidden_size\n",
    "        atom_encoder_layers.append(nn.Linear(input_size, critic_output_size, bias=include_bias)) \n",
    "        self.atom_encoder = nn.Sequential(*atom_encoder_layers)\n",
    "    \n",
    "    def forward(self, v1, x0i):\n",
    "        v1_encoded = self.v_encoder(v1)\n",
    "        x0i_encoded = self.atom_encoder(x0i)\n",
    "\n",
    "        scores = torch.matmul(v1_encoded, x0i_encoded.t())\n",
    "        return scores\n",
    "    \n",
    "class CLUB(nn.Module):  # CLUB: Mutual Information Contrastive Learning Upper Bound\n",
    "    '''\n",
    "        This class provides the CLUB estimation to I(X,Y)\n",
    "        Method:\n",
    "            forward() :      provides the estimation with input samples  \n",
    "            loglikeli() :   provides the log-likelihood of the approximation q(Y|X) with input samples\n",
    "        Arguments:\n",
    "            x_dim, y_dim :         the dimensions of samples from X, Y respectively\n",
    "            hidden_size :          the dimension of the hidden layer of the approximation network q(Y|X)\n",
    "            x_samples, y_samples : samples from X and Y, having shape [sample_size, x_dim/y_dim] \n",
    "    '''\n",
    "    def __init__(\n",
    "            self,\n",
    "            v_dim,\n",
    "            mu_hidden_sizes: list,\n",
    "            logvar_hidden_sizes: list\n",
    "        ):\n",
    "        super(CLUB, self).__init__()\n",
    "        # p_mu outputs mean of q(Y|X)\n",
    "        # p_logvar outputs log of variance of q(Y|X)\n",
    "\n",
    "        # NOTE: hard coding in 1 for output dim here (and below) so that we don't have to make assumptions about the covariance matrix between the different components of y\n",
    "        p_mu_layers = []\n",
    "        input_size = v_dim\n",
    "        for hidden_size in mu_hidden_sizes:\n",
    "            p_mu_layers.append(nn.Linear(input_size, hidden_size))\n",
    "            p_mu_layers.append(nn.ReLU())\n",
    "            input_size = hidden_size\n",
    "        p_mu_layers.append(nn.Linear(input_size, 1))\n",
    "        self.p_mu = nn.Sequential(*p_mu_layers)\n",
    "\n",
    "        p_logvar_layers = []\n",
    "        input_size = v_dim\n",
    "        for hidden_size in logvar_hidden_sizes:\n",
    "            p_logvar_layers.append(nn.Linear(input_size, hidden_size))\n",
    "            p_logvar_layers.append(nn.ReLU())\n",
    "            input_size = hidden_size\n",
    "        p_logvar_layers.append(nn.Linear(input_size, 1))\n",
    "        p_logvar_layers.append(nn.Tanh())\n",
    "        self.p_logvar = nn.Sequential(*p_logvar_layers)\n",
    "\n",
    "\n",
    "    def get_mu_logvar(self, x_samples):\n",
    "        mu = self.p_mu(x_samples)\n",
    "        logvar = self.p_logvar(x_samples)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def forward(self, x_samples, y_samples): \n",
    "        mu, logvar = self.get_mu_logvar(x_samples)\n",
    "        \n",
    "        # log of conditional probability of positive sample pairs\n",
    "        positive = - (mu - y_samples)**2 /2./logvar.exp()  \n",
    "        \n",
    "        prediction_1 = mu.unsqueeze(1)          # shape [nsample,1,dim]\n",
    "        y_samples_1 = y_samples.unsqueeze(0)    # shape [1,nsample,dim]\n",
    "\n",
    "        # log of conditional probability of negative sample pairs\n",
    "        negative = - ((y_samples_1 - prediction_1)**2).mean(dim=1)/2./logvar.exp() \n",
    "\n",
    "        return (positive.sum(dim = -1) - negative.sum(dim = -1)).mean()\n",
    "\n",
    "    def loglikeli(self, x_samples, y_samples): # unnormalized loglikelihood \n",
    "        mu, logvar = self.get_mu_logvar(x_samples)\n",
    "        return 0.5 * (-(mu - y_samples)**2 /logvar.exp()-logvar - torch.log(torch.tensor(2 * math.pi))).sum(dim=1).mean(dim=0)\n",
    "    # NOTE: y should be dim 1\n",
    "    def learning_loss(self, x_samples, y_samples):\n",
    "        return - self.loglikeli(x_samples, y_samples)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"batch_size\": 500,\n",
    "    \"num_atoms\": 64,\n",
    "    \"feature_size\": 1,\n",
    "    \"clip\": 5,\n",
    "    \"critic_output_size\": 16,\n",
    "    \"downward_hidden_sizes_v_critic\": [1024, 1024, 1024, 512],\n",
    "    \"downward_hidden_sizes_xi_critic\": [1024, 1024, 1024, 512],\n",
    "    \"feature_hidden_sizes\": [256, 512, 512, 256],\n",
    "    \"decoupled_critic_hidden_sizes\": [512, 512, 512],\n",
    "    \"feature_lr\": 1e-5,\n",
    "    \"decoupled_critic_lr\": 1e-4,\n",
    "    \"downward_lr\": 1e-4,    \n",
    "    \"bias\": True,\n",
    "    \"update_f_every_N_steps\": 5,\n",
    "    \"weight_decay\": 1e-6,\n",
    "}\n",
    "\n",
    "# config =  {'batch_size': 1000, 'feature_size': 8, 'clip': 1, 'critic_output_size': 20, 'downward_hidden_sizes_v_critic': [192,192,192,192], 'downward_hidden_sizes_xi_critic': [164,164,164,164], 'feature_hidden_sizes': [576,576,576,576], 'decoupled_critic_hidden_sizes': [113,113,113,113], 'feature_lr': 0.0008501232325785077, 'decoupled_critic_lr': 0.00016297738002821739, 'downward_lr': 7.91160518491613e-05, 'update_f_every_N_steps': 1, 'weight_decay': 1.4496890117592044e-05, 'bias': True, 'num_atoms': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a feature network for a given config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_feature_network(config):\n",
    "\n",
    "    dataset = torch.load(\"data/ecog_data_pairs.pth\")\n",
    "    trainloader = torch.utils.data.DataLoader(dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "\n",
    "    wandb.init(project=\"getting-figures\", config=config)\n",
    "\n",
    "    feature_network = SupervenientFeatureNetwork(\n",
    "        num_atoms=config['num_atoms'],\n",
    "        feature_size=config['feature_size'],\n",
    "        hidden_sizes=config['feature_hidden_sizes'],\n",
    "        include_bias=config['bias']\n",
    "        ).to(device)\n",
    "    decoupled_critic = DecoupledCritic(\n",
    "        feature_size=config['feature_size'],\n",
    "        critic_output_size=config['critic_output_size'],\n",
    "        hidden_sizes=config['decoupled_critic_hidden_sizes'],\n",
    "        include_bias=config['bias']\n",
    "        ).to(device)\n",
    "    downward_critics = [\n",
    "        DownwardCritic(\n",
    "            feature_size=config['feature_size'],\n",
    "            critic_output_size=config['critic_output_size'],\n",
    "            hidden_sizes_v_critic=config['downward_hidden_sizes_v_critic'],\n",
    "            hidden_sizes_xi_critic=config['downward_hidden_sizes_xi_critic'],\n",
    "            include_bias=config['bias']\n",
    "            ).to(device) \n",
    "        for _ in range(config['num_atoms'])\n",
    "    ]\n",
    "\n",
    "\n",
    "    downward_optims = [\n",
    "        torch.optim.Adam(\n",
    "            dc.parameters(),\n",
    "            lr=config[\"downward_lr\"],\n",
    "            weight_decay=config[\"weight_decay\"]\n",
    "        ) \n",
    "        for dc in downward_critics\n",
    "    ]\n",
    "    feature_optimizer = torch.optim.Adam(\n",
    "        feature_network.parameters(),\n",
    "        lr=config[\"feature_lr\"],\n",
    "        weight_decay=config[\"weight_decay\"]\n",
    "    )\n",
    "    decoupled_optimizer = torch.optim.Adam(\n",
    "        decoupled_critic.parameters(),\n",
    "        lr=config[\"decoupled_critic_lr\"],\n",
    "        weight_decay=config[\"weight_decay\"]\n",
    "    )\n",
    "\n",
    "\n",
    "    # TODO: figure out why only f network is being watched, I would like to keep a closer eye on the grad n params.\n",
    "    # TODO: Look at how GANs are trained with pytorch and make sure I'm not doing anything unreasonable.\n",
    "    # Eg, https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/gan/gan.py \n",
    "    # ^ this does not require retain_graph=True, so maybe this can be optomized somehow\n",
    "    wandb.watch(feature_network, log='all')\n",
    "    wandb.watch(decoupled_critic, log=\"all\")\n",
    "    for dc in downward_critics:\n",
    "        wandb.watch(dc, log='all')\n",
    "\n",
    "    ##\n",
    "    ## TRAIN FEATURE NETWORK\n",
    "    ##\n",
    "\n",
    "    epochs = 3\n",
    "\n",
    "    for _ in tqdm.tqdm(range(epochs), desc='Training'):\n",
    "        for batch_num, batch in enumerate(trainloader):\n",
    "            x0 = batch[:, 0].to(device).float()\n",
    "            x1 = batch[:, 1].to(device).float()\n",
    "            v0 = feature_network(x0)\n",
    "            v1 = feature_network(x1) \n",
    "\n",
    "            # update decoupled critic\n",
    "            feature_network.eval()\n",
    "            decoupled_critic.train()\n",
    "            downward_critics = [dc.train() for dc in downward_critics]\n",
    "\n",
    "            decoupled_optimizer.zero_grad()\n",
    "            decoupled_scores = decoupled_critic(v0, v1)\n",
    "            decoupled_MI = estimate_mutual_information('smile', decoupled_scores, clip=config['clip'])\n",
    "            decoupled_loss = -decoupled_MI\n",
    "            decoupled_loss.backward(retain_graph=True)\n",
    "            decoupled_optimizer.step()\n",
    "\n",
    "\n",
    "            # update each downward critic \n",
    "            for i in range(config['num_atoms']):\n",
    "                downward_optims[i].zero_grad()\n",
    "                channel_i = x0[:, i].unsqueeze(1)\n",
    "                downward_scores = downward_critics[i](v1, channel_i)\n",
    "                downward_MI_i = estimate_mutual_information('smile', downward_scores, clip=config['clip'])\n",
    "                # add spectral norm to the loss\n",
    "                downward_loss = - downward_MI_i\n",
    "                downward_loss.backward(retain_graph=True)\n",
    "                downward_optims[i].step()\n",
    "                wandb.log({\n",
    "                    f\"downward_MI_{i}\": downward_MI_i   \n",
    "                })\n",
    "\n",
    "            # update feature network   \n",
    "            feature_network.train()\n",
    "            decoupled_critic.eval()\n",
    "            downward_critics = [dc.eval() for dc in downward_critics]\n",
    "\n",
    "            feature_optimizer.zero_grad()\n",
    "            sum_downward_MI = 0\n",
    "\n",
    "            for i in range(config['num_atoms']):\n",
    "                channel_i = x0[:, i].unsqueeze(1)\n",
    "                downward_scores1 = downward_critics[i](v1, channel_i)\n",
    "                sum_downward_MI += estimate_mutual_information('smile', downward_scores1, clip=config['clip'])\n",
    "\n",
    "            decoupled_scores1 = decoupled_critic(v0, v1)\n",
    "            decoupled_MI1 = estimate_mutual_information('smile', decoupled_scores1, clip=config['clip'])\n",
    "\n",
    "            Psi = decoupled_MI1 - sum_downward_MI\n",
    "            feature_loss = -Psi\n",
    "\n",
    "            if batch_num % config['update_f_every_N_steps'] == 0:\n",
    "                feature_loss.backward()\n",
    "                feature_optimizer.step()\n",
    "\n",
    "            wandb.log({\n",
    "                \"decoupled_MI\": decoupled_MI1,\n",
    "                \"sum_downward_MI\": sum_downward_MI,\n",
    "                \"Psi\": Psi,\n",
    "            })\n",
    "\n",
    "    # free the memory associated with anything that is not the feature network\n",
    "    for dc in downward_critics:\n",
    "        del dc\n",
    "    del decoupled_critic\n",
    "    del decoupled_optimizer\n",
    "    del downward_optims\n",
    "    del trainloader\n",
    "    del dataset\n",
    "        \n",
    "    return feature_network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdmcsharry\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/dm2223/info-theory-experiments/wandb/run-20240417_011226-yc87n1td</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dmcsharry/getting-figures/runs/yc87n1td' target=\"_blank\">rural-wave-120</a></strong> to <a href='https://wandb.ai/dmcsharry/getting-figures' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dmcsharry/getting-figures' target=\"_blank\">https://wandb.ai/dmcsharry/getting-figures</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dmcsharry/getting-figures/runs/yc87n1td' target=\"_blank\">https://wandb.ai/dmcsharry/getting-figures/runs/yc87n1td</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3/3 [08:29<00:00, 169.80s/it]\n"
     ]
    }
   ],
   "source": [
    "feature_network = train_feature_network(config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the MI between different channels\n",
    "\n",
    "I( xt_i ; xt_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = torch.load(\"data/ecog_data_pairs.pth\")\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=2000, shuffle=False)\n",
    "\n",
    "wandb.init(project=\"Interchannel MI\")\n",
    "\n",
    "channel_critic = NoSpectralDownwardCritic(\n",
    "    feature_size=1, # replacing the feature with a channel which is dim 1\n",
    "    critic_output_size=8,\n",
    "    hidden_sizes_v_critic=[64, 512, 1028, 512],\n",
    "    hidden_sizes_xi_critic=[64, 512, 1028, 512],\n",
    "    include_bias=True\n",
    ").to(device) \n",
    "\n",
    "\n",
    "\n",
    "channel_critic_optim = torch.optim.Adam(channel_critic.parameters(), lr=1e-5, weight_decay=1e-6)\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "channels = (1,2)\n",
    "\n",
    "for _ in tqdm.tqdm(range(epochs), desc='Training a SMILE estimator for interchannel MI'):\n",
    "    for batch_num, batch in enumerate(trainloader):\n",
    "        x0 = batch[:, 0].to(device).float()\n",
    "        x1 = batch[:, 1].to(device).float()\n",
    "\n",
    "        channel_i = x0[:, channels[0]].unsqueeze(1)\n",
    "        channel_j = x0[:, channels[1]].unsqueeze(1)\n",
    "\n",
    "        scores = channel_critic(channel_j, channel_i)\n",
    "        MI = estimate_mutual_information('smile', scores, clip=1)\n",
    "        loss = -MI \n",
    "        loss.backward()\n",
    "        channel_critic_optim.step()\n",
    "        wandb.log({\n",
    "            \"Inter-channel MI\": MI\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Psi given a frozen feature network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model_path = \"/vol/bitbucket/dm2223/info-theory-experiments/promising_hmmm_f.pth\"\n",
    "\n",
    "# feature_network = SupervenientFeatureNetwork(\n",
    "#     num_atoms=config['num_atoms'],\n",
    "#     feature_size=config['feature_size'],\n",
    "#     hidden_sizes=config['feature_hidden_sizes'],\n",
    "#     include_bias=config['bias']\n",
    "#     ).to(device)\n",
    "# feature_network.load_state_dict(torch.load(model_path))\n",
    "# feature_network.eval()\n",
    "\n",
    "\n",
    "\n",
    "def find_true_Psi(feature_network, run_id, feature_config):\n",
    "\n",
    "    print(type(feature_network))\n",
    "\n",
    "    config = {\n",
    "        \"batch_size\": 1000,\n",
    "        \"num_atoms\": 64,\n",
    "        \"feature_size\": feature_config['feature_size'],\n",
    "        \"clip\": 5,\n",
    "        \"critic_output_size\": 16,\n",
    "        \"downward_hidden_sizes_v_critic\": [1028, 1028, 512, 64],\n",
    "        \"downward_hidden_sizes_xi_critic\": [512, 512, 512, 64],\n",
    "        \"feature_hidden_sizes\": [1028, 1028, 256],\n",
    "        \"decoupled_critis_hidden_sizes\": [512, 512, 128],\n",
    "        \"decoupled_critic_lr\": 1e-4,\n",
    "        \"downward_lr\": 1e-4,\n",
    "        \"bias\": True,\n",
    "        \"weight_decay\": 1e-6,\n",
    "        \"original_run_id\": run_id\n",
    "    }\n",
    "\n",
    "    dataset = torch.load(\"data/ecog_data_pairs.pth\")\n",
    "    trainloader = torch.utils.data.DataLoader(dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "\n",
    "    wandb.init(project=\"Finding-true-Psi-for-f\", config=config, id=run_id)\n",
    "\n",
    "    decoupled_critic = DecoupledCritic(\n",
    "        feature_size=config['feature_size'],\n",
    "        critic_output_size=config['critic_output_size'],\n",
    "        hidden_sizes=config['decoupled_critis_hidden_sizes'],\n",
    "        include_bias=config['bias']\n",
    "        ).to(device)\n",
    "\n",
    "    downward_critics = [\n",
    "        NoSpectralDownwardCritic(\n",
    "            feature_size=config['feature_size'],\n",
    "            critic_output_size=config['critic_output_size'],\n",
    "            hidden_sizes_v_critic=config['downward_hidden_sizes_v_critic'],\n",
    "            hidden_sizes_xi_critic=config['downward_hidden_sizes_xi_critic'],\n",
    "            include_bias=config['bias']\n",
    "            ).to(device) \n",
    "        for _ in range(config['num_atoms'])\n",
    "    ]\n",
    "\n",
    "    downward_optims = [\n",
    "        torch.optim.Adam(\n",
    "            dc.parameters(),\n",
    "            lr=config[\"downward_lr\"],\n",
    "            weight_decay=config[\"weight_decay\"]\n",
    "        ) \n",
    "        for dc in downward_critics\n",
    "    ]\n",
    "\n",
    "    decoupled_optimizer = torch.optim.Adam(\n",
    "        decoupled_critic.parameters(),\n",
    "        lr=config[\"decoupled_critic_lr\"],\n",
    "        weight_decay=config[\"weight_decay\"]\n",
    "    )\n",
    "\n",
    "    # TODO: figure out why only f network is being watched, I would like to keep a closer eye on the grad n params.\n",
    "    # TODO: Look at how GANs are trained with pytorch and make sure I'm not doing anything unreasonable.\n",
    "    # Eg, https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/gan/gan.py \n",
    "    # ^ this does not require retain_graph=True, so maybe this can be optomized somehow\n",
    "    wandb.watch(decoupled_critic, log=\"all\")\n",
    "    for dc in downward_critics:\n",
    "        wandb.watch(dc, log='all')\n",
    "\n",
    "    epochs = 5\n",
    "\n",
    "    for _ in tqdm.tqdm(range(epochs), desc='Training'):\n",
    "        for _, batch in enumerate(trainloader):\n",
    "            x0 = batch[:, 0].to(device).float()\n",
    "            x1 = batch[:, 1].to(device).float()\n",
    "\n",
    "            # update decoupled critic\n",
    "\n",
    "            v0 = feature_network(x0)\n",
    "            v1 = feature_network(x1) \n",
    "\n",
    "            decoupled_optimizer.zero_grad()\n",
    "            decoupled_scores = decoupled_critic(v0, v1)\n",
    "            decoupled_MI = estimate_mutual_information('smile', decoupled_scores, clip=config['clip'])\n",
    "            decoupled_loss = -decoupled_MI\n",
    "            decoupled_loss.backward(retain_graph=True)\n",
    "            decoupled_optimizer.step()\n",
    "\n",
    "\n",
    "            # update each downward critic \n",
    "\n",
    "            for i in range(config['num_atoms']):\n",
    "                downward_optims[i].zero_grad()\n",
    "                channel_i = x0[:, i].unsqueeze(1)\n",
    "                downward_scores = downward_critics[i](v1, channel_i)\n",
    "                downward_MI_i = estimate_mutual_information('smile', downward_scores, clip=config['clip'])\n",
    "                # add spectral norm to the loss\n",
    "                downward_loss = - downward_MI_i\n",
    "                downward_loss.backward(retain_graph=True)\n",
    "                downward_optims[i].step()\n",
    "                wandb.log({\n",
    "                    f\"downward_MI_{i}\": downward_MI_i   \n",
    "                })\n",
    "\n",
    "            # update feature network   \n",
    "\n",
    "            sum_downward_MI = 0\n",
    "\n",
    "            for i in range(config['num_atoms']):\n",
    "                channel_i = x0[:, i].unsqueeze(1)\n",
    "                downward_scores1 = downward_critics[i](v1, channel_i)\n",
    "                sum_downward_MI += estimate_mutual_information('smile', downward_scores1, clip=config['clip'])\n",
    "\n",
    "            decoupled_scores1 = decoupled_critic(v0, v1)\n",
    "            decoupled_MI1 = estimate_mutual_information('smile', decoupled_scores1, clip=config['clip'])\n",
    "\n",
    "            Psi = decoupled_MI1 - sum_downward_MI\n",
    "\n",
    "            wandb.log({\n",
    "                \"decoupled_MI\": decoupled_MI1,\n",
    "                \"sum_downward_MI\": sum_downward_MI,\n",
    "                \"Psi\": Psi,\n",
    "            })\n",
    "        \n",
    "    return Psi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save feature network\n",
    "torch.save(feature_network.state_dict(), f\"/vol/bitbucket/dm2223/info-theory-experiments/feature_network_snake.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.SupervenientFeatureNetwork'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdmcsharry\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/dm2223/info-theory-experiments/wandb/run-20240417_011021-panda</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dmcsharry/Finding-true-Psi-for-f/runs/panda' target=\"_blank\">panda</a></strong> to <a href='https://wandb.ai/dmcsharry/Finding-true-Psi-for-f' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dmcsharry/Finding-true-Psi-for-f' target=\"_blank\">https://wandb.ai/dmcsharry/Finding-true-Psi-for-f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dmcsharry/Finding-true-Psi-for-f/runs/panda' target=\"_blank\">https://wandb.ai/dmcsharry/Finding-true-Psi-for-f/runs/panda</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 1/5 [01:18<05:14, 78.58s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m feature_network\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/vol/bitbucket/dm2223/info-theory-experiments/feature_network_snake.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# find true Psi\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m Psi \u001b[38;5;241m=\u001b[39m \u001b[43mfind_true_Psi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_network\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpanda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 106\u001b[0m, in \u001b[0;36mfind_true_Psi\u001b[0;34m(feature_network, run_id, feature_config)\u001b[0m\n\u001b[1;32m    104\u001b[0m downward_optims[i]\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    105\u001b[0m channel_i \u001b[38;5;241m=\u001b[39m x0[:, i]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 106\u001b[0m downward_scores \u001b[38;5;241m=\u001b[39m \u001b[43mdownward_critics\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_i\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m downward_MI_i \u001b[38;5;241m=\u001b[39m estimate_mutual_information(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmile\u001b[39m\u001b[38;5;124m'\u001b[39m, downward_scores, clip\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# add spectral norm to the loss\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/dm2223/info-theory-experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/dm2223/info-theory-experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1564\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1565\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1566\u001b[0m     ):\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 123\u001b[0m, in \u001b[0;36mNoSpectralDownwardCritic.forward\u001b[0;34m(self, v1, x0i)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, v1, x0i):\n\u001b[1;32m    122\u001b[0m     v1_encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_encoder(v1)\n\u001b[0;32m--> 123\u001b[0m     x0i_encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matom_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0i\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(v1_encoded, x0i_encoded\u001b[38;5;241m.\u001b[39mt())\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "File \u001b[0;32m/vol/bitbucket/dm2223/info-theory-experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/dm2223/info-theory-experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/dm2223/info-theory-experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/vol/bitbucket/dm2223/info-theory-experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/dm2223/info-theory-experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/dm2223/info-theory-experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:101\u001b[0m, in \u001b[0;36mReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/dm2223/info-theory-experiments/.venv/lib/python3.10/site-packages/torch/nn/functional.py:1473\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1471\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1473\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load feature network\n",
    "feature_network = SupervenientFeatureNetwork(\n",
    "    num_atoms=config['num_atoms'],\n",
    "    feature_size=config['feature_size'],\n",
    "    hidden_sizes=config['feature_hidden_sizes'],\n",
    "    include_bias=config['bias']\n",
    "    ).to(device)\n",
    "feature_network.load_state_dict(torch.load(\"/vol/bitbucket/dm2223/info-theory-experiments/feature_network_snake.pth\"))\n",
    "\n",
    "# find true Psi\n",
    "Psi = find_true_Psi(feature_network, run_id=\"panda\", feature_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-15 02:40:40,595] A new study created in memory with name: no-name-09a86fe3-ffd4-45df-8ceb-77f5b43d8ebc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:hco69wgo) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Psi</td><td>▁</td></tr><tr><td>decoupled_MI</td><td>▁</td></tr><tr><td>downward_MI_0</td><td>▁</td></tr><tr><td>downward_MI_1</td><td>▁</td></tr><tr><td>downward_MI_10</td><td>▁</td></tr><tr><td>downward_MI_11</td><td>▁</td></tr><tr><td>downward_MI_12</td><td>▁</td></tr><tr><td>downward_MI_13</td><td>▁</td></tr><tr><td>downward_MI_14</td><td>▁</td></tr><tr><td>downward_MI_15</td><td>▁</td></tr><tr><td>downward_MI_16</td><td>▁</td></tr><tr><td>downward_MI_17</td><td>▁</td></tr><tr><td>downward_MI_18</td><td>▁</td></tr><tr><td>downward_MI_19</td><td>▁</td></tr><tr><td>downward_MI_2</td><td>▁</td></tr><tr><td>downward_MI_20</td><td>▁</td></tr><tr><td>downward_MI_21</td><td>▁</td></tr><tr><td>downward_MI_22</td><td>▁</td></tr><tr><td>downward_MI_23</td><td>▁</td></tr><tr><td>downward_MI_24</td><td>▁</td></tr><tr><td>downward_MI_25</td><td>▁</td></tr><tr><td>downward_MI_26</td><td>▁</td></tr><tr><td>downward_MI_27</td><td>▁</td></tr><tr><td>downward_MI_28</td><td>▁</td></tr><tr><td>downward_MI_29</td><td>▁</td></tr><tr><td>downward_MI_3</td><td>▁</td></tr><tr><td>downward_MI_30</td><td>▁</td></tr><tr><td>downward_MI_31</td><td>▁</td></tr><tr><td>downward_MI_32</td><td>▁</td></tr><tr><td>downward_MI_33</td><td>▁</td></tr><tr><td>downward_MI_34</td><td>▁</td></tr><tr><td>downward_MI_35</td><td>▁</td></tr><tr><td>downward_MI_36</td><td>▁</td></tr><tr><td>downward_MI_37</td><td>▁</td></tr><tr><td>downward_MI_38</td><td>▁</td></tr><tr><td>downward_MI_39</td><td>▁</td></tr><tr><td>downward_MI_4</td><td>▁</td></tr><tr><td>downward_MI_40</td><td>▁</td></tr><tr><td>downward_MI_41</td><td>▁</td></tr><tr><td>downward_MI_42</td><td>▁</td></tr><tr><td>downward_MI_43</td><td>▁</td></tr><tr><td>downward_MI_44</td><td>▁</td></tr><tr><td>downward_MI_45</td><td>▁</td></tr><tr><td>downward_MI_46</td><td>▁</td></tr><tr><td>downward_MI_47</td><td>▁</td></tr><tr><td>downward_MI_48</td><td>▁</td></tr><tr><td>downward_MI_49</td><td>▁</td></tr><tr><td>downward_MI_5</td><td>▁</td></tr><tr><td>downward_MI_50</td><td>▁</td></tr><tr><td>downward_MI_51</td><td>▁</td></tr><tr><td>downward_MI_52</td><td>▁</td></tr><tr><td>downward_MI_53</td><td>▁</td></tr><tr><td>downward_MI_54</td><td>▁</td></tr><tr><td>downward_MI_55</td><td>▁</td></tr><tr><td>downward_MI_56</td><td>▁</td></tr><tr><td>downward_MI_57</td><td>▁</td></tr><tr><td>downward_MI_58</td><td>▁</td></tr><tr><td>downward_MI_59</td><td>▁</td></tr><tr><td>downward_MI_6</td><td>▁</td></tr><tr><td>downward_MI_60</td><td>▁</td></tr><tr><td>downward_MI_61</td><td>▁</td></tr><tr><td>downward_MI_62</td><td>▁</td></tr><tr><td>downward_MI_63</td><td>▁</td></tr><tr><td>downward_MI_7</td><td>▁</td></tr><tr><td>downward_MI_8</td><td>▁</td></tr><tr><td>downward_MI_9</td><td>▁</td></tr><tr><td>sum_downward_MI</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Psi</td><td>-0.0016</td></tr><tr><td>decoupled_MI</td><td>0.0</td></tr><tr><td>downward_MI_0</td><td>-1e-05</td></tr><tr><td>downward_MI_1</td><td>-2e-05</td></tr><tr><td>downward_MI_10</td><td>-1e-05</td></tr><tr><td>downward_MI_11</td><td>-0.0</td></tr><tr><td>downward_MI_12</td><td>-1e-05</td></tr><tr><td>downward_MI_13</td><td>-1e-05</td></tr><tr><td>downward_MI_14</td><td>0.0</td></tr><tr><td>downward_MI_15</td><td>1e-05</td></tr><tr><td>downward_MI_16</td><td>0.0</td></tr><tr><td>downward_MI_17</td><td>0.0</td></tr><tr><td>downward_MI_18</td><td>-0.0</td></tr><tr><td>downward_MI_19</td><td>1e-05</td></tr><tr><td>downward_MI_2</td><td>-1e-05</td></tr><tr><td>downward_MI_20</td><td>-1e-05</td></tr><tr><td>downward_MI_21</td><td>1e-05</td></tr><tr><td>downward_MI_22</td><td>-5e-05</td></tr><tr><td>downward_MI_23</td><td>0.0</td></tr><tr><td>downward_MI_24</td><td>-1e-05</td></tr><tr><td>downward_MI_25</td><td>-1e-05</td></tr><tr><td>downward_MI_26</td><td>-0.0</td></tr><tr><td>downward_MI_27</td><td>1e-05</td></tr><tr><td>downward_MI_28</td><td>-2e-05</td></tr><tr><td>downward_MI_29</td><td>-0.0</td></tr><tr><td>downward_MI_3</td><td>-0.0</td></tr><tr><td>downward_MI_30</td><td>-2e-05</td></tr><tr><td>downward_MI_31</td><td>0.0</td></tr><tr><td>downward_MI_32</td><td>-2e-05</td></tr><tr><td>downward_MI_33</td><td>-0.0</td></tr><tr><td>downward_MI_34</td><td>1e-05</td></tr><tr><td>downward_MI_35</td><td>-0.0</td></tr><tr><td>downward_MI_36</td><td>-0.0</td></tr><tr><td>downward_MI_37</td><td>-0.0</td></tr><tr><td>downward_MI_38</td><td>-2e-05</td></tr><tr><td>downward_MI_39</td><td>1e-05</td></tr><tr><td>downward_MI_4</td><td>-3e-05</td></tr><tr><td>downward_MI_40</td><td>-5e-05</td></tr><tr><td>downward_MI_41</td><td>0.0</td></tr><tr><td>downward_MI_42</td><td>-1e-05</td></tr><tr><td>downward_MI_43</td><td>-0.0</td></tr><tr><td>downward_MI_44</td><td>0.0</td></tr><tr><td>downward_MI_45</td><td>-1e-05</td></tr><tr><td>downward_MI_46</td><td>-1e-05</td></tr><tr><td>downward_MI_47</td><td>-1e-05</td></tr><tr><td>downward_MI_48</td><td>-2e-05</td></tr><tr><td>downward_MI_49</td><td>-0.0</td></tr><tr><td>downward_MI_5</td><td>-1e-05</td></tr><tr><td>downward_MI_50</td><td>-2e-05</td></tr><tr><td>downward_MI_51</td><td>-1e-05</td></tr><tr><td>downward_MI_52</td><td>-3e-05</td></tr><tr><td>downward_MI_53</td><td>0.0</td></tr><tr><td>downward_MI_54</td><td>-1e-05</td></tr><tr><td>downward_MI_55</td><td>-2e-05</td></tr><tr><td>downward_MI_56</td><td>-2e-05</td></tr><tr><td>downward_MI_57</td><td>-0.0</td></tr><tr><td>downward_MI_58</td><td>-2e-05</td></tr><tr><td>downward_MI_59</td><td>1e-05</td></tr><tr><td>downward_MI_6</td><td>0.0</td></tr><tr><td>downward_MI_60</td><td>1e-05</td></tr><tr><td>downward_MI_61</td><td>1e-05</td></tr><tr><td>downward_MI_62</td><td>-0.0</td></tr><tr><td>downward_MI_63</td><td>-0.0</td></tr><tr><td>downward_MI_7</td><td>-2e-05</td></tr><tr><td>downward_MI_8</td><td>-0.0</td></tr><tr><td>downward_MI_9</td><td>-1e-05</td></tr><tr><td>sum_downward_MI</td><td>0.0016</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">still-terrain-8</strong> at: <a href='https://wandb.ai/dmcsharry/Finding-true-Psi-for-f/runs/hco69wgo' target=\"_blank\">https://wandb.ai/dmcsharry/Finding-true-Psi-for-f/runs/hco69wgo</a><br/> View project at: <a href='https://wandb.ai/dmcsharry/Finding-true-Psi-for-f' target=\"_blank\">https://wandb.ai/dmcsharry/Finding-true-Psi-for-f</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240415_023844-hco69wgo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:hco69wgo). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/dm2223/info-theory-experiments/wandb/run-20240415_024040-dxb7gqo0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dmcsharry/getting-figures/runs/dxb7gqo0' target=\"_blank\">peachy-oath-97</a></strong> to <a href='https://wandb.ai/dmcsharry/getting-figures' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dmcsharry/getting-figures' target=\"_blank\">https://wandb.ai/dmcsharry/getting-figures</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dmcsharry/getting-figures/runs/dxb7gqo0' target=\"_blank\">https://wandb.ai/dmcsharry/getting-figures/runs/dxb7gqo0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.SupervenientFeatureNetwork'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:dxb7gqo0) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Psi</td><td>▁</td></tr><tr><td>decoupled_MI</td><td>▁</td></tr><tr><td>downward_MI_0</td><td>▁</td></tr><tr><td>downward_MI_1</td><td>▁</td></tr><tr><td>downward_MI_10</td><td>▁</td></tr><tr><td>downward_MI_11</td><td>▁</td></tr><tr><td>downward_MI_12</td><td>▁</td></tr><tr><td>downward_MI_13</td><td>▁</td></tr><tr><td>downward_MI_14</td><td>▁</td></tr><tr><td>downward_MI_15</td><td>▁</td></tr><tr><td>downward_MI_16</td><td>▁</td></tr><tr><td>downward_MI_17</td><td>▁</td></tr><tr><td>downward_MI_18</td><td>▁</td></tr><tr><td>downward_MI_19</td><td>▁</td></tr><tr><td>downward_MI_2</td><td>▁</td></tr><tr><td>downward_MI_20</td><td>▁</td></tr><tr><td>downward_MI_21</td><td>▁</td></tr><tr><td>downward_MI_22</td><td>▁</td></tr><tr><td>downward_MI_23</td><td>▁</td></tr><tr><td>downward_MI_24</td><td>▁</td></tr><tr><td>downward_MI_25</td><td>▁</td></tr><tr><td>downward_MI_26</td><td>▁</td></tr><tr><td>downward_MI_27</td><td>▁</td></tr><tr><td>downward_MI_28</td><td>▁</td></tr><tr><td>downward_MI_29</td><td>▁</td></tr><tr><td>downward_MI_3</td><td>▁</td></tr><tr><td>downward_MI_30</td><td>▁</td></tr><tr><td>downward_MI_31</td><td>▁</td></tr><tr><td>downward_MI_32</td><td>▁</td></tr><tr><td>downward_MI_33</td><td>▁</td></tr><tr><td>downward_MI_34</td><td>▁</td></tr><tr><td>downward_MI_35</td><td>▁</td></tr><tr><td>downward_MI_36</td><td>▁</td></tr><tr><td>downward_MI_37</td><td>▁</td></tr><tr><td>downward_MI_38</td><td>▁</td></tr><tr><td>downward_MI_39</td><td>▁</td></tr><tr><td>downward_MI_4</td><td>▁</td></tr><tr><td>downward_MI_40</td><td>▁</td></tr><tr><td>downward_MI_41</td><td>▁</td></tr><tr><td>downward_MI_42</td><td>▁</td></tr><tr><td>downward_MI_43</td><td>▁</td></tr><tr><td>downward_MI_44</td><td>▁</td></tr><tr><td>downward_MI_45</td><td>▁</td></tr><tr><td>downward_MI_46</td><td>▁</td></tr><tr><td>downward_MI_47</td><td>▁</td></tr><tr><td>downward_MI_48</td><td>▁</td></tr><tr><td>downward_MI_49</td><td>▁</td></tr><tr><td>downward_MI_5</td><td>▁</td></tr><tr><td>downward_MI_50</td><td>▁</td></tr><tr><td>downward_MI_51</td><td>▁</td></tr><tr><td>downward_MI_52</td><td>▁</td></tr><tr><td>downward_MI_53</td><td>▁</td></tr><tr><td>downward_MI_54</td><td>▁</td></tr><tr><td>downward_MI_55</td><td>▁</td></tr><tr><td>downward_MI_56</td><td>▁</td></tr><tr><td>downward_MI_57</td><td>▁</td></tr><tr><td>downward_MI_58</td><td>▁</td></tr><tr><td>downward_MI_59</td><td>▁</td></tr><tr><td>downward_MI_6</td><td>▁</td></tr><tr><td>downward_MI_60</td><td>▁</td></tr><tr><td>downward_MI_61</td><td>▁</td></tr><tr><td>downward_MI_62</td><td>▁</td></tr><tr><td>downward_MI_63</td><td>▁</td></tr><tr><td>downward_MI_7</td><td>▁</td></tr><tr><td>downward_MI_8</td><td>▁</td></tr><tr><td>downward_MI_9</td><td>▁</td></tr><tr><td>sum_downward_MI</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Psi</td><td>0.00028</td></tr><tr><td>decoupled_MI</td><td>-0.0</td></tr><tr><td>downward_MI_0</td><td>-2e-05</td></tr><tr><td>downward_MI_1</td><td>-3e-05</td></tr><tr><td>downward_MI_10</td><td>-0.0</td></tr><tr><td>downward_MI_11</td><td>1e-05</td></tr><tr><td>downward_MI_12</td><td>1e-05</td></tr><tr><td>downward_MI_13</td><td>-3e-05</td></tr><tr><td>downward_MI_14</td><td>-7e-05</td></tr><tr><td>downward_MI_15</td><td>-5e-05</td></tr><tr><td>downward_MI_16</td><td>-0.00025</td></tr><tr><td>downward_MI_17</td><td>0.0001</td></tr><tr><td>downward_MI_18</td><td>-8e-05</td></tr><tr><td>downward_MI_19</td><td>-3e-05</td></tr><tr><td>downward_MI_2</td><td>-5e-05</td></tr><tr><td>downward_MI_20</td><td>1e-05</td></tr><tr><td>downward_MI_21</td><td>-2e-05</td></tr><tr><td>downward_MI_22</td><td>-4e-05</td></tr><tr><td>downward_MI_23</td><td>-3e-05</td></tr><tr><td>downward_MI_24</td><td>7e-05</td></tr><tr><td>downward_MI_25</td><td>1e-05</td></tr><tr><td>downward_MI_26</td><td>-1e-05</td></tr><tr><td>downward_MI_27</td><td>-0.00012</td></tr><tr><td>downward_MI_28</td><td>5e-05</td></tr><tr><td>downward_MI_29</td><td>-0.0001</td></tr><tr><td>downward_MI_3</td><td>-0.00013</td></tr><tr><td>downward_MI_30</td><td>1e-05</td></tr><tr><td>downward_MI_31</td><td>-2e-05</td></tr><tr><td>downward_MI_32</td><td>6e-05</td></tr><tr><td>downward_MI_33</td><td>-0.0</td></tr><tr><td>downward_MI_34</td><td>-3e-05</td></tr><tr><td>downward_MI_35</td><td>-4e-05</td></tr><tr><td>downward_MI_36</td><td>9e-05</td></tr><tr><td>downward_MI_37</td><td>3e-05</td></tr><tr><td>downward_MI_38</td><td>-2e-05</td></tr><tr><td>downward_MI_39</td><td>0.0</td></tr><tr><td>downward_MI_4</td><td>-1e-05</td></tr><tr><td>downward_MI_40</td><td>-8e-05</td></tr><tr><td>downward_MI_41</td><td>3e-05</td></tr><tr><td>downward_MI_42</td><td>-0.00014</td></tr><tr><td>downward_MI_43</td><td>-1e-05</td></tr><tr><td>downward_MI_44</td><td>-0.00012</td></tr><tr><td>downward_MI_45</td><td>-3e-05</td></tr><tr><td>downward_MI_46</td><td>-0.00013</td></tr><tr><td>downward_MI_47</td><td>7e-05</td></tr><tr><td>downward_MI_48</td><td>-5e-05</td></tr><tr><td>downward_MI_49</td><td>2e-05</td></tr><tr><td>downward_MI_5</td><td>2e-05</td></tr><tr><td>downward_MI_50</td><td>-0.0001</td></tr><tr><td>downward_MI_51</td><td>-0.00011</td></tr><tr><td>downward_MI_52</td><td>-1e-05</td></tr><tr><td>downward_MI_53</td><td>-1e-05</td></tr><tr><td>downward_MI_54</td><td>-6e-05</td></tr><tr><td>downward_MI_55</td><td>-7e-05</td></tr><tr><td>downward_MI_56</td><td>2e-05</td></tr><tr><td>downward_MI_57</td><td>-7e-05</td></tr><tr><td>downward_MI_58</td><td>2e-05</td></tr><tr><td>downward_MI_59</td><td>-6e-05</td></tr><tr><td>downward_MI_6</td><td>8e-05</td></tr><tr><td>downward_MI_60</td><td>-0.0</td></tr><tr><td>downward_MI_61</td><td>-4e-05</td></tr><tr><td>downward_MI_62</td><td>-0.0002</td></tr><tr><td>downward_MI_63</td><td>-1e-05</td></tr><tr><td>downward_MI_7</td><td>3e-05</td></tr><tr><td>downward_MI_8</td><td>5e-05</td></tr><tr><td>downward_MI_9</td><td>1e-05</td></tr><tr><td>sum_downward_MI</td><td>-0.00028</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">peachy-oath-97</strong> at: <a href='https://wandb.ai/dmcsharry/getting-figures/runs/dxb7gqo0' target=\"_blank\">https://wandb.ai/dmcsharry/getting-figures/runs/dxb7gqo0</a><br/> View project at: <a href='https://wandb.ai/dmcsharry/getting-figures' target=\"_blank\">https://wandb.ai/dmcsharry/getting-figures</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240415_024040-dxb7gqo0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:dxb7gqo0). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/dm2223/info-theory-experiments/wandb/run-20240415_024047-dxb7gqo0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dmcsharry/Finding-true-Psi-for-f/runs/dxb7gqo0' target=\"_blank\">logical-pyramid-9</a></strong> to <a href='https://wandb.ai/dmcsharry/Finding-true-Psi-for-f' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dmcsharry/Finding-true-Psi-for-f' target=\"_blank\">https://wandb.ai/dmcsharry/Finding-true-Psi-for-f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dmcsharry/Finding-true-Psi-for-f/runs/dxb7gqo0' target=\"_blank\">https://wandb.ai/dmcsharry/Finding-true-Psi-for-f/runs/dxb7gqo0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[I 2024-04-15 02:40:54,699] Trial 0 finished with value: -0.002632617950439453 and parameters: {'batch_size': 2000, 'feature_size': 16, 'clip': 7, 'critic_output_size': 30, 'downward_hidden_size_v': 86, 'downward_hidden_size_xi': 32, 'feature_hidden_size': 373, 'decoupled_critic_hidden_size': 463, 'feature_lr': 6.150712661095301e-06, 'decoupled_critic_lr': 1.7664621484298773e-05, 'downward_lr': 9.03235645544033e-05, 'update_f_every_N_steps': 5, 'weight_decay': 2.2904444521284543e-06}. Best is trial 0 with value: -0.002632617950439453.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:dxb7gqo0) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Psi</td><td>▁</td></tr><tr><td>decoupled_MI</td><td>▁</td></tr><tr><td>downward_MI_0</td><td>▁</td></tr><tr><td>downward_MI_1</td><td>▁</td></tr><tr><td>downward_MI_10</td><td>▁</td></tr><tr><td>downward_MI_11</td><td>▁</td></tr><tr><td>downward_MI_12</td><td>▁</td></tr><tr><td>downward_MI_13</td><td>▁</td></tr><tr><td>downward_MI_14</td><td>▁</td></tr><tr><td>downward_MI_15</td><td>▁</td></tr><tr><td>downward_MI_16</td><td>▁</td></tr><tr><td>downward_MI_17</td><td>▁</td></tr><tr><td>downward_MI_18</td><td>▁</td></tr><tr><td>downward_MI_19</td><td>▁</td></tr><tr><td>downward_MI_2</td><td>▁</td></tr><tr><td>downward_MI_20</td><td>▁</td></tr><tr><td>downward_MI_21</td><td>▁</td></tr><tr><td>downward_MI_22</td><td>▁</td></tr><tr><td>downward_MI_23</td><td>▁</td></tr><tr><td>downward_MI_24</td><td>▁</td></tr><tr><td>downward_MI_25</td><td>▁</td></tr><tr><td>downward_MI_26</td><td>▁</td></tr><tr><td>downward_MI_27</td><td>▁</td></tr><tr><td>downward_MI_28</td><td>▁</td></tr><tr><td>downward_MI_29</td><td>▁</td></tr><tr><td>downward_MI_3</td><td>▁</td></tr><tr><td>downward_MI_30</td><td>▁</td></tr><tr><td>downward_MI_31</td><td>▁</td></tr><tr><td>downward_MI_32</td><td>▁</td></tr><tr><td>downward_MI_33</td><td>▁</td></tr><tr><td>downward_MI_34</td><td>▁</td></tr><tr><td>downward_MI_35</td><td>▁</td></tr><tr><td>downward_MI_36</td><td>▁</td></tr><tr><td>downward_MI_37</td><td>▁</td></tr><tr><td>downward_MI_38</td><td>▁</td></tr><tr><td>downward_MI_39</td><td>▁</td></tr><tr><td>downward_MI_4</td><td>▁</td></tr><tr><td>downward_MI_40</td><td>▁</td></tr><tr><td>downward_MI_41</td><td>▁</td></tr><tr><td>downward_MI_42</td><td>▁</td></tr><tr><td>downward_MI_43</td><td>▁</td></tr><tr><td>downward_MI_44</td><td>▁</td></tr><tr><td>downward_MI_45</td><td>▁</td></tr><tr><td>downward_MI_46</td><td>▁</td></tr><tr><td>downward_MI_47</td><td>▁</td></tr><tr><td>downward_MI_48</td><td>▁</td></tr><tr><td>downward_MI_49</td><td>▁</td></tr><tr><td>downward_MI_5</td><td>▁</td></tr><tr><td>downward_MI_50</td><td>▁</td></tr><tr><td>downward_MI_51</td><td>▁</td></tr><tr><td>downward_MI_52</td><td>▁</td></tr><tr><td>downward_MI_53</td><td>▁</td></tr><tr><td>downward_MI_54</td><td>▁</td></tr><tr><td>downward_MI_55</td><td>▁</td></tr><tr><td>downward_MI_56</td><td>▁</td></tr><tr><td>downward_MI_57</td><td>▁</td></tr><tr><td>downward_MI_58</td><td>▁</td></tr><tr><td>downward_MI_59</td><td>▁</td></tr><tr><td>downward_MI_6</td><td>▁</td></tr><tr><td>downward_MI_60</td><td>▁</td></tr><tr><td>downward_MI_61</td><td>▁</td></tr><tr><td>downward_MI_62</td><td>▁</td></tr><tr><td>downward_MI_63</td><td>▁</td></tr><tr><td>downward_MI_7</td><td>▁</td></tr><tr><td>downward_MI_8</td><td>▁</td></tr><tr><td>downward_MI_9</td><td>▁</td></tr><tr><td>sum_downward_MI</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Psi</td><td>-0.00263</td></tr><tr><td>decoupled_MI</td><td>0.0</td></tr><tr><td>downward_MI_0</td><td>3e-05</td></tr><tr><td>downward_MI_1</td><td>-2e-05</td></tr><tr><td>downward_MI_10</td><td>-1e-05</td></tr><tr><td>downward_MI_11</td><td>2e-05</td></tr><tr><td>downward_MI_12</td><td>-0.0</td></tr><tr><td>downward_MI_13</td><td>-2e-05</td></tr><tr><td>downward_MI_14</td><td>-0.0</td></tr><tr><td>downward_MI_15</td><td>-0.0</td></tr><tr><td>downward_MI_16</td><td>-1e-05</td></tr><tr><td>downward_MI_17</td><td>-1e-05</td></tr><tr><td>downward_MI_18</td><td>-1e-05</td></tr><tr><td>downward_MI_19</td><td>1e-05</td></tr><tr><td>downward_MI_2</td><td>-0.0</td></tr><tr><td>downward_MI_20</td><td>-3e-05</td></tr><tr><td>downward_MI_21</td><td>-1e-05</td></tr><tr><td>downward_MI_22</td><td>0.0</td></tr><tr><td>downward_MI_23</td><td>2e-05</td></tr><tr><td>downward_MI_24</td><td>-1e-05</td></tr><tr><td>downward_MI_25</td><td>-0.0</td></tr><tr><td>downward_MI_26</td><td>-1e-05</td></tr><tr><td>downward_MI_27</td><td>-2e-05</td></tr><tr><td>downward_MI_28</td><td>2e-05</td></tr><tr><td>downward_MI_29</td><td>-3e-05</td></tr><tr><td>downward_MI_3</td><td>-1e-05</td></tr><tr><td>downward_MI_30</td><td>-1e-05</td></tr><tr><td>downward_MI_31</td><td>-1e-05</td></tr><tr><td>downward_MI_32</td><td>2e-05</td></tr><tr><td>downward_MI_33</td><td>1e-05</td></tr><tr><td>downward_MI_34</td><td>-0.0</td></tr><tr><td>downward_MI_35</td><td>-1e-05</td></tr><tr><td>downward_MI_36</td><td>-1e-05</td></tr><tr><td>downward_MI_37</td><td>-1e-05</td></tr><tr><td>downward_MI_38</td><td>-1e-05</td></tr><tr><td>downward_MI_39</td><td>-2e-05</td></tr><tr><td>downward_MI_4</td><td>-1e-05</td></tr><tr><td>downward_MI_40</td><td>-1e-05</td></tr><tr><td>downward_MI_41</td><td>-3e-05</td></tr><tr><td>downward_MI_42</td><td>-4e-05</td></tr><tr><td>downward_MI_43</td><td>-2e-05</td></tr><tr><td>downward_MI_44</td><td>-3e-05</td></tr><tr><td>downward_MI_45</td><td>-3e-05</td></tr><tr><td>downward_MI_46</td><td>-3e-05</td></tr><tr><td>downward_MI_47</td><td>-0.0</td></tr><tr><td>downward_MI_48</td><td>-1e-05</td></tr><tr><td>downward_MI_49</td><td>-1e-05</td></tr><tr><td>downward_MI_5</td><td>-3e-05</td></tr><tr><td>downward_MI_50</td><td>-1e-05</td></tr><tr><td>downward_MI_51</td><td>-1e-05</td></tr><tr><td>downward_MI_52</td><td>-1e-05</td></tr><tr><td>downward_MI_53</td><td>-1e-05</td></tr><tr><td>downward_MI_54</td><td>1e-05</td></tr><tr><td>downward_MI_55</td><td>-2e-05</td></tr><tr><td>downward_MI_56</td><td>-1e-05</td></tr><tr><td>downward_MI_57</td><td>-1e-05</td></tr><tr><td>downward_MI_58</td><td>-2e-05</td></tr><tr><td>downward_MI_59</td><td>-2e-05</td></tr><tr><td>downward_MI_6</td><td>-4e-05</td></tr><tr><td>downward_MI_60</td><td>-2e-05</td></tr><tr><td>downward_MI_61</td><td>-2e-05</td></tr><tr><td>downward_MI_62</td><td>0.0</td></tr><tr><td>downward_MI_63</td><td>-1e-05</td></tr><tr><td>downward_MI_7</td><td>-1e-05</td></tr><tr><td>downward_MI_8</td><td>-9e-05</td></tr><tr><td>downward_MI_9</td><td>-3e-05</td></tr><tr><td>sum_downward_MI</td><td>0.00263</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">logical-pyramid-9</strong> at: <a href='https://wandb.ai/dmcsharry/Finding-true-Psi-for-f/runs/dxb7gqo0' target=\"_blank\">https://wandb.ai/dmcsharry/Finding-true-Psi-for-f/runs/dxb7gqo0</a><br/> View project at: <a href='https://wandb.ai/dmcsharry/Finding-true-Psi-for-f' target=\"_blank\">https://wandb.ai/dmcsharry/Finding-true-Psi-for-f</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240415_024047-dxb7gqo0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:dxb7gqo0). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/dm2223/info-theory-experiments/wandb/run-20240415_024054-98wtdn99</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dmcsharry/getting-figures/runs/98wtdn99' target=\"_blank\">jolly-spaceship-98</a></strong> to <a href='https://wandb.ai/dmcsharry/getting-figures' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dmcsharry/getting-figures' target=\"_blank\">https://wandb.ai/dmcsharry/getting-figures</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dmcsharry/getting-figures/runs/98wtdn99' target=\"_blank\">https://wandb.ai/dmcsharry/getting-figures/runs/98wtdn99</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.SupervenientFeatureNetwork'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:98wtdn99) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Psi</td><td>▁</td></tr><tr><td>decoupled_MI</td><td>▁</td></tr><tr><td>downward_MI_0</td><td>▁</td></tr><tr><td>downward_MI_1</td><td>▁</td></tr><tr><td>downward_MI_10</td><td>▁</td></tr><tr><td>downward_MI_11</td><td>▁</td></tr><tr><td>downward_MI_12</td><td>▁</td></tr><tr><td>downward_MI_13</td><td>▁</td></tr><tr><td>downward_MI_14</td><td>▁</td></tr><tr><td>downward_MI_15</td><td>▁</td></tr><tr><td>downward_MI_16</td><td>▁</td></tr><tr><td>downward_MI_17</td><td>▁</td></tr><tr><td>downward_MI_18</td><td>▁</td></tr><tr><td>downward_MI_19</td><td>▁</td></tr><tr><td>downward_MI_2</td><td>▁</td></tr><tr><td>downward_MI_20</td><td>▁</td></tr><tr><td>downward_MI_21</td><td>▁</td></tr><tr><td>downward_MI_22</td><td>▁</td></tr><tr><td>downward_MI_23</td><td>▁</td></tr><tr><td>downward_MI_24</td><td>▁</td></tr><tr><td>downward_MI_25</td><td>▁</td></tr><tr><td>downward_MI_26</td><td>▁</td></tr><tr><td>downward_MI_27</td><td>▁</td></tr><tr><td>downward_MI_28</td><td>▁</td></tr><tr><td>downward_MI_29</td><td>▁</td></tr><tr><td>downward_MI_3</td><td>▁</td></tr><tr><td>downward_MI_30</td><td>▁</td></tr><tr><td>downward_MI_31</td><td>▁</td></tr><tr><td>downward_MI_32</td><td>▁</td></tr><tr><td>downward_MI_33</td><td>▁</td></tr><tr><td>downward_MI_34</td><td>▁</td></tr><tr><td>downward_MI_35</td><td>▁</td></tr><tr><td>downward_MI_36</td><td>▁</td></tr><tr><td>downward_MI_37</td><td>▁</td></tr><tr><td>downward_MI_38</td><td>▁</td></tr><tr><td>downward_MI_39</td><td>▁</td></tr><tr><td>downward_MI_4</td><td>▁</td></tr><tr><td>downward_MI_40</td><td>▁</td></tr><tr><td>downward_MI_41</td><td>▁</td></tr><tr><td>downward_MI_42</td><td>▁</td></tr><tr><td>downward_MI_43</td><td>▁</td></tr><tr><td>downward_MI_44</td><td>▁</td></tr><tr><td>downward_MI_45</td><td>▁</td></tr><tr><td>downward_MI_46</td><td>▁</td></tr><tr><td>downward_MI_47</td><td>▁</td></tr><tr><td>downward_MI_48</td><td>▁</td></tr><tr><td>downward_MI_49</td><td>▁</td></tr><tr><td>downward_MI_5</td><td>▁</td></tr><tr><td>downward_MI_50</td><td>▁</td></tr><tr><td>downward_MI_51</td><td>▁</td></tr><tr><td>downward_MI_52</td><td>▁</td></tr><tr><td>downward_MI_53</td><td>▁</td></tr><tr><td>downward_MI_54</td><td>▁</td></tr><tr><td>downward_MI_55</td><td>▁</td></tr><tr><td>downward_MI_56</td><td>▁</td></tr><tr><td>downward_MI_57</td><td>▁</td></tr><tr><td>downward_MI_58</td><td>▁</td></tr><tr><td>downward_MI_59</td><td>▁</td></tr><tr><td>downward_MI_6</td><td>▁</td></tr><tr><td>downward_MI_60</td><td>▁</td></tr><tr><td>downward_MI_61</td><td>▁</td></tr><tr><td>downward_MI_62</td><td>▁</td></tr><tr><td>downward_MI_63</td><td>▁</td></tr><tr><td>downward_MI_7</td><td>▁</td></tr><tr><td>downward_MI_8</td><td>▁</td></tr><tr><td>downward_MI_9</td><td>▁</td></tr><tr><td>sum_downward_MI</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Psi</td><td>-0.00046</td></tr><tr><td>decoupled_MI</td><td>-0.0</td></tr><tr><td>downward_MI_0</td><td>-0.0</td></tr><tr><td>downward_MI_1</td><td>0.0</td></tr><tr><td>downward_MI_10</td><td>-2e-05</td></tr><tr><td>downward_MI_11</td><td>1e-05</td></tr><tr><td>downward_MI_12</td><td>-1e-05</td></tr><tr><td>downward_MI_13</td><td>-2e-05</td></tr><tr><td>downward_MI_14</td><td>0.0</td></tr><tr><td>downward_MI_15</td><td>0.0</td></tr><tr><td>downward_MI_16</td><td>2e-05</td></tr><tr><td>downward_MI_17</td><td>-5e-05</td></tr><tr><td>downward_MI_18</td><td>-4e-05</td></tr><tr><td>downward_MI_19</td><td>-1e-05</td></tr><tr><td>downward_MI_2</td><td>-6e-05</td></tr><tr><td>downward_MI_20</td><td>-5e-05</td></tr><tr><td>downward_MI_21</td><td>-1e-05</td></tr><tr><td>downward_MI_22</td><td>1e-05</td></tr><tr><td>downward_MI_23</td><td>2e-05</td></tr><tr><td>downward_MI_24</td><td>-2e-05</td></tr><tr><td>downward_MI_25</td><td>-2e-05</td></tr><tr><td>downward_MI_26</td><td>1e-05</td></tr><tr><td>downward_MI_27</td><td>-2e-05</td></tr><tr><td>downward_MI_28</td><td>1e-05</td></tr><tr><td>downward_MI_29</td><td>9e-05</td></tr><tr><td>downward_MI_3</td><td>-1e-05</td></tr><tr><td>downward_MI_30</td><td>2e-05</td></tr><tr><td>downward_MI_31</td><td>7e-05</td></tr><tr><td>downward_MI_32</td><td>-1e-05</td></tr><tr><td>downward_MI_33</td><td>-4e-05</td></tr><tr><td>downward_MI_34</td><td>-0.0</td></tr><tr><td>downward_MI_35</td><td>-1e-05</td></tr><tr><td>downward_MI_36</td><td>-0.0</td></tr><tr><td>downward_MI_37</td><td>-3e-05</td></tr><tr><td>downward_MI_38</td><td>-0.0</td></tr><tr><td>downward_MI_39</td><td>-3e-05</td></tr><tr><td>downward_MI_4</td><td>-2e-05</td></tr><tr><td>downward_MI_40</td><td>-2e-05</td></tr><tr><td>downward_MI_41</td><td>1e-05</td></tr><tr><td>downward_MI_42</td><td>1e-05</td></tr><tr><td>downward_MI_43</td><td>-2e-05</td></tr><tr><td>downward_MI_44</td><td>-2e-05</td></tr><tr><td>downward_MI_45</td><td>-1e-05</td></tr><tr><td>downward_MI_46</td><td>3e-05</td></tr><tr><td>downward_MI_47</td><td>5e-05</td></tr><tr><td>downward_MI_48</td><td>-1e-05</td></tr><tr><td>downward_MI_49</td><td>0.0</td></tr><tr><td>downward_MI_5</td><td>-2e-05</td></tr><tr><td>downward_MI_50</td><td>0.0</td></tr><tr><td>downward_MI_51</td><td>1e-05</td></tr><tr><td>downward_MI_52</td><td>0.0</td></tr><tr><td>downward_MI_53</td><td>2e-05</td></tr><tr><td>downward_MI_54</td><td>1e-05</td></tr><tr><td>downward_MI_55</td><td>2e-05</td></tr><tr><td>downward_MI_56</td><td>1e-05</td></tr><tr><td>downward_MI_57</td><td>-0.0</td></tr><tr><td>downward_MI_58</td><td>-2e-05</td></tr><tr><td>downward_MI_59</td><td>5e-05</td></tr><tr><td>downward_MI_6</td><td>-3e-05</td></tr><tr><td>downward_MI_60</td><td>-4e-05</td></tr><tr><td>downward_MI_61</td><td>-0.0</td></tr><tr><td>downward_MI_62</td><td>-3e-05</td></tr><tr><td>downward_MI_63</td><td>2e-05</td></tr><tr><td>downward_MI_7</td><td>0.0</td></tr><tr><td>downward_MI_8</td><td>0.0</td></tr><tr><td>downward_MI_9</td><td>-8e-05</td></tr><tr><td>sum_downward_MI</td><td>0.00046</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">jolly-spaceship-98</strong> at: <a href='https://wandb.ai/dmcsharry/getting-figures/runs/98wtdn99' target=\"_blank\">https://wandb.ai/dmcsharry/getting-figures/runs/98wtdn99</a><br/> View project at: <a href='https://wandb.ai/dmcsharry/getting-figures' target=\"_blank\">https://wandb.ai/dmcsharry/getting-figures</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240415_024054-98wtdn99/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:98wtdn99). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/dm2223/info-theory-experiments/wandb/run-20240415_024101-98wtdn99</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dmcsharry/Finding-true-Psi-for-f/runs/98wtdn99' target=\"_blank\">clean-eon-10</a></strong> to <a href='https://wandb.ai/dmcsharry/Finding-true-Psi-for-f' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dmcsharry/Finding-true-Psi-for-f' target=\"_blank\">https://wandb.ai/dmcsharry/Finding-true-Psi-for-f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dmcsharry/Finding-true-Psi-for-f/runs/98wtdn99' target=\"_blank\">https://wandb.ai/dmcsharry/Finding-true-Psi-for-f/runs/98wtdn99</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[I 2024-04-15 02:41:08,486] Trial 1 finished with value: -0.0007123947143554688 and parameters: {'batch_size': 2000, 'feature_size': 16, 'clip': 2, 'critic_output_size': 10, 'downward_hidden_size_v': 476, 'downward_hidden_size_xi': 75, 'feature_hidden_size': 958, 'decoupled_critic_hidden_size': 175, 'feature_lr': 1.723749852560971e-05, 'decoupled_critic_lr': 1.6145668368018935e-05, 'downward_lr': 6.425805952319134e-05, 'update_f_every_N_steps': 5, 'weight_decay': 1.5989586833270346e-06}. Best is trial 1 with value: -0.0007123947143554688.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import optuna\n",
    "def objective(trial):\n",
    "\n",
    "    config = {\n",
    "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [500, 1000, 2000]),\n",
    "        \"num_atoms\": 64,\n",
    "        \"feature_size\": trial.suggest_categorical(\"feature_size\", [2, 4, 8, 16]),\n",
    "        \"clip\": trial.suggest_int(\"clip\", 1, 10),\n",
    "        \"critic_output_size\": trial.suggest_int(\"critic_output_size\", 8, 64, log=True),\n",
    "        \"downward_hidden_sizes_v_critic\": [trial.suggest_int(\"downward_hidden_size_v\", 64, 512, log=True) for _ in range(3)],\n",
    "        \"downward_hidden_sizes_xi_critic\": [trial.suggest_int(\"downward_hidden_size_xi\", 32, 256, log=True) for _ in range(3)],\n",
    "        \"feature_hidden_sizes\": [trial.suggest_int(\"feature_hidden_size\", 256, 1024, log=True) for _ in range(4)],\n",
    "        \"decoupled_critis_hidden_sizes\": [trial.suggest_int(\"decoupled_critic_hidden_size\", 64, 512, log=True) for _ in range(3)],\n",
    "        \"feature_lr\": trial.suggest_float(\"feature_lr\", 1e-6, 1e-3, log=True),\n",
    "        \"decoupled_critic_lr\": trial.suggest_float(\"decoupled_critic_lr\", 1e-5, 1e-3, log=True),\n",
    "        \"downward_lr\": trial.suggest_float(\"downward_lr\", 1e-5, 1e-3, log=True),\n",
    "        \"bias\": True,\n",
    "        \"update_f_every_N_steps\": trial.suggest_int(\"update_f_every_N_steps\", 1, 20, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-9, 1e-4, log=True),\n",
    "    }\n",
    "\n",
    "    feature_network = train_feature_network(config)\n",
    "    Psi = find_true_Psi(feature_network, wandb.run.id, feature_config=config)\n",
    "\n",
    "    return Psi\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)  # Adjust the number of trials as needed\n",
    "\n",
    "# add the Psi value the params of the top 5 runs, then save\n",
    "\n",
    "import json\n",
    "\n",
    "# save best params\n",
    "with open(\"optuna_results/best_params.json\", \"w\") as f:\n",
    "    json.dump(study.best_params, f)\n",
    "\n",
    "# save second best params\n",
    "with open(\"optuna_results/second_best_params.json\", \"w\") as f:\n",
    "    json.dump(study.best_trials[1].params, f)\n",
    "\n",
    "# save third best params\n",
    "with open(\"optuna_results/third_best_params.json\", \"w\") as f:\n",
    "    json.dump(study.best_trials[2].params, f)\n",
    "\n",
    "# save fourth best params\n",
    "with open(\"optuna_results/fourth_best_params.json\", \"w\") as f:\n",
    "    json.dump(study.best_trials[3].params, f)\n",
    "\n",
    "# save fifth best params\n",
    "with open(\"optuna_results/fifth_best_params.json\", \"w\") as f:\n",
    "    json.dump(study.best_trials[4].params, f)\n",
    "\n",
    "\n",
    "top_5 = study.best_trials[:5]\n",
    "\n",
    "for i, trial in enumerate(top_5):\n",
    "    trial.params['Psi'] = trial.value\n",
    "    with open(f\"optuna_results/trial_{i}.json\", \"w\") as f:\n",
    "        json.dump(trial.params, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacky hyperparam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
